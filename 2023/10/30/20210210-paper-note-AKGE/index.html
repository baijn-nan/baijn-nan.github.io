<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/ico_themes/chidouren.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/ico_themes/chidouren.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/ico_themes/chidouren.ico">
  <link rel="mask-icon" href="/ico_themes/chidouren.ico" color="#222">
  <link rel="manifest" href="/ico_themes/chidouren.ico">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Arial:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"baijn-nan.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.18.2","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="原文写于 20210210，存档如下 ※ 考虑到本文写作时间，笔记仍基于 v3 版本 → 原论文已于202109 更新 v4  Attentive knowledge graph embedding for personalized recommendation. Sha, X. , Sun, Z. , &amp; Zhang, J. . (2019). 原文：https:&#x2F;&#x2F;arxiv.org&#x2F;">
<meta property="og:type" content="article">
<meta property="og:title" content="AKGE: 基于注意力知识图谱嵌入的个性化推荐系统">
<meta property="og:url" content="https://baijn-nan.github.io/2023/10/30/20210210-paper-note-AKGE/index.html">
<meta property="og:site_name" content="baijnNAN MagicMountain">
<meta property="og:description" content="原文写于 20210210，存档如下 ※ 考虑到本文写作时间，笔记仍基于 v3 版本 → 原论文已于202109 更新 v4  Attentive knowledge graph embedding for personalized recommendation. Sha, X. , Sun, Z. , &amp; Zhang, J. . (2019). 原文：https:&#x2F;&#x2F;arxiv.org&#x2F;">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073433663.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073548374.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073702709.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021074609007.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075334866.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021074947597.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075034703.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075109707.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075149066.png">
<meta property="article:published_time" content="2023-10-31T03:59:33.000Z">
<meta property="article:modified_time" content="2023-10-30T12:22:15.378Z">
<meta property="article:author" content="baijnNAN">
<meta property="article:tag" content="推荐系统">
<meta property="article:tag" content="图模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073433663.png">


<link rel="canonical" href="https://baijn-nan.github.io/2023/10/30/20210210-paper-note-AKGE/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://baijn-nan.github.io/2023/10/30/20210210-paper-note-AKGE/","path":"2023/10/30/20210210-paper-note-AKGE/","title":"AKGE: 基于注意力知识图谱嵌入的个性化推荐系统"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AKGE: 基于注意力知识图谱嵌入的个性化推荐系统 | baijnNAN MagicMountain</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">baijnNAN MagicMountain</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-anchor fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-introduction"><span class="nav-text">1 introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A"><span class="nav-text">2 模型解释</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E6%9E%84%E5%BB%BA%E5%AD%90%E5%9B%BE"><span class="nav-text">2.1 构建子图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E7%BB%93%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-AGNN"><span class="nav-text">2.2 结合注意力机制的图神经网络 AGNN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-%E5%AE%9E%E4%BD%93%E6%98%A0%E5%B0%84%EF%BC%88entity-projection%EF%BC%89"><span class="nav-text">2.2.1 实体映射（entity projection）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-%E5%85%B3%E7%B3%BB%E6%84%9F%E7%9F%A5%E4%BC%A0%E6%92%AD%EF%BC%88relation-aware-propagation%EF%BC%89"><span class="nav-text">2.2.2 关系感知传播（relation-aware propagation）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-3-%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%81%9A%E5%90%88%EF%BC%88attentive-aggregation%EF%BC%89"><span class="nav-text">2.2.3 注意力聚合（attentive aggregation）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-4-%E9%97%A8%E6%8E%A7%E6%9B%B4%E6%96%B0%EF%BC%88gated-update%EF%BC%89"><span class="nav-text">2.2.4 门控更新（gated update）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-5-summary"><span class="nav-text">2.2.5 summary</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-%E9%A2%84%E6%B5%8B%E5%B1%82"><span class="nav-text">2.3 预测层</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0"><span class="nav-text">3 模型学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AE%9E%E9%AA%8C"><span class="nav-text">4 数据集实验</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="baijnNAN"
      src="/ico_themes/nisepanda.jpg">
  <p class="site-author-name" itemprop="name">baijnNAN</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JhaWpuLW5hbg==" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;baijn-nan"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOmppbmduYW5iYWkxMDMyMjFAZ21haWwuY29t" title="Mail → mailto:jingnanbai103221@gmail.com"><i class="fa fa-envelope fa-fw"></i>Mail</span>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://baijn-nan.github.io/2023/10/30/20210210-paper-note-AKGE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/ico_themes/nisepanda.jpg">
      <meta itemprop="name" content="baijnNAN">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="baijnNAN MagicMountain">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="AKGE: 基于注意力知识图谱嵌入的个性化推荐系统 | baijnNAN MagicMountain">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AKGE: 基于注意力知识图谱嵌入的个性化推荐系统
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-30 23:59:33" itemprop="dateCreated datePublished" datetime="2023-10-30T23:59:33-04:00">2023-10-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">推荐系统</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E5%9B%BE%E6%A8%A1%E5%9E%8B-%E6%8E%A8%E8%8D%90/" itemprop="url" rel="index"><span itemprop="name">图模型+推荐</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>3.3k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>12 mins.</span>
    </span>
</div>


          
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>原文写于 20210210，存档如下</p>
<p>※ 考虑到本文写作时间，笔记仍基于 v3 版本 → 原论文已于202109 更新 v4</p>
<blockquote>
<p><strong>Attentive knowledge graph embedding for personalized recommendation</strong>. Sha, X. , Sun, Z. , &amp; Zhang, J. . (2019).</p>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MTAuMDgyODgucGRm">https://arxiv.org/pdf/1910.08288.pdf<i class="fa fa-external-link-alt"></i></span> ；本文写作版本 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MTAuMDgyODh2My5wZGY=">https://arxiv.org/pdf/1910.08288v3.pdf<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<p>知识图谱（KG）已经被广泛用于推荐系统中，但是主要思路仍集中于以下两个方向：</p>
<ul>
<li><strong>基于路径提取的思路（path-based methods）</strong>：有的是要求人手动设计 meta-path / meta-graph，有的集中于寻找 user 和 item 之间的线性的路径联系。缺点在于只是利用异构信息网路将 side information 引入了推荐系统，但是本质上 linear path 的信息十分有限，特别是和本文提出的包含高阶关系的子图相比，其不能够较好地挖掘整个 KG 的语义信息和拓扑结构信息。</li>
<li><strong>基于传播的思路（propagation-based methods）</strong>：在整个 KG 上通过传播的方式（propagate）传递用户的偏好，再得到用户的表示 embedding。较为经典的就是 RippleNet（<a href="https://baijn-nan.github.io/2023/10/18/20210208-paper-note-RippleNet/">RippleNet 笔记</a>）和 KGAT（<a href="https://baijn-nan.github.io/2023/10/21/20210209-paper-note-KGAT/">KGAT 笔记</a>），KGCN 类似（<a href="https://baijn-nan.github.io/2023/10/21/20210209-paper-note-KGCN/">KGCN笔记</a>）。虽然一定程度上可以捕捉到语义信息和拓扑结构信息，传播的时候往往出现重合的问题，也就是若将过多跳的信息加入当前 item 的模型计算，反而容易向模型中引入噪音，故其在类似于 yelp 的较为 dense 的数据集上表现不佳（详见 RippleNet 原文作者的解释）。</li>
</ul>
<p>而原文所提出的 <strong>基于注意力知识图谱嵌入的推荐系统（AKGE）</strong> 可以同时关注知识图谱对应的语义信息和拓扑信息：作为端到端训练的神经网络，首先提取包含语义信息的，连接 item 和 user 的高阶关系的子图，再利用注意力机制，基于子图学习用户偏好。</p>
<p>利用高阶子图的好处主要有：</p>
<ul>
<li>涉及了高阶关系的子图本质上可以看作是非线性路径（nonlinear path ）的一个组合（combination），也就是说相较于普通的路径提取，此时可以更好地挖掘整个 KG 的语义信息与拓扑结构信息</li>
<li>本身一个特定高阶子图对应一个（用户 - 物品 pair），也就是说此时可以一定程度上避免直接在整个 KG 上进行传播的算法造成的引入噪音的问题，不同的 use-item interaction 对应的是不同的高阶子图。</li>
</ul>
<p>但是这里同样为整个模型提出了挑战：如何去提取挖掘这样的高阶子图，特别是在 KG 本身的 entity 较多，本身就给整个模型计算带来巨大计算开销的情况下。本文提出 <strong>距离感知抽样策略（distance-aware sampling strategy）</strong> 来帮助构造 item 和 user 之间关系的高阶子图。</p>
<p>另一个问题就是如何利用提取出的高阶子图来进行 encode，这里采用 <strong>图神经网络（ graph neural networks  / GNNs）</strong> 来对子图进行 embedding。子图的非欧几里德结构适合应用 GNN。但是注意到，在 GNN 中所有的邻居都会被平等对待，为了强调不同的权重，在这里同时加入 <strong>注意力机制</strong> 。（这里的思路类似 KGAT ，在 KGAT 中，考察某一个结点的邻域表示时，利用注意力机制赋予不同的邻居不同的权重。）主要包括两个部分：<strong>关系感知的传播（relation-aware propagation）</strong> 和 <strong>注意力聚合（attentive aggregation）</strong></p>
<br>
<br>
<hr>
<h2 id="2-模型解释">2 模型解释</h2>
<br>
<p>整体模型结构如下：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073433663.png" style="zoom:80%"/>
<p>注意此时本质上是输入一个 user 和一个 item（ 比如这里就是给定了 mike 和 k记），首先提取它俩之间的一个子图（不是单纯的 线性path，而是一个子图），再通过这个子图计算 mike 和 k记 的 embedding，再通过正常的 MLP 预测 mike 点击 k 记的概率。</p>
<br>
<br>
<h3 id="2-1-构建子图">2.1 构建子图</h3>
<p>这里不再使用传统的 BFS  / DFS 在整个 KG 上进行搜索，采用效率更高的 <strong>距离感知抽样策略（distance-aware sampling strategy）</strong></p>
<p>对于传统的基于 meta-path 和 meta-graph 的方法，此时需要人工设计路径来使用，本身不全面且有效性有待商榷。</p>
<p>首先得到 KG 中所有实体的一个 embedding （像预训练一样，这里可以用 Trans 系列的方法，原论文用的是 TransR，并且在实验部分证明了 TransR 预训练的效果比较好），则此时可以通过欧几里得距离来衡量两个 entity 之间的距离。同理，对于任意两个 entity 之间的任意一条的 path，可以将 path 上每一步的两个 entity 的距离算出来，再求和作为这个 path 的距离。</p>
<p>对于给定的两个 entity ，仅保留最后的 K 条最短的路径构成二者之间的子图（subgraph）。注意这里和 DFS / BFS 之间的区别在于本身通过距离进行了筛选，而不是单纯地保留了所有的邻居。</p>
<p>得到 K 条最短的 path 后，需要进行 <strong>路径装配（Path Assembling）</strong></p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073548374.png" style="zoom:70%"/>
<p>也就是将得到的 K 条路径装配起来，得到一个子图。同理可以得到其对应的邻接矩阵（adjacency matrix)，注意这里得到的子图是一个无向图，也就是说不再确定 relationship 所指向的方向。</p>
<br>
<br>
<h3 id="2-2-结合注意力机制的图神经网络-AGNN">2.2 结合注意力机制的图神经网络 AGNN</h3>
<p>这里的 AGNN 本质上是对 GGNN 的一个改进（gated graph neural network），AGNN 可以用于异构图上，而 GGNN 需要各个结点的类型相同（也就是同质图）</p>
<p>AGNN 分为以下四个步骤：</p>
<ul>
<li><strong>实体映射（entity projection）</strong>：将实体的 embedding 和实体类型的 embedding 进行结合，得到融合了类型信息的实体的 embedding，即 $h_l^0$</li>
<li><strong>关系感知传播（relation-aware propagation）</strong>：对于第 t 轮迭代，通过实体 l 和它的邻居 e 之间的关系 r，计算 l 的邻居实体 e 的临时隐藏状态 $\hat{h}_k^t$</li>
<li><strong>注意力聚合（attentive aggregation）</strong>：通过注意力机制分配权重，将实体 l 邻居 e 的临时隐藏状态 $\hat{h}_k^t$ 通过某种方式进行聚合。</li>
<li><strong>门控更新（gated update）</strong>：用注意力聚合的结果，经过门控机制来更新实体 l 的 embedding 表示。</li>
</ul>
<br>
<h4 id="2-2-1-实体映射（entity-projection）">2.2.1 实体映射（entity projection）</h4>
<p>此时输入的是构造好的子图 $\mathcal{G}$ 和对应的邻接矩阵 $A$，将图中的各个实体和其对应的类型进行拼接。</p>
<p>这里的 embedding 预训练由 TransR 完成。记实体 entity 的 embedding 是 $e_l$，记实体类型 entity type 的 embedding 为 $e'_l$，则此时直接进行拼接：$$h_l^0 = \hat{e}_l = f(e_l \text{ }\oplus\text{ }e_l'); \text{ }\text{ } f(x) = \sigma(Wx+b)$$ 注意这里的 entity 和 entity type 的 embedding 可以是不同维度的（总之只是作拼接操作），最后得到的 $h_l^0 = \hat{e}_l$ 也就是融合了类型信息的实体的 embedding，这也是和 GNN 不同的地方。</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073702709.png" style="zoom:100%"/>
<br>
<h4 id="2-2-2-关系感知传播（relation-aware-propagation）">2.2.2 关系感知传播（relation-aware propagation）</h4>
<p>类似传播的思路，此时利用邻域的信息和原本信息的聚合（aggregation）来不断更新实体 e 的 embedding</p>
<p>对于当前的实体 l，考虑它的邻居 k，令 $r_{l,k}$ 表示二者之间的关系，此时通过前面的实体映射已经得到了 t=0 时的实体 ek 的隐藏状态 $h_k^0$</p>
<p>对于一个特定的 t，此时通过 $h_k^t$ 来计算 $\hat{h}_k^t$：$$\hat{h}<em>k^t = g(h_k^t \text{ }\oplus\text{ }r</em>{l,k}), \text{ } e_k\in N_l, \text{ }g(x) = \sigma(Wx + b)$$这里的 $N(l)$ 也就是 $l$ 的所有的邻居实体的集合。</p>
<br>
<h4 id="2-2-3-注意力聚合（attentive-aggregation）">2.2.3 注意力聚合（attentive aggregation）</h4>
<p>此时用注意力机制分配权重，将实体 l 的所有邻居实体 e 的 embedding 进行聚合。得到结合了注意力机制的实体 l 的隐藏状态，记作 $a_l^t$：$$a_l^t = (A_{sl} \odot Q_l^t) [\hat{h}<em>1^{t-1}, ..., \hat{h}</em>{|\mathcal{E}_s|}^{t-1}]^T + b$$这里的 A 是输入的子图对应的邻接矩阵（0-1），A_sl 表示 A 中对应实体 l 的那一行向量，Ql 是注意力权重矩阵（后续会说怎么算），$\mathcal{E}_s$ 是子图中所有结点的集合，$\odot$ 表示哈达玛积。</p>
<p>如果此时实体 e 和当前实体 l 并没有联系，则 Q 注意力权重和邻接矩阵 A 的对应位置都是 0。</p>
<p>现在来看 Q 注意力权重矩阵怎么算，本身用于衡量实体 l 的不同邻居 e 对于实体 l 的重要程度。这里和注意力机制的原理相同，还是利用一个两层的全连接层进行计算，最后通过 softmax 进行归一化。</p>
<p>$$\alpha_{l,k}^t = W_2^T(W_1[\hat{h}_k^{t-1}\oplus h_l^{t-1}]+b_1)+b_2$$</p>
<p>$$q_{l,k}^t = \frac{exp(\alpha_{l,k}^t )}{\sum_{e_j\in N_l}{exp(\alpha_{l,k}^t )}}$$</p>
<p>注意这里衡量邻居 e 对实体 l 的重要程度，用的是经过了 关系感知传播 后的 k 的隐藏状态 $\hat{h}_k^{t-1}$ 和上一个完整步后得到的 $h_l^{t-1}$</p>
<p>则此时可以得到注意力权重矩阵 Q</p>
<br>
<h4 id="2-2-4-门控更新（gated-update）">2.2.4 门控更新（gated update）</h4>
<p>也就是利用上面得到的 $\alpha_l^t$ 经过门控机制来更新实体 l 的embedding，最终得到 $h_l^{t+1}$</p>
<p>先看更新门 z 和重置门 r：</p>
<p>$$z_l^t = \sigma(W_z a_l^t + U_Z h _L ^{t-1})$$</p>
<p>$$r_l^t = \sigma(W_r a_l^t + U_r h_l ^{t-1})$$</p>
<p>这里是同时用到注意力机制后得到的 alpha 和本身在上一步的 embedding h 的，对应 σ 是 sigmoid 函数，W 和 U 是可学习参数；</p>
<p>综上基于当前的 h，不断更新得到新的 h：</p>
<p>$$\tilde{h} _l ^t = tanh(W_h a_l^t + U_h(r_l^t \odot h _l ^{t-1}))$$</p>
<p>$$h_l^t = (1-z_l^t) \odot h_l ^{t-1} + z_l^t \odot \tilde{h} _l ^t$$</p>
<br/>
<h4 id="2-2-5-summary">2.2.5 summary</h4>
<p>再整体看看 AGNN 部分的流程：</p>
<p>本质就是先从前一步提取中的子图中，利用 TransR 先得到的预训练 embedding 和实体类型的结合进行 <strong>实体映射</strong>，以得到初始的隐状态。</p>
<p>再通过 <strong>关系感知传播</strong> 来计算邻居实体的临时隐藏状态，进一步结合注意力机制分配权重的思想，通过 <strong>注意力聚合</strong> 将上一步得到的邻居实体的状态进行加权聚合，最后通过<strong>门控机制</strong>，以完成针对实体 l 的 embedding 的更新。</p>
<p>上述的更新部分（也就是后三个步骤）重复多次，最后得到各个实体的最终 embedding 表示。也就是预训练（实体映射）+ 共 T 次不断更新隐藏状态：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021074609007.png" style="zoom:80%"/>
<p>每一次隐藏状态更新的细节：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075334866.png" alt="image-20231021075334866" style="zoom:80%;" />
<br>
<br>
<h3 id="2-3-预测层">2.3 预测层</h3>
<p>此时通过 MLP prediction 来预测用户是否会对物品进行点击。注意这里和大部分模型不同，没有利用点击预测，而是一个普通的多层感知机。</p>
<p>原论文的激活函数用的是 ReLU，最后输出层是 sigmoid（最后输出点击的概率）</p>
<br>
<br>
<hr>
<h2 id="3-模型学习">3 模型学习</h2>
<p>因为最后的预测也就是一个二分类问题，这里的目标函数是对数似然函数：</p>
<p>$$\mathcal{J} = - \sum _{(u,i) \in R^+} {\log {(\tilde{r} _{u,i})}} + \sum _{(u,i) \in R^-} {\log {(1-r _{u,j})}} $$</p>
<p>学就是了</p>
<p>注意这里本身是端到端的模型，也就是说所有的参数更新都是依靠最后这一个对数似然函数的梯度进行的。</p>
<p>整体的模型训练过程：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021074947597.png" style="zoom:80%"/>
<br>
<br>
<hr>
<h2 id="4-数据集实验">4 数据集实验</h2>
<p>具体参考原论文</p>
<p>先来看看数据集情况：</p>
<p>可以看到这里同时使用了不是那么稀疏的数据集和比较稀疏的数据集</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075034703.png" style="zoom:75%"/>
<p>看看效果</p>
<p>可以看到此时的效果较 KGAT 都有明显的提升。</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075109707.png" style="zoom:100%"/>
<blockquote>
<p>一点个人看法：这里某种程度上可以看出它的优势点 / 改进点 → 特别是在第一个数据集上，优于 MI-1M 的数据集比较 dense，此时 KGAT 这种基于在整个 KG 上进行传播的模型容易引入噪声，可以看到 AKGE 在这方面有很大的改善（针对每一个 user-item 都构造了特定的子图来帮助 embedding，而不是在整个 KG 上传播）</p>
</blockquote>
<p>看看 embedding 的预训练方法：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075149066.png" style="zoom:80%"/>
<p>可以看到 TransR 是压倒性的好</p>
<br>
<br>
<br>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>baijnNAN
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://baijn-nan.github.io/2023/10/30/20210210-paper-note-AKGE/" title="AKGE: 基于注意力知识图谱嵌入的个性化推荐系统">https://baijn-nan.github.io/2023/10/30/20210210-paper-note-AKGE/</a>
  </li>
  <li class="post-copyright-license">
      <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" rel="tag"><i class="fa fa-tag"></i> 推荐系统</a>
              <a href="/tags/%E5%9B%BE%E6%A8%A1%E5%9E%8B/" rel="tag"><i class="fa fa-tag"></i> 图模型</a>
          </div>

        

    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-anchor"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">baijnNAN</span>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://baijn-nan.github.io/2023/10/30/20210210-paper-note-AKGE/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
