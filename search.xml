<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Releases</title>
    <url>/2023/10/30/0-update-log/</url>
    <content><![CDATA[<blockquote>
<p>sanatorium construction logs XD</p>
</blockquote>
<span id="more"></span>
<br/>
<hr>
<h2 id="v1-0-20231030">v1.0 - 20231030</h2>
<ul>
<li>init</li>
<li>... and HB to me!</li>
</ul>
]]></content>
      <categories>
        <category>Hans&#39; note</category>
      </categories>
      <tags>
        <tag>疗养院基建</tag>
      </tags>
  </entry>
  <entry>
    <title>RippleNet: 知识图谱+用户偏好传播的推荐系统</title>
    <url>/2023/10/30/20210208-paper-note-RippleNet/</url>
    <content><![CDATA[<p>原文写于 20210208，存档如下</p>
<blockquote>
<p><strong>RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems</strong><br>
Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, Minyi Guo<br>
The 27th ACM International Conference on Information and Knowledge Management (CIKM 2018)</p>
<p>原文(arXiv): <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE4MDMuMDM0Njd2NC5wZGY=">https://arxiv.org/pdf/1803.03467v4.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2h3d2FuZzU1L1JpcHBsZU5ldA==">tensorflow / official<i class="fa fa-external-link-alt"></i></span> -  <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3FpYmluYy9SaXBwbGVOZXQtUHlUb3JjaA==">pytorch<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>	
<p>​</p>
<p>​</p>
<hr>
<h2 id="1-background">1 background</h2>
<p>传统基于协同过滤 (CF) 的推荐系统算法普遍存在 <strong>数据稀疏 (用户 - 物品矩阵)</strong> 和 <strong>冷启动</strong> 两个问题，且往往难以充分利用所提供的数据，如用户社交数据（social networks），用户 / 物品特征（user / item attributes），文本信息（context）</p>
<p>为解决协同过滤带来的问题并将更多的信息（side information）引入推荐系统，利用知识图谱（KG）往往是一个能够较好地综合各类信息的选择。此时将各类实体（entity）标识为点，将实体之间的关系（relationship）标识为边（有向边，比如用户 A 关注 B 需要用有向的关系进行表示），同时考虑到存在多种不同类别的实体（可以是用户可以是物品可以是某一个tag）和不同类别的关系（用户与商品的交互，用户之间的关注关系等），构造异构信息网络，即能够较好地将不同的信息综合进入整体的信息网络。则此时一条信息可以表示为一个三元组：<strong>（头节点H，关系R，尾节点T）</strong></p>
<p>利用知识图谱的推荐系统按实现思路在此分为两类：</p>
<ul>
<li>
<p><strong>基于 embedding 的方法</strong>：也就是利用知识图谱嵌入的方法（KGE）先学习到各个实体 / 关系的嵌入 = 用一定维度的向量来表示各个结点和边，再利用向量表示来进行推荐任务（比如计算某一个物品和用户以前好评的物品的相似度 // 对于两个向量这是很好处理的 // 以决定是否需要将这个物品向用户进行推荐 etc）</p>
<ul>
<li>embedding 的方法分为 Trans 系的方法或基于异构信息网络的方法等，（具体的建议关键字 KGE / <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMTQ0NzAxNDE=">扫盲参考<i class="fa fa-external-link-alt"></i></span>），后续推荐系统的任务基于 CF 等均可。</li>
</ul>
</li>
<li>
<p><strong>基于路径 path 的方法</strong>: 也就是将物品与用户构建为一个巨大的异构图，利用路径进行推荐（比如 meta-path / meta-graph 的方法，构建结束后再利用矩阵分解 + 分解因子机等方法进行推荐任务，<span class="exturl" data-url="aHR0cHM6Ly93d3cubGVpcGhvbmUuY29tL25ld3MvMjAxNzA5L2tlZnZRUGsxRk15YkNsZWIuaHRtbA==">参考<i class="fa fa-external-link-alt"></i></span>）但是注意此时的缺点在于要人工设计 meta-graph / meta-path，繁琐是一方面，有效性或全面性本身有待商榷。</p>
</li>
</ul>
<p>在如上讨论的基础上，本文提出了新的基于知识图谱与用户偏好传播的推荐系统：<strong>RippleNet</strong>，几个优点如下：</p>
<ul>
<li>结合知识图谱表示，能够较好地综合辅助信息（side information）</li>
<li>本身是端到端（end-to-end）的模型，也就是说采用的是<strong>联合训练</strong>的思路，此时embedding的部分和下游推荐系统的部分是统一用最后的损失函数训练的，换言之可以解决（明明最后的下游问题是推荐系统，但是 embedding 部分训练实际上只是一个对尾节点的预测）所带来的不匹配的问题（这也正是依次训练的缺点，<span class="exturl" data-url="aHR0cHM6Ly93d3cubXNyYS5jbi96aC1jbi9uZXdzL2ZlYXR1cmVzL2VtYmVkZGluZy1rbm93bGVkZ2UtZ3JhcGgtaW4tcmVjb21tZW5kYXRpb24tc3lzdGVtLWlp">参考<i class="fa fa-external-link-alt"></i></span>）</li>
<li>采用了偏好传播的思路，能够更好地挖掘用户的潜在兴趣（而不单纯只是讨论用户发生了行为的那些物品，具体通过多跳的方式实现）</li>
<li>本身针对点击预测问题，也就是给定用户和物品，预测用户是否会对物品感兴趣（本身是一个二分类问题，最后输出层应该是 softmax = 对点击概率的预测）</li>
</ul>
<p>​</p>
<p>​</p>
<hr>
<h2 id="2-RippleNet">2 RippleNet</h2>
<h3 id="2-1-整体框架">2.1 整体框架</h3>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231018012238468.png" alt="RippleNet_model_structure"></p>
<p>注意这里还是分为 <strong>embedding</strong> 和 <strong>推荐任务</strong> 两个部分，首先给定一个物品（item）和一个用户（user），物品经过 embedding 后的向量不断地和 KG 中该用户周围 h 跳的物品的 embedding 进行交互运算（注意这里的 H = 也就是具体用到几跳的信息本质上是一个超参数，取值后面会讨论），最后<strong>组成该用户的embedding</strong>（图中灰色的 user embedding)，再和前面的 item embedding 一起计算点击概率</p>
<p>​</p>
<h3 id="2-2-RippleSet">2.2 RippleSet</h3>
<p>定义用户 u 的第 k 跳对应相关的实体集合（直观理解就是从用户出发，向外至少需要经过 k 步所有可以达到的实体的集合），表示为：</p>
<p>$$\mathcal{E}_u^k= \lbrace t | (h,r,t) \in \mathcal{G} \text{  }and\text{  }h \in \mathcal{E_u^{k-1} } \rbrace $$</p>
<p>同理定义用户 u 的第 k 跳对应的 ripple set：</p>
<p>$$\mathcal{S}_u^k = \lbrace (h,r,t)|(h,r,t) \in \mathcal{G} \text{  } and \text{  } h\in \mathcal{E}_u^{k-1} \rbrace \qquad  k = 1,2,...,H$$</p>
<p>​</p>
<h3 id="2-3-偏好传播">2.3 偏好传播</h3>
<p>先再放一遍整体模型的图（摆好摆好：</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231018012238468.png" alt="RippleNet_model_structure"></p>
<p>先看 <strong>embedding 部分</strong>：可以采用 Trans 系列的嵌入方式，也可以直接用语义匹配等，假设此时物品 v 通过 embedding 后得到了 $v \in R^d$ (也就是得到了一个 d 维的向量表示)<br>
考虑用户 u 的一跳的 ripple set，也就是和用户 u 在 KG 上直接相连的物品作为 h 所得到的三元组，记作 $(h_i, r_i, t_i)$，这里的 hi 也就是和 u 直接相连的物品。注意此时三元组内各个元素的大小：$$h_i \in R^d , t_i \in R^d , r_i \in R^{d\times d}$$</p>
<p><strong>再看 Rh 和 softmax 部分</strong>：对于每一个三元组，计算对应的一个概率 $p_i$（实际上可以看作是计算每一个 i 对应的相关性以后归一化得到各个的权重，实质上衡量的是在关系 r 上，我给定的商品$v$ 和用户一跳发生过行为的物品 $h_i$ 之间的相似度）：</p>
<p>$$p_i = softmax(v^{T}R_{i}h_{i}) = \frac{exp(v^TR_ih_i)}{\sum_{(h,r,t) \in S_u^1}{exp(v^TRh)}}$$</p>
<p>注意此时考察的是 <strong>在关系 R 上，我给定的物品$v$ 和 用户$u$本身在 KG 上相连的物品$h_i$的相似度</strong>，也就是说不同关系下的评价是不同的。举例，如果两家餐馆存在（位于同一地区）的关系，另外两家参观存在（属于同一菜系）的关系，我们可以认为后者的关系更能够证明两家餐馆可能是相似的。</p>
<p><strong>接下来是 t 部分</strong>：也就是利用前面得到的每一个 i 的对应权重 $p_i$，计算所有的 $S_u^1$ 中三元组尾结点 $t_i$ 的加权和：$$o_u^1 = \sum_{(h_i, r_i,t_i)\in \mathcal{S}_u^1}{p_it_i}$$</p>
<p>注意这里的 $o_u^1$ 本身是 t 的一个加权和，而 t 是和 用户 u 在 KG 上存在一定相关关系的物品。也就是说，这里的 o 按照 CF 的思路，<strong>可以作为用户 u 的一个表示</strong>：也就是利用 用户 u 相关的产品来表示 u 用户的特征。</p>
<p><strong>重复，得到用户表示 user embedding</strong>： 后续同理，不断重复上面的步骤，一直得到 $o_u^H$，（这里的 H 是一个超参数），则每一个 $o_u^h$ 本身都可以作为用户 u 的一个嵌入，也就是对用户 u 进行 embedding 的结果。此时将得到的 H 个向量作相加：$$u = o_u^1 + o_u^2 + ... + o_u^H$$这里的 u 也就是用户 u 的一个 embedding 表示，对应图上的 user embedding。</p>
<p><strong>最后计算用户和物品 embedding 的相似度，完成推荐</strong>：这里直接采用向量积配合 Sigmoid 函数的形式：</p>
<p>$$\hat{y}_{uv} = \sigma(u^Tv) = \frac{1}{1+exp(-u^Tv)}$$</p>
<p>最后得到的就是该用户 u 对该物品 v 的点击概率</p>
<p>​</p>
<p>​</p>
<hr>
<h2 id="3-训练策略">3 训练策略</h2>
<p>还是用梯度下降的方式进行整体的模型训练</p>
<p>具体损失函数的推导略，原论文讲得还是比较清楚的，根本思想是需要最大化后验概率，同时将 KGE 部分（物品 v 的 embedding 部分）的似然函数包括进去，以实现端到端的训练，具体损失函数如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231018013048938.png" alt="image-20231018013048938"></p>
<p>注意各个符号含义：</p>
<ul>
<li>$V / E$:  所有的物品（item）和实体（entity）的 embedding 矩阵</li>
<li>$R$：关系 r 的 embedding 矩阵（是 dxd 大小的）</li>
<li>$y_{uv}$: 用户 u 和物品 v 到底有没有交互（真实的交互情况，也就是 0/1）</li>
<li>$\lambda_1, \lambda_2$: 防止过拟合用的正则项</li>
</ul>
<p>也就是说，整体的 损失函数 是由三个部分组成的：第一部分是预测结果的交叉熵损失函数（也就是用户到底会不会点击的 0/1 二分类问题）；第二部分是知识图谱本身 embedding 的损失，第三部分是参数正则化损失</p>
<p>得到损失函数后，直接利用梯度下降的方法进行模型训练</p>
<p>整体的模型训练过程如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231018013007536.png" alt="image-20231018013007536"></p>
<p>​</p>
<p>​</p>
<hr>
<h2 id="4-后续讨论">4 后续讨论</h2>
<p>​</p>
<p>这里就不赘述实验结果了，具体参考原文</p>
<p><strong>如何选择适合的超参数 H？</strong></p>
<p>如果跳数过大，一方面整体涉及的实体会过多，导致计算困难；另一方面会出现实体的重合（也就是发散得太远了导致不同的 ripple 之间出现重合的部分），会为整体模型引入噪音。如果过小又不能够更好地挖掘用户的潜在兴趣。论文建议 H 跳数不宜过大（在论文使用的三个数据集中 H = 2，3 就已经可以得到比较好的效果）<br>
具体选择的时候还是可以直接通过实验来选择（每一个 H 都试一试，调参），但是一般都不会过大，并不会带来太大的计算负担</p>
<p><strong>每一跳的时候对涉及的三元组进行采样</strong></p>
<p>注意到如果此时 H 较大，容易涉及到过多的实体；也就是说此时可以对每一跳涉及到的三元组作采样，只使用部分三元组来训练模型，防止带来过大的计算负担。对于论文使用的数据集，每一跳的时候用 16 / 32 的 ripple set 进行模型训练就已经可以得到较好的效果。</p>
<p>​</p>
<p>​</p>
<hr>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>推荐系统</category>
        <category>图模型+推荐</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>图模型</tag>
      </tags>
  </entry>
  <entry>
    <title>KGAT: 融合知识图谱的 CKG 表示 + 图注意力机制的推荐系统</title>
    <url>/2023/10/30/20210209-paper-note-KGAT/</url>
    <content><![CDATA[<p>原文写于 20210209，存档如下</p>
<blockquote>
<p>Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu and Tat-Seng Chua (2019). <strong>KGAT: Knowledge Graph Attention Network for Recommendation</strong>. Paper in ACM DL or Paper in arXiv. In KDD'19, Anchorage, Alaska, USA, August 4-8, 2019.</p>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDc4NTQucGRm">https://arxiv.org/pdf/1905.07854.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3hpYW5nd2FuZzEyMjMva25vd2xlZGdlX2dyYXBoX2F0dGVudGlvbl9uZXR3b3Jr">tensorflow official<i class="fa fa-external-link-alt"></i></span>（tensorflow / official）** <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0x1bmFCbGFjay9LR0FULXB5dG9yY2g=">pytorch<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<p>​</p>
<p>​</p>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<p>传统 CF （协同过滤）算法存在一定的问题：数据稀疏，冷启动，且难以将大量辅助信息（side information）加入利用，例如用户本身特征，物品特征，文本信息，社交网络信息等。</p>
<p>当前的一种利用 side information 的解决方式为将其转化为有监督学习问题：也就是利用 embedding 将物品和用户都利用向量表示，再输入有监督学习的模型中进行处理（比如给定用户和物品，判断用户是否会点击物品的二分类问题，此时的损失函数本身就是交叉熵函数；经过 embedding 以后就是一个简单的有监督问题。）但是这样的处理方式存在一定的问题：其往往先通过 embedding，在下游推荐问题中（也就是有监督问题的处理中）往往考察的是（当前我给出的物品 item 和用户 user 过去发生过交互的物品的相似度），也就是类似于（基于物品的协同过滤）的思路；而难以将（基于用户的协同过滤），也就是寻找到和当前用户相似的用户，再进行推荐的方法进行融合。</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021015348175.png" alt="image-20231021015348175"></p>
<p>比如上图，此时想要为用户 u1 进行推荐，传统 CF 的方法能够帮助找到用户 u4 和 u5，因为他们和 u1 一样都对物品 i1 发生过行为；而利用了 side information 的有监督学习的方法往往能够找到 i2，因为其与用户曾经发生过行为的物品 i1 存在相似之处（都由 e1 导演（和 e1 的关系 r 都是类别 r2），这里的 e1 就是 side information，被利用起来了)。</p>
<p>但是注意，此时图中仍存在没有被利用起来的信息：比如这里的 u2 和 u3 应该是和 u1 相似的用户（因为 i1 和 i2 是相似的物品）但是难以被 CF 或有监督学习的方法捕捉；同理 i3 和 i4 同理也被忽略了：此时 i3 和 i4 同理和 i1 一样都与 e1 存在交互（虽然交互的 r 联系类型不同）。<br>
也就是说上述的方法难以捕捉到一种高阶的关系（high-order relationship），但是捕捉这样的关系同理为整体模型带来了挑战 →</p>
<ul>
<li>更多的实体将被引入模型带来计算的巨大压力，也就是到底选择多少的高阶关系参与进入模型训练的问题；</li>
<li>并不是所有的高阶关系都合适，此时需要模型对这些高阶关系进行一定的筛选 / 给予其不同的权重（不然对于 i3 i4 这种被忽略的情况，似乎直接不对 r 分类就可以解决）。简单来说，需要模型给不同的高阶关系以不同的权重，在后续通过注意力机制的方式解决。</li>
</ul>
<p>解决： 提出 <strong>collaborative knowledge graph (CKG)方法</strong>，一般可以分为两个思路：</p>
<ul>
<li>基于路径的方法（path-based）：本身两个节点之间可能的路径很多，缺点在于需要人工手动设计 meta-path / meta-graph，且并没有针对推荐问题进行优化。</li>
<li>基于规则的方法（regularization-based ），注意并不是直接将高阶关系加入到优化推荐模型中，而是以隐式方法对它们进行编码。此时一方面难以保证确实捕捉到了长距离的关系，另一方面难以保证捕捉到的长距离关系确实是有意义的（也就是难以得到较好的解释性）</li>
</ul>
<p>本文提出一个新的思路：<strong>知识图注意力网络（Knowledge Graph Attention Network (KGAT)）</strong>，具体优势如下：</p>
<ul>
<li>以端到端的方式实现建模，且较好地捕捉整体 KG 中的高阶关系</li>
<li>以显式的方式进行，保障模型的可解释性</li>
<li>采用了注意力机制，自动学习权重</li>
<li>不需要像 meta-path / meta-graph 那样要求手动设计路径，优于基于路径的方法</li>
</ul>
<br/>
<br/>
<hr>
<h2 id="2-任务解释">2 任务解释</h2>
<h3 id="2-1-定义">2.1 定义</h3>
<ul>
<li>
<p><strong>user-item 二部图（User-Item Bipartite Graph）</strong>：也就是用户和物品的历史行为记录，类似于用户-物品矩阵，但是本身以图的形式展示。定义$$\mathcal{G_1} = \lbrace (u, y_{u,i}, i) | u\in U , i\in I\rbrace$$ 这里的 U 和 I 分别表示用户和物品集合，注意此时只是讨论用户和物品之间的关系，仅限于传统 CF 讨论的关系。如果此时存在联系，则对应的 $y_{u,i} = 1$， 否则为 0。</p>
</li>
<li>
<p><strong>知识图谱（Knowledge Graph）</strong> 也就是更为自由的可以由不同的类型的实体组成的整体异构信息网，本身由节点和有向边组成，节点表示实体 entity，边表示关系 relationship。将此时传统 CF 难以利用的辅助信息都融入知识图谱中进行利用（也就是 side information）</p>
</li>
<li>
<p><strong>CKG（Collaborative Knowledge Graph）</strong> 也就是一个二部图和 KG 的结合体。考虑整合关系：$$\mathcal{G} = \lbrace (h,r,t) | h,t \in \epsilon',  r\in \mathcal{R}'\rbrace$$ 注意这里：$\epsilon' = \epsilon \cup \mathcal{U},\text{ } R' = R\cup\lbrace interact\rbrace \text{ }$,  ε 本身是实体 entity 集合， R 是关系集合。直观理解就是上面那个图（搬过来在下面放好放好 ↓）：在下面部分作为普通的知识图谱的同时，特别地将物品集合提出来，针对物品集合再创建 用户 - 物品 矩阵的部分，可以看作是在正常的知识图谱上接了一个 CF 的稀疏矩阵的形式。</p>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021015659273.png" alt="image-20231021015659273"></p>
<p>​</p>
<h3 id="2-2-模型结构（framework）">2.2 模型结构（framework）</h3>
<p><strong>输入：</strong> 构造好的 CKG，记作 $\mathcal{G}$，对应的 CF 的用户-物品矩阵 $\mathcal{G_1}$ 和知识图谱 $\mathcal{G_2}$<br>
<strong>输出：</strong> 能够预测用户 u 点击物品 i 的概率的 prediction function</p>
<p>基本模型结构如下图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021015735207.png" alt="image-20231021015735207"></p>
<p>此时分为三个主要的组成部分：</p>
<ul>
<li><strong>CKG embedding layer</strong>：利用构造的 CKG 结构进行嵌入表示，也就是通过 embedding 得到各个实体的向量表示。</li>
<li><strong>attentive embedding propagation layer</strong>：通过邻居节点递归地传播 embedding来增强表示 → 通过基于知识的注意力来计算权重 → 信息聚合</li>
<li><strong>prediction layer</strong>：也就是预测层，注意这里想要的是用户是否会点击物品，归一化后得到概率。</li>
</ul>
<p>​</p>
<p>​</p>
<hr>
<h2 id="3-模型解释">3 模型解释</h2>
<h3 id="3-1-embedding-layer-嵌入层">3.1 embedding layer 嵌入层</h3>
<p>也就是通过 CKG 得到实体的向量表示。在这里使用的是 Trans 系的 embedding 方式（原论文用到的是 <strong>TransR</strong>）</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021020411312.png" alt="image-20231021020411312"></p>
<p>具体 Trans 系的方法还是用的很多的，这里就只简单提两句，<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMjk5MzA0NA==">具体参考<i class="fa fa-external-link-alt"></i></span></p>
<p>直观来说可以理解为，我构建一个针对三元组的评分标准：$$g(h,r,t) = || W_re_h + e_r - W_re_t||_2^2$$，此时三元组的得分 $g(h,r,t)$ 越低，我认为这个三元组是越可信的（也就是 h 和 t 之间更可能确实存在关系 r）</p>
<p>则此时我通过不断优化下面的损失函数来训练模型得到一个更好的 embedding 表示：</p>
<p>$$\mathcal{L}<em>{KG} = \sum</em>{(h, r, t, t')\in \mathcal{T}}{-\ln{\sigma(g(h,r,t')-g(h, r,t))}}$$</p>
<p>也就是说上述的 loss 越小，说明 sigmoid 函数出来的结果越贴近 1，也就是 sigmoid 内部的结果很大，也就是 我随意选择的 t’ 构成的三元组（也就是随机替换掉一个有效实体构造的实际上无效的三元组 = 噪声)的得分要比正常的三元组的得分高很多，此时分越高就是越不可信的。</p>
<br/>
<h3 id="3-2-Attentive-Embedding-Propagation-Layers">3.2 Attentive Embedding Propagation Layers</h3>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021020513201.png" alt="image-20231021020513201"></p>
<p>这里主要分为三个部分。输入的是 embedding 结束的 u 和 i （实体）</p>
<br/>
<h4 id="3-2-1-信息传播-Information-Propagation">3.2.1 信息传播 - Information Propagation</h4>
<p>考虑：此时如果从 a 指向 b，尾节点的信息同样可以用来丰富头节点 a 的信息，此时利用 ego 网络的思路：<br>
对于一个实体 h，此时用 $N_h$ 来表示所有以 h 为头节点的三元组的集合，也就是节点 h 的 ego 网络：$N_h = \lbrace (h,r,t) | (h,r,t)\in\mathcal{G}\rbrace$</p>
<p>衡量 h 的 ego 网络的 embedding 表达方式，定义：$$e_{N_h} = \sum_{(h,r,t)\in N_h}{\pi(h,r,t) e_t}$$，这里的 $\pi(h,r,t)$ 也就是这个三元组对应的权重，用以控制有多少的尾节点的信息 et 可以通过 r 传递给头节点 h。也就是说（所有以 h 为头节点的三元组的集合 = h 的 ego 网络）的 e（也就是 embedding 表示） 定义为（这些三元组的尾节点的 embedding 表示的线性组合）</p>
<br/>
<h4 id="3-2-2-基于知识的注意力-Knowledge-aware-Attention">3.2.2 基于知识的注意力 - Knowledge-aware Attention</h4>
<p>这里利用基于知识的注意力来计算前面需要的 $\pi(h,r,t)$：$$\pi(h,r,t) = (W_re_t)^Ttanh((W_re_h+e_r))$$ $$\pi(h,r,t) = \frac{exp(\pi(h,r,t))}{\sum_{(h,r',t')\in N_h}{exp(\pi(h,r',t'))}}$$<br>
这里的 $W_r\in R^{d\times d}$，<br>
则如上的计算可以理解为：到底<strong>有多少尾节点 t 的信息可以通过关系 r 传递给头节点 h，主要取决于在关系 r 空间上 h 和 t 的距离</strong>。此时距离越近越容易将 t 的信息传递给 h，在 h 的 ego 网络的 embedding 中得到更大的表示权重。<br>
注意最后还是要 softmax 归一化得到权重。</p>
<br>
<h4 id="3-2-3-信息聚合-Information-Aggregation">3.2.3 信息聚合 - Information Aggregation</h4>
<p>考虑聚合头节点本身的 embedding（也就是 eh）的信息和头节点对应的 ego 网络的 embedding（也就是 $e_{N_h}$） 来重新得到 h 结点的 embedding 表示。此时定义 h 头节点的新的 embedding 表示：$$e_h^{(1)} = f(e_h, e_{N_h})$$，这里的 $f(.)$ 可以使用以下三种可能的聚合器：</p>
<ul>
<li><strong>GCN 聚合</strong>：先将两个向量相加，再进行非线性的转换$$f_{GCN} = LeakyReLU(W(e_h+e_{N_h}))$$</li>
<li><strong>GraphSage 聚合</strong>：将两个表示方法直接先接在一起，再通过非线性的转换：$$f_{GraphSage} = LeakyReLU(W(e_h||e_{N_h}))$$</li>
<li><strong>Bi-Interaction 聚合</strong>：某种程度上是以上两种方式的合体：$$f_{Bi-Interaction} = LeakyReLU(W_1(e_h+e_{N_h}))+LeakyReLU(W_2(e_h \odot e_{N_h} ))$$，注意这里满足 $W_1, W_2 \in R^{d'\times d}$，$\odot$指的是元素一一对应相乘</li>
</ul>
<p>这里采用迭代的方式，也就是重复上面的过程多次：用当前的 $e_h^{(l-1)}$ 代替 eh 来计算新的 $e_h^{(l)}$，也就是满足：$$e_{N_h}^{l-1} = \sum_{(h,r,t)\in N_h} \pi(h,r,t) e_t^{(l-1)}$$ $$e_h^{(l)} = f(e_h^{(l-1)}, e_{N_h}^{(l-1)})$$</p>
<p>注意此时对于 $e_h^{(l-1)}$，就确实是存储了节点 h 的 (l-1) 跳（l-1-hop）的信息的：举个例子，对于计算$e_h^{(1)}$的时候，因为综合了$e_{N_h}^{(0)}$ 的信息，也就是综合了 h 结点的一跳的尾节点 $e_t^{(0)}$ 的信息；但是计算 $e_h^{(2)}$ 的时候，同理会用到 h 结点的一条的尾节点更新后的信息，也就是 $e_t^{(1)}$，但是计算 $e_t^{(1)}$ 的时候，本身会用到 h 的 尾节点 t 的一跳的尾节点的信息，也就是 h 的两跳的尾节点的信息。</p>
<p>通过不断的传递和迭代，此时将结点 h 的多跳的信息都传入了 h 的 embedding 编码中。且通过注意力机制保证了不同信息的不同权重。也就是说，既实现了高阶信息的传递，同时利用注意力机制让模型自动地为不同的高阶信息赋予不同的权重。</p>
<br/>
<h3 id="3-3-预测层（prediction-layer）">3.3 预测层（prediction layer）</h3>
<p>3.2 部分经过 L 次迭代后，此时可以得到每一个 用户 u 和物品 i 的各 L 个不同的表示（包含着不同的 L 跳的信息）</p>
<p>$$\lbrace e_u^{(1)}, ..., e_u^{(L)}\rbrace ;\text{ } \text{ } \text{ } \text{ } \lbrace e_i^{(1)}, ..., e_i^{(L)}\rbrace$$</p>
<p>加上原来的表示 embedding，直接采用 <strong>层聚合机制</strong> 将 L+1 个表示进行拼接，得到每一个 用户 u 和物品 i 的最终表示，记作 $e_u^<em>, e_i^</em>$ $$e_u^* = e_u^{(0)}|| ... || e_u^{(L)}; \text{ } \text{ } \text{ } \text{ } e_i^* = e_i^{(0)}|| ... || e_i^{(L)}$$</p>
<p>也就是说此时既保证了原来结点的特征（也就是 L = 0 的初始的 embedding 的结果）参与了结点的最终表示；同时可以通过调整 L 控制让多远的信息参与进入结点的 embedding 表示，以控制信息传播（propagation）的强度。</p>
<p>预测部分就比较简单了，直接通过 u 和 i 的最终表示的内积来进行预测：$$\hat{y}(u,i) = {e_u^<em>}^T e_i^</em>$$</p>
<br/>
<br/>
<hr>
<h2 id="4-模型学习">4 模型学习</h2>
<p>综上各个部分的损失函数：</p>
<p>$$\mathcal{L}_{KG} = \sum _{(h, r, t, t) \in \mathcal{T}} {- \ln{\sigma(g(h,r,t')-g(h, r,t))}}$$</p>
<p>$$\mathcal{L}_{CF} = \sum _{(u, i,j)\in\mathcal{O}}{-\ln{\sigma(\hat{y}(u,i) - \hat{y}(u,j))}}$$</p>
<p>这里的 i 是确实和 u 发生了交互的物品，j 是没有和 u 发生交互的商品，分别用模型去预测 u 是否会和 i j 发生交互，如果一个模型效果不错，对应 i 的yhat 应该大，而对应 j 的应该小，整体经过 sigmoid 函数后应该贴近 1，取对数后贴近 0 ，此时损失函数的值较小。</p>
<p>整体的损失函数应该就是 <strong>embedding 层的损失函数（也就是 KG 部分的损失函数)+ 推荐部分 CF 的 BPR loss + L2正则化</strong></p>
<p>$$\mathcal{L} _{KGAT} = \mathcal{L} _{KG} + \mathcal{L} _{CF} + \lambda||\Theta||^2_2$$</p>
<p>具体训练的时候还是采用梯度下降的方式。</p>
<p><strong>实验结果</strong>：在所利用的三个数据集上均有提升，具体实验在这里不赘述了，参考原文。</p>
<p>注意和同为（依赖异构网络图的模型）的 RippleNet 相比也是有所提升的；</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021021908777.png" alt="image-20231021021908777"></p>
<br>
<p>最后提一下中间的几个点：</p>
<p><strong>超参数 L 的选取</strong>：也就是到底吸纳多远的信息进入模型训练：</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021021957298.png" alt="image-20231021021957298"></p>
<p>注意并不一定是越远的信息均加入就会越好，原文提及对于 Yelp 数据集这类不是这么稀疏的数据集（densest），如果 L 过大反而容易造成重合+引入更多的噪声。</p>
<blockquote>
<p>It is worthwhile pointing out that KGAT slightly outperforms some baselines in the densest user group (e.g., the &lt; 2057 group of Yelp2018). One possible reason is that the preferences of users with too many interactions are too general to capture. High-order connectivity could introduce more noise into the user preferences, thus leading to the negative effect.</p>
</blockquote>
<br>
<p><strong>多种聚合方式的选取（aggregator）</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021022046385.png" alt="image-20231021022046385"></p>
<p>Bi-Interaction 作为前两种的综合好像效果不错，当然具体实验的时候如果时间允许还是均尝试一下比较好，个人感觉有时候特定数据集上的提升和开销比起来还是性价比太低 ...</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>推荐系统</category>
        <category>图模型+推荐</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>图模型</tag>
      </tags>
  </entry>
  <entry>
    <title>KGCN: 知识图谱 + 图卷积神经网络的推荐系统</title>
    <url>/2023/10/30/20210209-paper-note-KGCN/</url>
    <content><![CDATA[<p>原文写于 20210209，存档如下：</p>
<blockquote>
<p><strong>Knowledge Graph Convolutional Networks for Recommender Systems</strong><br>
Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, Minyi Guo.<br>
In Proceedings of The 2019 Web Conference (WWW 2019)</p>
<p>论文原文（arXiv）：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDQuMTI1NzV2MS5wZGY=">https://arxiv.org/pdf/1904.12575v1.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2h3d2FuZzU1L0tHQ04=">tensorflow / official*<i class="fa fa-external-link-alt"></i></span>； <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3p6YWVib2svS0dDTi1weXRvcmNo">pytorch<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br/>
<br/>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br/>
<p>（先日常嘲协同过滤系算法</p>
<p>协同过滤类的方法（CF-based methods）存在一定的不足之处，例如数据稀疏与冷启动问题。为缓解部分问题，当前大多采用知识图谱（KG）的思路，即将物品属性，用户信息，社交网络关系等多种可以辅助决策的属性（attribute）通过知识图谱的方式结合，以得到能够较好融合 side information 的网络，并同时建立各个实体之间，实体与属性之间的关系。</p>
<p>知识图谱，在此多以异构信息网络的形式，主要有以下几个优点：</p>
<ul>
<li>利用更多的 side information 数据信息以帮助决策，可以更好地发掘用户的潜在兴趣</li>
<li>此时各个实体之间存在多种多样的关系，能够帮助提高用户推荐的多样性（diversity）</li>
<li>推荐结果具有较好的解释性</li>
</ul>
<p>然而将知识图谱与推荐系统本身进行融合的工作本身面临诸多挑战，当前大多使用 embedding 的方法进行融合（KGE），即将各个实体与关系转化为一定维度的向量表示（<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMTQ0NzAxNDE=">主流模型参考这里<i class="fa fa-external-link-alt"></i></span>），但存在训练目标与下游任务不匹配的问题：以 Trans 系算法为例，在进行 embedding 时的训练往往基于头结点，关系与尾结点的运算关系，更适用于单纯基于 KG 的下游任务，而和推荐系统最终推荐 / 点击预测的目标是不匹配的。</p>
<p>同理，基于路径的方法同样存在其问题，人工设计  meta-path 与 meta-graph 往往要求一定的专家建议，且有效性与全面性难以得到保证（<span class="exturl" data-url="aHR0cHM6Ly93d3cubGVpcGhvbmUuY29tL25ld3MvMjAxNzA5L2tlZnZRUGsxRk15YkNsZWIuaHRtbA==">KDD2017 这篇<i class="fa fa-external-link-alt"></i></span> 就是典型的基于路径的方法，注意下游任务往往又是回到矩阵分解 / 分解因子机的）</p>
<p>其他方法，如 RippleNet 同样存在一定的问题（<a href="https://baijn-nan.github.io/2023/10/18/20210208-paper-note-RippleNet/">RippleNet 笔记</a>）：首先其降低了关系 R 的重要性，其直接的 $v^TRh$ 的计算方式难以捕捉关系带来的信息；其次，随着整个 ripple 的范围的扩大，此时加入模型训练的实体会大幅增多，带来巨大的计算负担和冗余。</p>
<p>原文提出一种融合 KG 特点与图卷积神经网络的模型（KGCN），也就是在计算 KG 中某一个给定的 entity 的表示时，将邻居信息与偏差一并结合进来。主要体现出如下的优势：</p>
<ul>
<li>通过邻居信息的综合，可以更好地捕捉局部邻域结构（local proximity structure）并储存在各 entity 中</li>
<li>不同邻居的权重取决于之间的关系和特定的用户 u，可以更好地体现用户的个性化兴趣，以展示 entity 的特点</li>
</ul>
<br>
<br>
<hr>
<h2 id="2-模型解释">2 模型解释</h2>
<br>
<h3 id="2-1-问题叙述">2.1 问题叙述</h3>
<p>本质上还是基于知识图谱的推荐系统，考虑此时已经得到一个构造好的，由 （实体，关系，实体）的三元组组成的知识图谱，记作 $\mathcal{G}$</p>
<p>给定 用户 - 物品矩阵 $Y$（本身是一个稀疏矩阵） 和知识图谱 $\mathcal{G}$ ，判断用户 u 是否会对物品 v 有兴趣，也就是需要学习到一个预测方程（prediction function）：$$\hat{y}_{u,v} = \mathcal{F}(u,v |  \text{ } \Theta,Y,\mathcal{G} )$$，这里的 $\Theta$ 定义为整个模型的学习参数的集合。</p>
<br>
<h3 id="2-2-KGCN-layer">2.2 KGCN layer</h3>
<p><strong>符号定义</strong>：</p>
<ul>
<li>$N(v)$：所有和实体 v 直接相连的（也就是一跳内的）所有实体的集合</li>
<li>$r_{e_i, e_j}$：实体 ei 和 ej 之间的关系</li>
<li>定义函数 $g$：某个函数，可以使得 $R^d \times R^d \to R$（比如内积），用来计算用户 u 和某个关系 r 之间的分数：$$\pi_r^u= g(r,u) $$，这里的 $d$ 是 KG 的 embedding 表示的维度。注意这里的现实含义可以理解为（计算用户对不同的关系的偏好程度），比如某个用户非常在意影片的演员，则他对于 star 这类的 relationship 会有更多的关注，也会更愿意看他喜欢的演员的电影；而对于不是很在意演员的用户，可能对导演 director 之类的 relationship 反而有更多的帮助，这里的 g 函数即用于衡量用户对于不同关系的偏好程度。</li>
</ul>
<p><strong>利用邻居信息的线性组合来刻画结点 v 的邻域信息</strong>，定义为：$$v_{N(v)}^u = \sum_{e\in N(v)}{ \pi_{r_{v,e}}^u e}$$，注意这里的权重 $\pi$ 同时和（v，e 两个结点之间的关系）和（此时对应的用户 u 的特点）有关。这里的权重也就是 v 对应的 N(v) 中的所有实体 e 和关系 r 的 g 函数得分再归一化，计算如下：</p>
<p>$$\pi_{r_{v,e}}^u = \frac{exp(\pi_{r_{v,e}}^u)}{\sum_{e\in N(v)} {exp(\pi_{r_{v,e}}^u)}}$$</p>
<blockquote>
<p>个人感觉这里实际上和 KGAT 的第二部分有点像（<a href="https://baijn-nan.github.io/2023/10/21/20210209-paper-note-KGAT/">KGAT 笔记</a>），在 KGAT 中以 v 结点周围的 N(v) （这里的 N(v) 是所有以 v 为头结点的三元组的集合）中的实体 e （也就是尾节点）的线性组合来表示 v，具体计算各个 e 的权重的时候用的是注意力机制，可以理解为，此时决定权重的是在关系 r 的空间上，要被表示的头结点和尾节点的相似程度。但是这里更多地考虑了当前关系 r 对于用户 u 的重要性（通过上面的得分函数 g）</p>
</blockquote>
<p><strong>控制邻居个数</strong>：注意可能会出现某一个结点 v 存在过多的邻居的情况，会为整体的模型的计算带来巨大的压力。此时定义一个超参数 $K$，对于每一个结点 v，只是选取 K 个邻居进行计算。也就是说，此时 v 的邻域表示记作$v_{S(v)}^u$，且满足：</p>
<p>$$S(v) \to  \lbrace e| e\in N(v)\rbrace \text{ },\text{ }\text{ } |S(v)| = \mathcal{K}$$</p>
<p><strong>将原 embedding 与邻域表示结合起来</strong>：这里提供了几个可以用的聚合器（aggregators）：</p>
<ul>
<li>Sum aggregator:</li>
</ul>
<p>$$agg _{sum} = \sigma(W \cdot (v + v ^u _{S(v)}) + b)$$</p>
<ul>
<li>Concat aggregator:</li>
</ul>
<p>$$agg _{concat} = \sigma(W \cdot concat(v, v ^u _{S(v)}) + b)$$</p>
<ul>
<li>Neighbor aggregator:</li>
</ul>
<p>$$agg _{neighbor} = \sigma(W \cdot v ^u _{S(v)} + b)$$</p>
<p>注意最后一个 neighbor 的聚合器直接就是利用邻域表示来代替 v 结点的表示。</p>
<p><strong>预测层</strong>：得到各个结点的表示后，同理使用 u  v 的内积搭配 sigmoid 函数作点击概率预测，就不再赘述了。</p>
<br/>
<p><strong>summary</strong><br>
下图为上面计算方法的一个示例，这里的 K = 2：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021065929449.png" style="zoom:70%" />
<p>在参数迭代的过程中，比如对于第 h+1 次迭代，就是用第 h 次迭代时得到的实体 e 的 embedding 表示作为初始值，再更新计算当前结点 v 的邻域表示，再和第 h 次得到的 v 的邻域表示进行 aggregate，得到第 h+1 次结点 v 的邻域表示。</p>
<blockquote>
<p>个人感觉这段就是很像 KGAT（<a href="https://baijn-nan.github.io/2023/10/21/20210209-paper-note-KGAT/">KGAT 笔记</a>），KGAT 是每轮参数迭代的时候也是通过多次迭代的方式（以一个超参数控制）融合多跳位置的信息，再扔进去预测；这里同理，比如第 2 次训练的时候，要用到 v 的邻域 e‘ 的第一次训练的结果，而 e’ 的第一次训练的结果是包含了 e’ 的再邻域的，也就是此时将 v 的二跳的 entity 的信息综合到 v 中了，也就是可以实现多跳位置的信息的捕捉。具体看后面模型学习部分的算法流程，通过一个超参数 H 来确定要吸收几跳的信息。也就是将（得到邻域表示 + 原本表示 → 融合）的过程重复 H 遍，再往下一个流程走。</p>
<p>此时个人感觉最大的区别还是在（邻居的权重）的计算方式上，此时是通过一个和关系，和 u 有关的得分函数 g 来计算的；而 KGAT 是通过图注意力机制，考察的是在关系 r 这个空间上，尾节点 t 和头结点 h 之间的相似程度，越相似越容易得到更大的权重，但没有考虑不同 u 对于不同 r 的偏重是不同的。</p>
</blockquote>
<br>
<h3 id="2-3-模型学习">2.3 模型学习</h3>
<p>整体模型的损失函数：</p>
<p>$$\mathcal{L} = \sum _{u \in \mathcal{U}} {(\sum _{v:y _{uv}=1} \mathcal{J}(y _{uv}, \hat{y} _{uv}) - \sum _{i=1} ^{T^u} {E _{v_i \sim P(v_i)} \mathcal{J} (y _{uv_i}, \hat{y}  _{uv_i})})} + \lambda||\mathcal{F}||_2^2$$</p>
<p>注意，在衡量的时候本身一个用户 u 没有发生过行为的物品数量是要远远大于发生过行为的物品数量的，对于类别不平衡问题，这里采用的是负采样。本质上损失函数就是交叉熵函数，前面部分是考虑了负采样的分布的交叉熵损失函数（也就是最后的推荐行为的损失函数 = 预测用户是否会点击 = 二分类问题)，最后带一个 L2 正则项减轻过拟合。</p>
<p><strong>整体模型的迭代过程</strong>：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021070742505.png" style="zoom:80%"/>
<p>这里的 $\mathcal{M}[h]$ 就是不断得到 v 对应的邻域，注意随着迭代的 h 的次数上升，是不断将多跳范围的信息都融合进入了 v 的 embedding 的。</p>
<br/>
<br/>
<hr>
<h2 id="3-测试">3 测试</h2>
<p>实验用的数据集：还是传统的老三样</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021070837756.png" style="zoom:75%"/>
<p>注意这里的 K 都不是很大，一般只要选择一部分的邻居来计算邻域表示本身的效果就不错。同理 H 选取也不大，如果过多跳的信息融入，一方面是计算很大，另一方面会导致重合（也就是每一个 v 都是它为中心的一大块范围的信息的融合，则不同的 v 之间会有趋同的倾向，反而是向模型中引入了噪音)。</p>
<p>这里用 F1 和 AUC 来评价：</p>
<p><img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021070901792.png" alt="image-20231021070901792"></p>
<p>注意这里选择不同的 aggregator （上面给了三种选择) 结果还是存在一定的差异的；</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>推荐系统</category>
        <category>图模型+推荐</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>图模型</tag>
      </tags>
  </entry>
  <entry>
    <title>AKGE: 基于注意力知识图谱嵌入的个性化推荐系统</title>
    <url>/2023/10/30/20210210-paper-note-AKGE/</url>
    <content><![CDATA[<p>原文写于 20210210，存档如下</p>
<p>※ 考虑到本文写作时间，笔记仍基于 v3 版本 → 原论文已于202109 更新 v4</p>
<blockquote>
<p><strong>Attentive knowledge graph embedding for personalized recommendation</strong>. Sha, X. , Sun, Z. , &amp; Zhang, J. . (2019).</p>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MTAuMDgyODgucGRm">https://arxiv.org/pdf/1910.08288.pdf<i class="fa fa-external-link-alt"></i></span> ；本文写作版本 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MTAuMDgyODh2My5wZGY=">https://arxiv.org/pdf/1910.08288v3.pdf<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<p>知识图谱（KG）已经被广泛用于推荐系统中，但是主要思路仍集中于以下两个方向：</p>
<ul>
<li><strong>基于路径提取的思路（path-based methods）</strong>：有的是要求人手动设计 meta-path / meta-graph，有的集中于寻找 user 和 item 之间的线性的路径联系。缺点在于只是利用异构信息网路将 side information 引入了推荐系统，但是本质上 linear path 的信息十分有限，特别是和本文提出的包含高阶关系的子图相比，其不能够较好地挖掘整个 KG 的语义信息和拓扑结构信息。</li>
<li><strong>基于传播的思路（propagation-based methods）</strong>：在整个 KG 上通过传播的方式（propagate）传递用户的偏好，再得到用户的表示 embedding。较为经典的就是 RippleNet（<a href="https://baijn-nan.github.io/2023/10/18/20210208-paper-note-RippleNet/">RippleNet 笔记</a>）和 KGAT（<a href="https://baijn-nan.github.io/2023/10/21/20210209-paper-note-KGAT/">KGAT 笔记</a>），KGCN 类似（<a href="https://baijn-nan.github.io/2023/10/21/20210209-paper-note-KGCN/">KGCN笔记</a>）。虽然一定程度上可以捕捉到语义信息和拓扑结构信息，传播的时候往往出现重合的问题，也就是若将过多跳的信息加入当前 item 的模型计算，反而容易向模型中引入噪音，故其在类似于 yelp 的较为 dense 的数据集上表现不佳（详见 RippleNet 原文作者的解释）。</li>
</ul>
<p>而原文所提出的 <strong>基于注意力知识图谱嵌入的推荐系统（AKGE）</strong> 可以同时关注知识图谱对应的语义信息和拓扑信息：作为端到端训练的神经网络，首先提取包含语义信息的，连接 item 和 user 的高阶关系的子图，再利用注意力机制，基于子图学习用户偏好。</p>
<p>利用高阶子图的好处主要有：</p>
<ul>
<li>涉及了高阶关系的子图本质上可以看作是非线性路径（nonlinear path ）的一个组合（combination），也就是说相较于普通的路径提取，此时可以更好地挖掘整个 KG 的语义信息与拓扑结构信息</li>
<li>本身一个特定高阶子图对应一个（用户 - 物品 pair），也就是说此时可以一定程度上避免直接在整个 KG 上进行传播的算法造成的引入噪音的问题，不同的 use-item interaction 对应的是不同的高阶子图。</li>
</ul>
<p>但是这里同样为整个模型提出了挑战：如何去提取挖掘这样的高阶子图，特别是在 KG 本身的 entity 较多，本身就给整个模型计算带来巨大计算开销的情况下。本文提出 <strong>距离感知抽样策略（distance-aware sampling strategy）</strong> 来帮助构造 item 和 user 之间关系的高阶子图。</p>
<p>另一个问题就是如何利用提取出的高阶子图来进行 encode，这里采用 <strong>图神经网络（ graph neural networks  / GNNs）</strong> 来对子图进行 embedding。子图的非欧几里德结构适合应用 GNN。但是注意到，在 GNN 中所有的邻居都会被平等对待，为了强调不同的权重，在这里同时加入 <strong>注意力机制</strong> 。（这里的思路类似 KGAT ，在 KGAT 中，考察某一个结点的邻域表示时，利用注意力机制赋予不同的邻居不同的权重。）主要包括两个部分：<strong>关系感知的传播（relation-aware propagation）</strong> 和 <strong>注意力聚合（attentive aggregation）</strong></p>
<br>
<br>
<hr>
<h2 id="2-模型解释">2 模型解释</h2>
<br>
<p>整体模型结构如下：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073433663.png" style="zoom:80%"/>
<p>注意此时本质上是输入一个 user 和一个 item（ 比如这里就是给定了 mike 和 k记），首先提取它俩之间的一个子图（不是单纯的 线性path，而是一个子图），再通过这个子图计算 mike 和 k记 的 embedding，再通过正常的 MLP 预测 mike 点击 k 记的概率。</p>
<br>
<br>
<h3 id="2-1-构建子图">2.1 构建子图</h3>
<p>这里不再使用传统的 BFS  / DFS 在整个 KG 上进行搜索，采用效率更高的 <strong>距离感知抽样策略（distance-aware sampling strategy）</strong></p>
<p>对于传统的基于 meta-path 和 meta-graph 的方法，此时需要人工设计路径来使用，本身不全面且有效性有待商榷。</p>
<p>首先得到 KG 中所有实体的一个 embedding （像预训练一样，这里可以用 Trans 系列的方法，原论文用的是 TransR，并且在实验部分证明了 TransR 预训练的效果比较好），则此时可以通过欧几里得距离来衡量两个 entity 之间的距离。同理，对于任意两个 entity 之间的任意一条的 path，可以将 path 上每一步的两个 entity 的距离算出来，再求和作为这个 path 的距离。</p>
<p>对于给定的两个 entity ，仅保留最后的 K 条最短的路径构成二者之间的子图（subgraph）。注意这里和 DFS / BFS 之间的区别在于本身通过距离进行了筛选，而不是单纯地保留了所有的邻居。</p>
<p>得到 K 条最短的 path 后，需要进行 <strong>路径装配（Path Assembling）</strong></p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073548374.png" style="zoom:70%"/>
<p>也就是将得到的 K 条路径装配起来，得到一个子图。同理可以得到其对应的邻接矩阵（adjacency matrix)，注意这里得到的子图是一个无向图，也就是说不再确定 relationship 所指向的方向。</p>
<br>
<br>
<h3 id="2-2-结合注意力机制的图神经网络-AGNN">2.2 结合注意力机制的图神经网络 AGNN</h3>
<p>这里的 AGNN 本质上是对 GGNN 的一个改进（gated graph neural network），AGNN 可以用于异构图上，而 GGNN 需要各个结点的类型相同（也就是同质图）</p>
<p>AGNN 分为以下四个步骤：</p>
<ul>
<li><strong>实体映射（entity projection）</strong>：将实体的 embedding 和实体类型的 embedding 进行结合，得到融合了类型信息的实体的 embedding，即 $h_l^0$</li>
<li><strong>关系感知传播（relation-aware propagation）</strong>：对于第 t 轮迭代，通过实体 l 和它的邻居 e 之间的关系 r，计算 l 的邻居实体 e 的临时隐藏状态 $\hat{h}_k^t$</li>
<li><strong>注意力聚合（attentive aggregation）</strong>：通过注意力机制分配权重，将实体 l 邻居 e 的临时隐藏状态 $\hat{h}_k^t$ 通过某种方式进行聚合。</li>
<li><strong>门控更新（gated update）</strong>：用注意力聚合的结果，经过门控机制来更新实体 l 的 embedding 表示。</li>
</ul>
<br>
<h4 id="2-2-1-实体映射（entity-projection）">2.2.1 实体映射（entity projection）</h4>
<p>此时输入的是构造好的子图 $\mathcal{G}$ 和对应的邻接矩阵 $A$，将图中的各个实体和其对应的类型进行拼接。</p>
<p>这里的 embedding 预训练由 TransR 完成。记实体 entity 的 embedding 是 $e_l$，记实体类型 entity type 的 embedding 为 $e'_l$，则此时直接进行拼接：$$h_l^0 = \hat{e}_l = f(e_l \text{ }\oplus\text{ }e_l'); \text{ }\text{ } f(x) = \sigma(Wx+b)$$ 注意这里的 entity 和 entity type 的 embedding 可以是不同维度的（总之只是作拼接操作），最后得到的 $h_l^0 = \hat{e}_l$ 也就是融合了类型信息的实体的 embedding，这也是和 GNN 不同的地方。</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021073702709.png" style="zoom:100%"/>
<br>
<h4 id="2-2-2-关系感知传播（relation-aware-propagation）">2.2.2 关系感知传播（relation-aware propagation）</h4>
<p>类似传播的思路，此时利用邻域的信息和原本信息的聚合（aggregation）来不断更新实体 e 的 embedding</p>
<p>对于当前的实体 l，考虑它的邻居 k，令 $r_{l,k}$ 表示二者之间的关系，此时通过前面的实体映射已经得到了 t=0 时的实体 ek 的隐藏状态 $h_k^0$</p>
<p>对于一个特定的 t，此时通过 $h_k^t$ 来计算 $\hat{h}_k^t$：$$\hat{h}<em>k^t = g(h_k^t \text{ }\oplus\text{ }r</em>{l,k}), \text{ } e_k\in N_l, \text{ }g(x) = \sigma(Wx + b)$$这里的 $N(l)$ 也就是 $l$ 的所有的邻居实体的集合。</p>
<br>
<h4 id="2-2-3-注意力聚合（attentive-aggregation）">2.2.3 注意力聚合（attentive aggregation）</h4>
<p>此时用注意力机制分配权重，将实体 l 的所有邻居实体 e 的 embedding 进行聚合。得到结合了注意力机制的实体 l 的隐藏状态，记作 $a_l^t$：$$a_l^t = (A_{sl} \odot Q_l^t) [\hat{h}<em>1^{t-1}, ..., \hat{h}</em>{|\mathcal{E}_s|}^{t-1}]^T + b$$这里的 A 是输入的子图对应的邻接矩阵（0-1），A_sl 表示 A 中对应实体 l 的那一行向量，Ql 是注意力权重矩阵（后续会说怎么算），$\mathcal{E}_s$ 是子图中所有结点的集合，$\odot$ 表示哈达玛积。</p>
<p>如果此时实体 e 和当前实体 l 并没有联系，则 Q 注意力权重和邻接矩阵 A 的对应位置都是 0。</p>
<p>现在来看 Q 注意力权重矩阵怎么算，本身用于衡量实体 l 的不同邻居 e 对于实体 l 的重要程度。这里和注意力机制的原理相同，还是利用一个两层的全连接层进行计算，最后通过 softmax 进行归一化。</p>
<p>$$\alpha_{l,k}^t = W_2^T(W_1[\hat{h}_k^{t-1}\oplus h_l^{t-1}]+b_1)+b_2$$</p>
<p>$$q_{l,k}^t = \frac{exp(\alpha_{l,k}^t )}{\sum_{e_j\in N_l}{exp(\alpha_{l,k}^t )}}$$</p>
<p>注意这里衡量邻居 e 对实体 l 的重要程度，用的是经过了 关系感知传播 后的 k 的隐藏状态 $\hat{h}_k^{t-1}$ 和上一个完整步后得到的 $h_l^{t-1}$</p>
<p>则此时可以得到注意力权重矩阵 Q</p>
<br>
<h4 id="2-2-4-门控更新（gated-update）">2.2.4 门控更新（gated update）</h4>
<p>也就是利用上面得到的 $\alpha_l^t$ 经过门控机制来更新实体 l 的embedding，最终得到 $h_l^{t+1}$</p>
<p>先看更新门 z 和重置门 r：</p>
<p>$$z_l^t = \sigma(W_z a_l^t + U_Z h _L ^{t-1})$$</p>
<p>$$r_l^t = \sigma(W_r a_l^t + U_r h_l ^{t-1})$$</p>
<p>这里是同时用到注意力机制后得到的 alpha 和本身在上一步的 embedding h 的，对应 σ 是 sigmoid 函数，W 和 U 是可学习参数；</p>
<p>综上基于当前的 h，不断更新得到新的 h：</p>
<p>$$\tilde{h} _l ^t = tanh(W_h a_l^t + U_h(r_l^t \odot h _l ^{t-1}))$$</p>
<p>$$h_l^t = (1-z_l^t) \odot h_l ^{t-1} + z_l^t \odot \tilde{h} _l ^t$$</p>
<br/>
<h4 id="2-2-5-summary">2.2.5 summary</h4>
<p>再整体看看 AGNN 部分的流程：</p>
<p>本质就是先从前一步提取中的子图中，利用 TransR 先得到的预训练 embedding 和实体类型的结合进行 <strong>实体映射</strong>，以得到初始的隐状态。</p>
<p>再通过 <strong>关系感知传播</strong> 来计算邻居实体的临时隐藏状态，进一步结合注意力机制分配权重的思想，通过 <strong>注意力聚合</strong> 将上一步得到的邻居实体的状态进行加权聚合，最后通过<strong>门控机制</strong>，以完成针对实体 l 的 embedding 的更新。</p>
<p>上述的更新部分（也就是后三个步骤）重复多次，最后得到各个实体的最终 embedding 表示。也就是预训练（实体映射）+ 共 T 次不断更新隐藏状态：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021074609007.png" style="zoom:80%"/>
<p>每一次隐藏状态更新的细节：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075334866.png" alt="image-20231021075334866" style="zoom:80%;" />
<br>
<br>
<h3 id="2-3-预测层">2.3 预测层</h3>
<p>此时通过 MLP prediction 来预测用户是否会对物品进行点击。注意这里和大部分模型不同，没有利用点击预测，而是一个普通的多层感知机。</p>
<p>原论文的激活函数用的是 ReLU，最后输出层是 sigmoid（最后输出点击的概率）</p>
<br>
<br>
<hr>
<h2 id="3-模型学习">3 模型学习</h2>
<p>因为最后的预测也就是一个二分类问题，这里的目标函数是对数似然函数：</p>
<p>$$\mathcal{J} = - \sum _{(u,i) \in R^+} {\log {(\tilde{r} _{u,i})}} + \sum _{(u,i) \in R^-} {\log {(1-r _{u,j})}} $$</p>
<p>学就是了</p>
<p>注意这里本身是端到端的模型，也就是说所有的参数更新都是依靠最后这一个对数似然函数的梯度进行的。</p>
<p>整体的模型训练过程：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021074947597.png" style="zoom:80%"/>
<br>
<br>
<hr>
<h2 id="4-数据集实验">4 数据集实验</h2>
<p>具体参考原论文</p>
<p>先来看看数据集情况：</p>
<p>可以看到这里同时使用了不是那么稀疏的数据集和比较稀疏的数据集</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075034703.png" style="zoom:75%"/>
<p>看看效果</p>
<p>可以看到此时的效果较 KGAT 都有明显的提升。</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075109707.png" style="zoom:100%"/>
<blockquote>
<p>一点个人看法：这里某种程度上可以看出它的优势点 / 改进点 → 特别是在第一个数据集上，优于 MI-1M 的数据集比较 dense，此时 KGAT 这种基于在整个 KG 上进行传播的模型容易引入噪声，可以看到 AKGE 在这方面有很大的改善（针对每一个 user-item 都构造了特定的子图来帮助 embedding，而不是在整个 KG 上传播）</p>
</blockquote>
<p>看看 embedding 的预训练方法：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021075149066.png" style="zoom:80%"/>
<p>可以看到 TransR 是压倒性的好</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>推荐系统</category>
        <category>图模型+推荐</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>图模型</tag>
      </tags>
  </entry>
  <entry>
    <title>RE3QA: 检索+阅读+重新排序：端到端的多文档阅读理解</title>
    <url>/2023/10/30/20210303-paper-note-RE3QA/</url>
    <content><![CDATA[<p>原文写于 20210303，存档如下</p>
<blockquote>
<p>Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li, National University of Defense Technology, Changsha, China (ACL19)   <strong>Retrieve, Read, Rerank: Towards End-to-End Multi-Document Reading Comprehension</strong></p>
<p>原论文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDYuMDQ2MTgucGRm">https://arxiv.org/pdf/1906.04618.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2h1bWluZ2hhbzE2L1JFM1FB">official<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1. introduction</h2>
<p>延续前序研究的思路，考虑通过 <strong>检索（也就是寻找和整体问题相关的段落）+ 阅读（编码，embedding etc）+ 重排序（对可能的答案进行重新排序以生成最终的回答）的方式</strong> 完成机器阅读理解的任务。但是此时存在几个常有的问题：</p>
<ul>
<li>多个模块之间是独立的，独立进行训练，而不是作为一个整体共同解决问题。且此时常常要重复编码的输入，属于不必要的计算开支。</li>
<li>难以将上游问题和下游任务很好地结合，简单理解就是上游的学习的目标往往不是下游任务最终的目标，导致学习目标和最后的目的的分离，或整体模型的训练-测试的分离。</li>
</ul>
<p>原论文提出 $RE^3QA$ 方法，作为一个整体阅读理解问题模型，将检索（context retrieve）+ 阅读（reading comprehension）+ 重新排序（answer reranking） 三个部分进行结合，得到端到端的多文档阅读理解模型。</p>
<p>其本身为多文档的阅读理解任务设计，也就是说不同于传统的单独一个段落的阅读理解，此时需要 retrieve 的行为，即从整个内容中寻找和问题相关的部分，删除大部分对回答问题没有贡献的文本。进一步地从提取出的段落中提取答案，再通过重排序候选答案的方式（reranker）得到最终解答。新方法的优势在于：一方面其本身三个模块共享文本表示（contextualized text representation），另一方面将上游学习任务和下游的部分很好地结合，属于一个端到端的模型。同时由于将文本表示在整个模型的各个部分直接共享，此时不再需要重复的编码的输入，节省时间。</p>
<p>几个前序研究的特点如下表：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021080610230.png" alt="image-20231021080610230" style="zoom: 50%;" />
<br>
<br>
<hr>
<h2 id="2-模型解释">2 模型解释</h2>
<br>
<p>先看一下整个模型的 overview</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021080700504.png" alt="image-20231021080700504" style="zoom: 67%;" />
<p>明确地分为 <strong>三个部分（retrieve + read + rerank）</strong>。输入的为问题和一系列文档（a set of document)</p>
<ul>
<li>首先将输入的文档进行初步的筛选（也就是上图 pruning document 部分）→</li>
<li>再将文本进行处理，得到固定长度的 segment →</li>
<li>继续对得到的 segment 进行编码（这里使用的是预训练的 transformer 模块，对应图中的 T-block 部分）→
<ul>
<li>为保证效率，这里采用提前停止的思路，通过排序评分比较，仅仅将部分文档继续进入下一部分（也就是 early stop 部分）→</li>
</ul>
</li>
<li>通过远程监督的阅读理解器，输出候选答案（图中 read 部分） →</li>
<li>将候选答案重排序，得到最终答案</li>
</ul>
<br>
<br>
<h3 id="2-1-文档筛选（初步修剪，pruning-document）">2.1 文档筛选（初步修剪，pruning document）</h3>
<p>以段落为尺度对文档进行拆解和修剪</p>
<p>考虑此时输入的是文档的集合，经过 TF-IDF 向量化后，保留的是和输入的问题之间余弦cos距离最小的 topK 段落。此时通过保留下来的 k 个段落原本的相对位置，将经过筛选后的段落重新排序为一个新的文档 d，作为修剪后的文档，进入下一步操作。</p>
<p>注意这里的方法很简单，但是作为一个初步筛选是十分有效的（论文表示 95% 以上的无关的段落将被舍弃）</p>
<br>
<h3 id="2-2-文本片段编码（segment-embedding）">2.2 文本片段编码（segment embedding）</h3>
<p>这里不同于传统直接使用 句子 作为划分依据，而是通过 <strong>滑动窗口</strong> 来帮助分割文档。设定滑动窗口长度为 l，跨度 stride 为 r，将上述筛选处理后的文档 d 划分为多个 segment：</p>
<p>$$C = { c_1, ... , c_n }, \text{ }\text{ }\text{ } n = [\frac{L_d-l}{r}]+1$$</p>
<p>再通过预训练的 transformer 对 segment 进行编码。此时输入的为：</p>
<p>$$[\text{ }[CLS]; q; [SEP] ; c ; [SEP]\text{ }]$$</p>
<p>这里和 Transformer 和 bert 是相同的，就不多说了。CLS 是表征 token，标识分类 classification；q 是问题，SEP 作为句子之间区分的标志。注意这里上述的输入中的每一个 xi 都是 单词，type 类别 ，位置 embedding 的逐元素相加。直接放进 Transformer 进行编码，得到 $$h0 \in R^{L_x * D_h}$$，这里的 Lx 是输入的长度，Dh 为 hidden size</p>
<p>注意这里同时使用 $I$ 个 Transformer blocks 进行训练，也就是得到 $I$ 个上述的 embedding 结果。</p>
<br>
<h3 id="2-3-提前停止检索器（-Early-Stopped-Retriever）">2.3 提前停止检索器（ Early-Stopped Retriever）</h3>
<p>这里为了计算效率，采用了 early stop 的方法。</p>
<p>论文表示在部分数据集中即使经过筛选，最后的 segment 也是较多的，如果此时将每一个 segment 都进行完整的 embedding 将损失大量信息。本文 <strong>利用早期汇总的隐藏层表示对各个 segment 进行评分和排序，并仅保留 topK 的 segment 的信息进入后续的模块</strong></p>
<p>也就是说这里本身有 $I$ 个 transformer，但是仅仅使用第 J 个隐藏层的输出来作为对 segment 的表示来计算不同 segment 的得分，（这里的 J &lt; I，也就是使用的是早期层中的表示）<br>
设 $h^J$ 为第 J 个隐藏层的输出，此时通过：</p>
<p>$$\mu = softmax(w_\mu h^J)$$</p>
<p>$$score^r = w_r tanh(W_r \sum _{i=1} ^{L_x} {\mu_ih_i^J})$$</p>
<p>计算各个 segment 的得分。注意这里的  $w_\mu , w_r , W_r$ 都是学习的参数。第一个式子 μ 和 第二个式子的 sum 后部分，可以看作是将整个句子按照重要程度转换得到一个向量，输入第二个式子的 wr tanh 部分进行打分。</p>
<p>得到所有的 segment 的得分后，保留得分最高的 N 个segment 进入下一个模块。其他的信息直接丢弃。注意这里的 N 一般不会太大，可以起到大大简化计算的作用。</p>
<p>注意这一部分训练的目标函数：先将多个 segment 的得分 score r 标准化，通过：</p>
<p>$$\mathcal{L}_I = -\sum _{i=1} ^2 y_i^r \log{(softmax(score^r)_i)}$$</p>
<p>作为目标函数，其中 $y_i^r$ 是 one-hot label，用来标识当前的 segment 中是否存在至少一个正确答案中的文本（需要完全匹配)。</p>
<br>
<h3 id="2-4-远程监督阅读器（Distantly-Supervised-Reader）">2.4 远程监督阅读器（Distantly-Supervised Reader）</h3>
<p>此时的目标是从多个 segment 中得到候选答案。此时通过片段切割的方法实现，也就是 <strong>计算每一个（答案开始位置 s）和 （答案结束位置 e）的得分，将得分相加作为这个候选答案的得分，排序再选择。</strong></p>
<p>这里的 Transformer 共 $I$ 个，考虑最终隐藏层的输出 $h^l$，则此时答案开始部分和结束部分的得分计算为：</p>
<p>$$score^s  = w_s h^l , \text{  } score^e = w_eh^l$$</p>
<p>，进一步假设此时有一个候选答案 $a_i$，$\alpha_i$ 和 $\beta_i$ 分别是它的开始和结束部分对应的 indice，则此时整个答案 $a_i$ 的得分就是 $\alpha_i$ 作为开始的得分和 $\beta_i$ 作为结束的得分的加和：</p>
<p>$$score^{all}<em>{a_i} = score^s</em>{\alpha_i} + score^e_{\beta_i}$$</p>
<p>注意，这里为了标记最后的正确答案在原文中的位置，引入两个label：$y^s , y^e$，用来标记当前是否确实为正确答案的某一个文本片段的开始或结束。原文提到由于可能当前的 segment 本身不含有任何的正确答案文本片段，所以 ys 和 ye 的第一个元素都默认标记为 1</p>
<p>这里用远程监督的方式来训练阅读器，这部分的损失函数：<br>
$$<br>
\begin{align}<br>
\mathcal{L} _{II} &amp;= -\sum _{i=1} ^{L_x} y_i^s \log{(softmax(score^s)_i)} \\<br>
&amp;= -\sum _{i=1} ^{L_x} y_j^e \log{(softmax(score^e)_j)}<br>
\end{align}<br>
$$<br>
<br></p>
<h3 id="2-5-答案重排序（answer-reranker）">2.5 答案重排序（answer reranker）</h3>
<p>此时得到了候选答案，通过 reranker 作重排序，得到最后的答案。</p>
<p>注意前面得到的候选答案中可能会存在重复的正确答案的片段（比如正确答案含有 dog ，可能很多的候选答案中都存在 dog 这个片段），这里采用 <strong>跨度级别非最大抑制（Span-level non-maximum suppression）</strong> 来对部分重复冗余的候选答案进行裁剪；</p>
<p>此时输入候选答案集合 A，候选答案得分集合 S（来自于上一步），选择 A 集合中得分最高的答案 ai，将其加入集合 B 并从集合 A 中删除，同时寻找集合 A 中和答案 ai 存在重叠的答案。不断循环上述步骤，直到集合 A 为空或者集合 B 中的答案个数达到某个上限。</p>
<p>具体 span-level NMS 的算法步骤如下：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021081500190.png" alt="image-20231021081500190" style="zoom:67%;" />
<p>此时将集合 B 作为我的候选答案的集合，进一步对集合 B 中的候选答案进行重排。注意这里的思路和前面的打分比较类似，同理是将候选答案 a 进行某种转化为新的向量，再进行打分：<br>
$$<br>
\eta = softmax(w_{\eta} h ^I _{\alpha_i : \beta_i}) \<br>
score_i ^a = w_a \tanh{(W_a \sum _{j=\alpha_i} ^{\beta_i} \eta _{j-\alpha_i+1} h_j^I)}<br>
$$</p>
<p>为了对这一部分的打分进行训练，引入标签 yhard 和 ysoft：</p>
<ul>
<li>$y_i^{hard}$： 也就是当前答案 ai 和真实答案的精确匹配分数</li>
<li>$y_i^{soft}$：也就是当前答案 ai 和真实答案的模糊匹配 F1 分数</li>
</ul>
<p>如果此时 B 集合中的所有候选答案实际上都不包含正确答案，也就是所有的 element 的 yhard 编码都是 0，则此时用正确答案来替代集合 B 中得分最低的那个候选答案。</p>
<p>定义第三部分的损失函数：<br>
$$<br>
\begin{align}<br>
\mathcal{L} _{III} &amp;= -\sum _{i=1} ^{M^*} y _i ^{hard} \log {(softmax(score^a)_i)} \\<br>
&amp;+ \sum _{i=1} ^{M^*} {|| y_i ^{soft} - \frac{score_i^a}{\sum _{j=1} ^{M^*} score_j^a}||^2}<br>
\end{align}<br>
$$</p>
<p>最终选择重排序（rerank)后得分最高的候选答案作为正确答案。</p>
<br>
<be>
<hr>
<h2 id="3-模型训练">3 模型训练</h2>
<p>注意这里本身是一个端到端的学习方式，则整体的损失函数为前面三个部分的损失函数的加和：<br>
$$<br>
\mathcal{J} = \mathcal{L} _I + \mathcal{L} _{II} + \mathcal{L} _{III}<br>
$$</p>
<p>通过直接计算迭代最后的损失函数来训练整个模型。整体的端到端的训练顺序：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021082022887.png" alt="image-20231021082022887" style="zoom:67%;" />
<br>
<p>来看看最后的模型效果</p>
<p>首先是使用的数据集的情况：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021082156471.png" alt="image-20231021082156471" style="zoom: 55%;" />
<p>最后的训练效果比较：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021082244711.png" alt="image-20231021082244711" style="zoom: 67%;" />
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>CogQA：基于认知图谱的多跳阅读理解</title>
    <url>/2023/10/30/20210304-paper-note-CogQA/</url>
    <content><![CDATA[<p>原文写于 20210304，存档如下；</p>
<p>23 再看到真是有点小怀念 ...</p>
<blockquote>
<p>Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang, Department of Computer Science and Technology, Tsinghua University, DAMO Academy, Alibaba Group<br>
<strong>Cognitive Graph for Multi-Hop Reading Comprehension at Scale</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDU0NjB2Mi5wZGY=">https://arxiv.org/pdf/1905.05460v2.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1RIVURNL0NvZ1FB">official / pytorch<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<p>近期较多模型（例如 bert ）均在一些传统的阅读理解问题上取得了较好的效果，但是本质上同人类表现相比仍存在以下三个需要克服的问题：</p>
<ul>
<li>推理能力：传统阅读理解问题的机制仍限制于从文本中寻找和问题相似的段落并从中提取答案，也就是说只是简答地完成匹配的任务 = <strong>简单的语义匹配</strong>，并不具有推理并解决复杂问题的能力。</li>
<li>解释性：传统用于解决阅读理解问题的模型并不具有较好的<strong>解释性</strong>，即使可以标注出提取答案所依赖的段落，但是难以给出整体问题解决推理的逻辑链条，难以 step by step 地给出问题的解决思路。</li>
<li>拓展性：传统模型大多通过从整个文本中寻找相关的段落进行一定的文本筛选，再集中于一部分的文本进行整体的阅读理解与答案提取，不同于人类的能够针对总体文本作总结并<strong>结合多个部分的信息，再通过推理</strong>给出答案的能力。</li>
</ul>
<br>
<p>在这里先解释一下什么是 <strong>多跳阅读理解问题</strong>：可以直观地理解为需要多次跳转，将不同的信息进行进一步整合才能得到答案的阅读理解问题。举个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021084007009.png" alt="image-20231021084007009" style="zoom: 80%;" />
<p>这个问题本身问的是导演，但是没有给出电影的名字，首先需要后面的信息去推断是哪一部电影，才能进一步去寻找该电影的导演。</p>
<br>
<p>为解决上述问题，基于 dual process theory，我们尝试将以下两个模块进行结合以模拟人类解决问题的思路：</p>
<ul>
<li>系统 1 通过浏览信息，收集和问题可能相关的信息</li>
<li>系统 2 则将得到的信息作进一步的挖掘整合（也就是推理过程）再得到最终的答案</li>
</ul>
<p>这样的结合方式能够较好地解决更为复杂的多跳阅读理解问题。</p>
<p>基于此本文提出 <strong>Cognitive Graph QA (CogQA)</strong> 模型。模型主要由以下两个模块组成：</p>
<ul>
<li>
<p><strong>system1（BERT）</strong>：从文本中提取和问题相关的实体（entity）并得到候选答案，同时对其语义信息进行编码（encode），对应到人脑进行阅读理解的过程也就是记忆部分，人通过浏览阅读材料无意识地记录所有和问题相关的信息。</p>
</li>
<li>
<p><strong>system2（GNN）</strong>：将系统 1 得到的信息进行整合，通过图的方式进行问题的推导，并收集一定的线索（clues）来帮助更好地提取下一跳的信息。对应到人脑也就是推断过程</p>
</li>
</ul>
<p>将上述的两个步骤不断循环重复，直到找到所有可能的候选答案（也就是 system1 不再能够给出新的候选答案的时候）。最后的问题的解答基于 system2 的推断结果，也就是对各个结点更新后的结果（reasoning results）。注意其中<strong>两个系统是互相依赖的</strong></p>
<br>
<br>
<hr>
<h2 id="2-模型解释">2 模型解释</h2>
<p>这里利用 BERT 作为 system1，利用 GNN 作为 system2，整体的模型架构如下图所示：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021084048309.png" alt="image-20231021084048309" style="zoom: 60%;" />
<br>
<h3 id="2-1-System-1-BERT">2.1 System 1  (BERT)</h3>
<p>也就是对整体信息的提取部分</p>
<h4 id="2-1-1-输入">2.1.1 输入</h4>
<p>BERT 部分系统的输入形如：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021084221942.png" alt="image-20231021084221942" style="zoom:80%;" />
<p>这里的 CLS 和 SEP 同传统 BERT 的含义相同，不再赘述。question 为目标问题文本，而 $clues[x ,G]$ 为认知图谱中<strong>结点 x 的前序结点相关的文本中涉及到了 x 的句子</strong>，$Para[x]$ 也就是涉及了结点 x 的 context</p>
<p>这里着重说一下 clues，举个例子，在上面的问题中（再放一遍图）：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021084007009.png" alt="image-20231021084007009" style="zoom: 80%;" />
<p>第一跳通过问题提取到了 quality cafe，第二跳通过 quality cafe 提取到了 old school，则此时 quality cafe 就是 old school 的前序结点。此时关于 old school 的 clues 就是所有 quality cafe 的段落中涉及到了  old school 的句子。注意这里的 clues 是直接输入原句子（raw sentence）的，而没有利用某一个隐藏层的表示之类。（原文提到主要是基于训练效率的考虑)</p>
<p>也就是说，这里的 结点 x 的 clues 可以简单理解为（我之所以从 x 的上一个结点推出 x 的原因 = 涉及 x 的上一个结点的文本中确实提到了 x 的证据）</p>
<p>对于一个实体 x 它的 Para[x] 可能是空的（也就是上一个实体确实提到了实体 x，但是实体 x 的更多信息没有了），则此时 Span Extraction 的部分（也就是下一跳实体和候选答案的提取）不能够继续进行，但是仍能够基于前面的部分计算 Semantics Generation 部分。可以认为此时结点 x 不再作延伸（也就是不再有从 x 出发的新的 ans 结点或者实体结点），但是本身 x 自己的初始化表示还是可以完成的。</p>
<br>
<h4 id="2-1-2-输出">2.1.2 输出</h4>
<p>再来看系统 1 的输出，主要包括两个部分：</p>
<ul>
<li><strong>Span Extraction</strong>：也就是下一跳的实体 + 答案候选</li>
<li><strong>Semantics Generation</strong> : 关于涉及了结点 x 的文本的语义向量</li>
</ul>
<p>先分别来计算候选答案和下一跳的实体。将两个部分分开考虑的主要原因是二者的生成依赖的思路不同：候选答案更多的依赖的还是问题的表述和用词（比如对于一个涉及了 where 的问题，明显 new york 比 2019 更可能是正确答案），而下一跳的实体的选择更多地考虑描述的匹配，也就是某一个实体是否符合某一个问题中的描述，考虑的更多的是句子之间的关系。</p>
<p>这里利用四个指针向量 $S_{hop},  E_{hop}, S_{ans},  E_{ans}$ 来计算该序列的某一个指定位置是下一跳实体 / 答案的开始 / 结束位置的概率。举例，设 T 是 BERT 输出的序列，第 i 个位置是某一个答案的开始位置的概率计算如下：<br>
$$<br>
P ^{start} <em>{ans} [i] = \frac{e ^{S</em>{ans} \cdot T_i}}{\sum <em>j {e ^{S</em>{ans} \cdot T_j}}}<br>
$$</p>
<p>也可以看作是把 BERT 的输出放进一个新的前馈并加上了一个 softmax 层，本质上也就是 bert 的输出表示配合一个分类（也就是分类当前的 i 位置到底是不是开始/结束)的下游任务。     上面的四个指针向量就是学习的目标。</p>
<p>这里只关注 top-K 个概率最大的起始位置，对于每一个起始位置，计算它的结束位置：<br>
$$<br>
end_k = \arg{\max} _{start_k \leqslant j \leqslant start_k + max{L}} {P _{ans} ^{end} [j]}<br>
$$</p>
<p>也就是从起始位置开始，往后 maxL 的范围内，寻找概率最大的可能的结束位置。</p>
<p>注意这样得到的可能还是概率很小（因为寻找的是最大的概率，但是可能即使是概率最大的那个位置，对应的概率本身还是比较小的，比如此时推理还没有完成，我要找的是 director 但是所有 x 对应的 para 都没有 director 相关的信息，则此时可能还不存在答案），则此时将第 0 个位置（对于 BERT 的输入，也就是 [cls]）作为答案起始的概率 P 作为阈值（也就是 $P_{ans}^{start}[0]$），只有大于这个阈值才能被认定为可能的答案起始位置。对于 hop 同理。</p>
<p>得到新的候选答案和下一跳实体以后，对整个认知图谱进行结点扩充。</p>
<p>System 1 <strong>同时还输出 Semantics Generation</strong></p>
<p>考虑到 BERT 输出的序列 T 的第 0 位置的 T0 具有总结整个句子的能力，这里使用 T0 作为 $sem[x, Q, clues]$ 的表示。注意这里并不是使用最后一层输出的 T0，（因为最后一层输出来的 T 用在前面去获取可能的下一跳实体和候选答案了，且本身依据 BERT 自己的特点后面几层的存在意义也就是帮助 span 预测之类的任务），在这里直接使用隐藏层输出的 T0。</p>
<br>
<br/>
<h3 id="2-2-System-2-GNN">2.2 System 2 (GNN)</h3>
<p>系统 2 本质上就是一个图神经网络 GNN，首先根据 System 1 生成的新的下一跳实体和候选答案，在认知图谱上生成新的结点（也就是从实体 x 延伸出去的新的结点）。</p>
<p>同时用上一步生成的 sem 作为结点 x 的初始化表示</p>
<p>注意这里针对 GNN 更新的结点分为两种类型：</p>
<ul>
<li><strong>answer nodes</strong> : 也就是来自于上面预测得到的 answer span</li>
<li><strong>next-hop nodes</strong> : 也就是来自于新找到的下一个 hop 的 entity</li>
</ul>
<p>进一步地，我希望这个知识图谱能够通过推断来更好地更新对 x 的表示（bert 得到的 sem 只是一个初始化表示，这里进一步利用认知图谱的推断来获得一个更加优化的表示，也就是说将该结点与其他结点的关系等信息也加入该结点的表示，而不仅仅是通过预训练的 BERT 给定初始的表示，从而能够更好地展现认知图谱上相近的各个结点之间的互相影响 = 互相充实信息）</p>
<p>更新规则如下：<br>
$$<br>
\Delta = \sigma ((AD ^{-1})^T \sigma(XW_1)) \\<br>
X' = \sigma (XW_2 + \Delta)<br>
$$</p>
<p>这里的 W1 和 W2 是权重矩阵，而 A 是 图的邻接矩阵，D 通过 A 计算：$$D_{jj} = \sum_i A_{ij}$$，从公式的角度来说，$(AD^{-1})^T$ 也就是对 A 的某种归一化（column-normalized)，而 $\Delta$ 也就是 x 的前序结点对 x 的影响的某种综合度量。</p>
<p>注意论文提到，每一时刻都同步更新 x 和 <strong>在整个认知图谱构造完成后多次地（by multiple steps）统一更新 x</strong> 之间的差距是不大的，而肯定地此时后者会更节省时间和计算资源。</p>
<br>
<br>
<h3 id="2-3-预测部分（predictor）">2.3 预测部分（predictor）</h3>
<p>经过系统12 的处理，此时得到的认知图谱中的实体都是和问题以某种逻辑相关的，则此时需要从这些实体中（筛的是 answer span 实体）进行一定的筛选得到答案。</p>
<p>由于这里最后测试的时候使用的是 HotpotQA 数据集，其中的答案大致分为两类：</p>
<ul>
<li>special question：也就是一般的问题，以 what / where / when / who 之类的开头的普通的询问问题</li>
<li>alternative / general question：也就是两个实体比较的问题，此时回答是 yes 或 no，或回答两个实体中的某一个</li>
</ul>
<p>此时原文通过问题的疑问词简单地判断各个问题属于哪一类，再分别用不同的预测 predictor 来处理</p>
<p>对于一般的问题 <strong>special question</strong>，答案大多是抽取式得到的，这部分通过一个两层的全连接神经网络（也就是这里的 $F()$）来实现：<br>
$$<br>
answer = \arg{\max} _{\text{answer node x}} {\mathcal{F} (X [x])}<br>
$$</p>
<p>也就是从所有构造得到的答案结点中选出通过 MLP 后最大的结点作为最后的答案</p>
<p>而对于 <strong>alternative question 和 general question</strong>，本质上都是对两个实体 x 和 y 的比较问题，则此时将两个结点的差值作为输入（$X[x] - X[y]$），再通过 FCN（全连接卷积）来作为一个二分类问题处理（两个问题类型对应两个 FCN）</p>
<br>
<br/>
<h3 id="2-4-模型训练（training）">2.4 模型训练（training）</h3>
<p>注意到这里的 system1 和 system2 之间是互相辅助的，system1 不断地提取可能的答案和下一跳的实体，从而扩充整个认知图谱（answer nodes 和 next-hop nodes）；而 system2 本身通过认知图谱的构建，利用 clues[x] 来扩充和 x 有关的信息而帮助 system1 下一步的寻找（也就是 system1 在找 clues 的时候要回到 GNN 里看看前序结点）</p>
<p>最后需要的是利用 GNN 通过推理增强后的 answer nodes 的表示来从多个 clue 得到的 answer nodes 中选择一个来作为最后的 final answer</p>
<p>整体模型的训练分别针对 system 1 和 system 2 进行：</p>
<br>
<p><strong>Task #1: Span Extraction</strong></p>
<p>考虑到 HotpotQA 数据集的特点，这里已经给出了每一个问题的最佳答案 + 对答案预测有帮助的两个实体，故这里用<strong>有监督的方式</strong>，对于每一个实体 x 相关的 context，也就是 $Para[x]$，此时都有关于 span 的信息：$$D[x,Q] = {(y_1, start_1, end_1), ... , (y_n, start_n, end_n)}$$ 注意这里的 yi 表示不同的真实答案和确实用到的实体，训练用到的真实 start 和 end 是通过模糊匹配得到的（本身给出的 gold answer 本身不一定真的一字不差存在于文本中，实体同理）。则此时我们可以得到真实的 hop span 和 ans span 的位置，如果一个 para 中有 k 个 entity 存在，则此时用于训练的真实标签 → 将每一个可能的 hop 的 start 位置的概率设置为 1/k</p>
<p>将训练集中样本 hop 和 ans 的开始位置记作 $gt_{ans}^{start}$</p>
<p>进一步地，为训练模型学会避开无关的信息，此时事先向构造的认知图谱中<strong>加入无关的结点</strong>，模型应学会不要从这些无关的结点中延伸得到 answer span。注意到前面设置了 0 位置的值为阈值，如果 start 位点的值 &lt; 0 位置的值则此时不设置 span，则对于这些额外加入的无关结点，其正确的 span 的标签也就是一个 <strong>0 位置为 1 的 one-hot 向量</strong></p>
<p>这里用交叉熵损失函数：<br>
$$<br>
\mathcal{L} _{ans} ^{start} = -\sum _i {gt ^{start} _{ans} [i] \cdot \log {P _{ans} ^{start} [i]}}<br>
$$</p>
<br>
<p><strong>Task #2: Answer Node Prediction</strong></p>
<p>前面的训练是为了判断模型是否能够真的提取出真实答案所在的实体，而 predict 部分也就是判断模型能否从所有和问题 Q 相关的结点（也就是所有的认知图谱中的 answer span 实体）中提取出最后的真实答案。</p>
<p>这里为每一个问题构造一个 sample：根据训练集构造一个真的的认知网络，其中包括所有真实需要的推理路径，记作 gold-only graph</p>
<p>向这个 graph 中添加负样本，包括在上一个 task1 中用到的无关的实体结点，再从所有结点中随机选择一个，随机从这个结点对应的 para 中随机抽取一段作为答案结点，同理生成两个错误的答案结点加入 gold-only graph，再在这个东西上训练 answer prediction 的部分</p>
<p>用交叉熵函数作为损失函数：<br>
$$<br>
\mathcal{L} = -\log {(softmax(\mathcal{F}(X)) [ans])}<br>
$$</p>
<p>这个损失函数一方面可以优化预测的 F 和 system2，注意到此时 system1 生成的 sem 也作为初始值参与了最终 X 的值，也就是说对该损失函数的优化某种程度上也可以帮助对 system1 也就是 BERT 进行精调。</p>
<br>
<br>
<hr>
<h2 id="3-实验部分">3 实验部分</h2>
<br>
<h3 id="3-1-数据集介绍">3.1 数据集介绍</h3>
<p>先简单说一下数据集，这里用到的是  <strong>HotpotQA</strong></p>
<p>考虑到传统的机器阅读理解数据集存在一定的缺陷，将模型的能力仅仅限制在了简单的模式匹配，而不是真正的理解问题与顺次推理，这里为展现 CogQA 模型在需要一定的理解推理能力的更为复杂的多跳阅读理解问题上的优势，采用 HotpotQA 来进行测试</p>
<p>HotpotQA 提出的挑战主要包括：1）此时要求模型能够有从多个文档中综合收集信息的能力，也就是多个来源筛选可能的支撑性事实 2）不再是简单的模式匹配，本身需要模型自己具有一定的推理能力，真正理解问题并结合信息进行推理，得到最后答案</p>
<p>基本包括：</p>
<ul>
<li><code>id</code> 唯一标识</li>
<li><code>question</code> 问题字符串</li>
<li><code>answer</code> 正确答案字符串，注意这里的答案是有多种类别的，有些答案只是 yes / no 类型，仅仅从文中进行 answer span 的划分不能完全满足需要</li>
<li><code>supporting_fact</code> 包含所有解答这个问题所需要的事实推理证据，每一个证据包括 title 所在段落标题和 sent_id = 具体提供了事实证据的句子的下标，也就是说这里给出的证据是精确到句子的</li>
<li><code>context</code> 参考段落内容</li>
</ul>
<br>
<p>HotpotQA 同时为挑战者提供了两个子任务：</p>
<ul>
<li>预测答案</li>
<li>标记出答案的事实证据，也就是考察模型的可解释性</li>
</ul>
<br>
<h3 id="3-2-实验结果">3.2 实验结果</h3>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021085453537.png" alt="image-20231021085453537" style="zoom:60%;" />
<p>这里的 CogQA-sys1 是只利用 system1 抽取实体但是不作推理直接预测，Cog-onlyQ 是 system1 只利用问题信息而不涉及前序结点对应的 clues</p>
<p>原文给了一些具体的例子，可以看出此时 CogQA 确实以某种推导的思路得到了最后的正确答案，而不仅仅通过语义匹配误打误撞</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021085225964.png" alt="image-20231021085225964" style="zoom: 60%;" />
<p>看看在不同问题类型上的不同效果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021085254195.png" alt="image-20231021085254195" style="zoom: 67%;" />
<p>注意在 alternative（是否问题 yes/no）和 general （比较类）问题上的提升比较小，可以理解，此时 CogQA 并没有作整体的答案类型判断，只是选取 answer span 作为最后的结果，所以在是否问题上表现不会特别好；而比较类问题本身就是当前多跳阅读理解的难点之一，后续几个模型好像突破也不是非常大</p>
<br>
<br>
<hr>
<p>最后一点个人想法：</p>
<ul>
<li>
<p>觉得实体抽取部分的思路比较独特，对于大多数同样沿用 BERT 类模型 + GNN 思路的模型，大多直接将句子中出现的所有实体直接作下一跳的结点（引入大量噪声且图变得很大）或者直接用文段中出现的超链接作为指引下一跳的方式（太依赖于 HotpotQA 数据集本身的特点，有点任务导向的意味在里面 / 说的就是 [HGN][1]），这一点本身也在原文的实验部分体现，CogQA 的 <strong>通过不断循环而寻找所有可能的下一跳实体并根据阈值决定何时结束</strong> 的思路确实是简单但有效的（[EPAr][2]也有点类似于它的思路）</p>
</li>
<li>
<p>实体抽取部分比较有趣的还有 MUPPET，类似于利用迭代的方式抽取，并依据当前已经抽取得到的信息来不断更新检索向量，类似于不断自我引导的一种抽取方式（<strong>待补充</strong>）</p>
</li>
<li>
<p>训练的部分用到的 <strong>引入错误实体</strong> 来帮助训练的思路，感觉比较少看到 BERT系+GNN 的模型用这样的思路帮助训练的（自己对这块还不熟悉...）但是训练部分（特别是 task2 的 answer predictor 部分）的负样本的生成是不是有点随意（</p>
</li>
<li>
<p>注意到 CogQA 在一些 yes / no 和比较类问题上表现不佳</p>
<ul>
<li>这里是怎么提取到切实的需要比较的两个实体 x 和 y 的原文没有说明（后续看源码 <strong>待补充</strong>）。</li>
<li>当前看到的大多使用 HotpotQA 的模型都较难在这两个问题类型上取得较好的突破（[HGN][1] 也是在比较类问题上效果不好），期待更多的解决方案？</li>
</ul>
</li>
<li>
<p>将<strong>常识知识加入</strong>帮助模型推理（HGN 实验发现对于 HotpotQA 数据集中的部分问题错答的主要原因是缺乏一定的常识知识，可以利用 [KT-NET][4] 的思路将常识信息和 bert 的编码作一定程度的融合？）</p>
</li>
</ul>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>HDEGraph: 基于异构图推理实现跨文档的多跳阅读理解</title>
    <url>/2023/10/30/20210305-paper-note-HDEGraph/</url>
    <content><![CDATA[<p>原文写于 20210305，存档如下</p>
<blockquote>
<p>Ming Tu, Guangtao Wang, Jing Huang, Yun Tang, Xiaodong He, Bowen Zhou<br>
JD AI Research;  <strong>Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDUuMDczNzR2Mi5wZGY=">https://arxiv.org/pdf/1905.07374v2.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0pELUFJLVJlc2VhcmNoLVNpbGljb24tVmFsbGV5L0hERUdyYXBo">official<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br>
<p>多跳阅读理解问题，特别是跨文档的多跳阅读理解问题为当前的机器阅读理解学习模型提出了新的挑战。</p>
<p>在这里首先解释以下什么是多跳阅读理解问题，这里借用 CogQA 论文里的例子来展示。（<a href="https://baijn-nan.github.io/2023/10/21/20210304-paper-note-CogQA/">CogQA 笔记</a>）</p>
<p><strong>多跳阅读理解问题</strong> 可以直观地理解为需要多次跳转，将不同的信息进行进一步整合才能得到答案的阅读理解问题。举个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021084007009.png" alt="image-20231021084007009" style="zoom: 80%;" />
<p>这个问题本身问的是导演，但是没有给出电影的名字，首先需要后面的信息去推断是哪一部电影，才能进一步去寻找该电影的导演。直观理解就是此时需要从多个文档中收集信息并经过一定的多重推导过程才能得到最后答案。</p>
<br>
<p>针对多跳理解问题，当前效果比较好的模型主要集中于以下两种模式：</p>
<ul>
<li>对多个文档内容进行初步筛选，再把筛选出来的内容进行拼接为一个新的文档，再利用前面的针对单文档的模型来进行阅读理解和实体的提取。</li>
<li>使用 GNN 方法，也就是先通过阅读理解将内容作为 GNN 的新的实体加入网络，再通过 GNN 的结点结构完成下游任务（CogQA 就是类似的思路）</li>
</ul>
<p>本文使用的还是受到基于 GNN 方法的启发，将异构信息网络的思路引入机器阅读理解模型，提出一种新类型的图模型：<strong>异构文档-实体网络（Heterogeneous Document-Entity (HDE) graph）</strong></p>
<p>HDE graph 的特点主要有：</p>
<ul>
<li>此时允许图上的不同结点属于不同的类型（也就是异构信息网络的特点），也就是说此时的图模型可以充分表示不同级别不同类型的信息。这里采用三种类型的结点：候选答案（candidate）+ 文档（document）+ 实体（entity）</li>
<li>受到 CFC 的启发，这里用到 co-attention 和 self-attention 来学习初始结点的表示</li>
<li>此时将结点之间不同的关系引入图模型（也就是异构信息网络中能够表示不同结点关系的不同类型的边），以更好地完成依赖图模型推断过程。</li>
</ul>
<br>
<br>
<hr>
<h2 id="2-模型解释">2 模型解释</h2>
<p>先看看整体模型的架构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022035202426.png" alt="image-20231022035202426" style="zoom: 67%;" />
<p>整体模型大致可以分为三个部分：</p>
<ul>
<li><strong>上下文编码 context encoding</strong>：也就是通过 co-attention 和 self-attention 进行上下文编码，以初始化整个 HDE graph</li>
<li><strong>基于异构图的推断过程 Reasoning over HDE graph</strong>：通过基于 GNN 的传播算法在整个构造的 HDE graph 上进行推断过程，从而得到各个结点的最终表示</li>
<li><strong>针对候选答案打分  score accumulation</strong>：也就是利用此时 HDE graph 的结点表示对候选答案进行打分，筛选出最终答案</li>
</ul>
<br>
<br>
<h3 id="2-1-上下文编码-context-encoding">2.1 上下文编码 context encoding</h3>
<p>类似于异构图的思路，实际上就是对一个 query 的预测任务：给定 (s , r , ?) 则此时的目标就是通过给定的 s 实体，r 关系和背景资料支持文档 $S_q$ ，从所有可能的候选答案 $C_q$ 中选择得到最后的结果。</p>
<p>上下文编码部分分为四个模块，如下图所示：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022035534992.png" alt="image-20231022035534992" style="zoom:90%;" />
<ul>
<li><strong>GRU 编码（蓝色部分）</strong></li>
<li><strong>实体提取 Entity extraction（橙色部分）</strong></li>
<li><strong>计算实体间 co-attention（绿色部分）</strong></li>
<li><strong>自注意力池化 self-attentive pooling（红色部分）</strong></li>
</ul>
<p>这里作者提了一下本文基于 CFC 的优化的点：</p>
<ul>
<li>比 CFC 更多地计算了 query 和 候选答案 之间的 co-attention</li>
<li>用到了自注意力机制来综合 co-attention 给出的信息</li>
</ul>
<br/>
<h4 id="2-1-1-GRU-编码（蓝色部分）">2.1.1 GRU 编码（蓝色部分）</h4>
<p>首先使用 GRU 分别对 query， 文档 和 候选答案 进行编码，最后输出 query 的编码 $H_q \in R^{l_q*h}$，文档的编码 $H_s^i \in R^{l_s^i * h}$（这里的 i 表示是第 i 个参考文档），候选答案的编码 $H_c^j \in R^{l_c^j * h}$，这里的 h 是  RNN 最后输出的维度</p>
<br>
<h4 id="2-1-2-实体提取-Entity-extraction（橙色部分）">2.1.2 实体提取 Entity extraction（橙色部分）</h4>
<p>还是前面导演的那个例子，此时从电影的信息需要先抽取出电影名字这个实体，才能进一步地得到最后导演名字作为答案。</p>
<p>注意这里将同时利用问题 query 和 可能的候选答案 来进行实体抽取。使用 simple exact match strategy 的方法（具体来自于 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE4MDguMDk5MjA=">De Cal 2018 等人<i class="fa fa-external-link-alt"></i></span>）得到 query 和 候选答案中各个 mention 的开始和结束位置，此时的各个 mention 将被处理为一个实体。得到实体后将上述 GRU 部分编码结果的实体对应部分提取出来，作为其初始表示。</p>
<br>
<h4 id="2-1-3-计算实体间-co-attention（绿色部分）">2.1.3 计算实体间 co-attention（绿色部分）</h4>
<p>co-attention 的作用为使得 query 和 document 之间的信息能够互相融合加强</p>
<p>首先通过 GRU 输出的表示，计算 query 和第 i 个文档之间的相似度矩阵（similarity matrix）：<br>
$$<br>
A _{qs} ^i = H _s ^i (H _q)^T \in \mathbb{R} ^{l^i_s \times l_q}<br>
$$</p>
<p>这里的 A 用于展示当前 query 中某个词和 文档 中任意某个词之间的两两相关程度</p>
<p>进一步计算注意力文本，也就是 query 和 document 经过注意力机制后的上下文表示（attention context）<br>
$$<br>
C_q = softmax(A^T _{qs}) H_s \in \mathbb{R} ^{l_q \times h} \\<br>
C_s = softmax(A _{qs}) H_q \in \mathbb{R} ^{l_s \times h}<br>
$$</p>
<p>注意这里用 softmax 做了一个标准化的操作（column-wise normalization)</p>
<p>再进一步利用一个双向 GRU 对得到的 Cs （也就是文档部分）进行进一步的编码：<br>
$$<br>
D_s = f(softmax(A _{qs}) C_q) \in \mathbb{R} ^{l_s \times h}<br>
$$<br>
此时将得到的 Ds 和 Cq 进行按列的拼接，得到最后的 co-attention 表示：<br>
$$<br>
S _{ca} = [C_s ; D_s] \in \mathbb{R} ^{l_s \times 2h}<br>
$$<br>
注意这里最后得到的 $S _{ca}$ 也就是经过了 query 的信息融合和注意力机制的支持文档的信息。将上述的步骤同样用于 query 和 候选答案之间，query 和实体之间，得到 $C _{ca}$ 和 $E _{ca}$，注意这里总共是计算了三组 co-attention</p>
<br>
<h4 id="2-1-4-自注意力池化-self-attentive-pooling（红色部分）">2.1.4 自注意力池化 self-attentive pooling（红色部分）</h4>
<p>也就是将一个有序的上下文表示通过自注意力模块得到一个固定维度的 + 非有序的特征向量，中间经过的是注意力筛选。直观理解就是，此时通过为 co-attention 得到的结果（一个序列）中的每一个词语进行打分，将得分标准化后作为权重经过池化操作，最终得到一个能够体现输入序列的综合信息的特征向量。</p>
<p>给定 co-attention 的输出 $S_ {ca}$，计算如下：<br>
$$<br>
a_s = softmax(MLP(S _{ca})) \in \mathbb{R} ^{l_s \times 1} \\<br>
s _{sa} = a_s^T S _{ca} \in \mathbb{R} ^{1 \times 2h}<br>
$$</p>
<p>这里的 MLP 是一个两层的 MLP 配上 tanh 作为激活函数，最终得到经过了自注意力池化的表示 $S_{sa}$</p>
<p>同理，考虑 co-attention 的其他两个输出 $C_{ca}$ 和 $E_{ca}$，经过同样的操作得到 $C_{sa}$ 和 $E_{sa}$</p>
<br>
<br>
<h3 id="2-2-基于异构图的推断-Reasoning-over-HDE-graph">2.2 基于异构图的推断 Reasoning over HDE graph</h3>
<p>这里将 HDE graph 表示为 $G = {V , E}$，V 是结点的表示，而 E 为连接结点的边，此时的结点分为三种：文档，候选答案，抽取出的实体</p>
<p>此时利用 HDE graph 可以表示更多粒度下的信息：</p>
<ul>
<li>document 结点可以表示融合了 query 信息的（因为经过了 co-attention）文档层面的整体信息</li>
<li>候选答案结点表示经过了 query 信息融合的候选答案中相关的信息</li>
<li>entity 结点表示了通过 query 信息后的，某文档中的或者 query 本身中存在的可能会对推理有帮助作用的 subject</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022040213330.png" alt="image-20231022040213330" style="zoom:50%;" />
<br>
<h4 id="2-2-1-HDE-graph-构建">2.2.1 HDE graph 构建</h4>
<p>通过上一步最后的自注意力池化后，此时可以得到各个结点的初始表示。此时进一步地定义它们之间的相关关系，也就是边的关系：</p>
<ul>
<li>文档 + 候选答案：只要该候选答案出现在该文档中至少一次则存在这类的边连接两个实体</li>
<li>文档 + 实体：标识该实体是从该文档中提取出来的</li>
<li>候选答案 + 实体：标识该实体本身是该候选答案中的一个 mention</li>
<li>实体 + 实体：标识两个实体是从同一个文档中提取出来的</li>
<li>实体 + 实体：如果两个实体是来自同一个 query 或同一个候选答案的 mention，但不是来自于同一个文档（和上一个边类型区别开）</li>
<li>候选答案 + 候选答案 ：所有的候选答案之间两两相连</li>
<li>实体 + 实体：其他的不满足上述条件的两个实体之间相连</li>
</ul>
<p>至此，我们将整个 HDE graph 构造完毕</p>
<br>
<h4 id="2-2-2-信息传递-Message-passing">2.2.2 信息传递 Message passing</h4>
<p>本文选用的是 GNC 的消息传递策略，分为 聚合（aggregation）和 组合（combination）两个部分。</p>
<br>
<p><strong>聚合</strong> 也就是将邻居结点的信息进行聚集整合：<br>
$$<br>
z_i^k = \sum _{r\in R} {\frac {1} {N_i^r}} \sum _{j \in N_i^r} {f_r(h_j^k)}<br>
$$</p>
<p>这里的 R 是所有的边的种类的集合，$N_i^r$ 是所有以边类别 r 与结点 i 相连的邻居结点的集合，$|N_i^r|$ 表示这样的结点集合中结点的个数，$h_j^k$ 是结点 j 在第 k 层的表示，$f_r$ 本身是一个转换，可以用 MLP 实现，最后得到的是 $z_i^k$ ，也就是结点 i 的第 k 层表示。</p>
<p>个人觉得这里的思路和 RippleNet 是类似的（<a href="https://baijn-nan.github.io/2023/10/18/20210208-paper-note-RippleNet/">RippleNet 笔记</a>），比如此时相连的模式是 1-2-3，则第一层都只有自己的信息，而第二层时，二层的结点 2 的信息中包含了结点 3 的信息，而 三层的结点 1 的信息中包含了二层的结点 2 的信息，自然也就包含了结点 3 的信息，经过多层的传播，此时实现了多跳的信息融合。</p>
<p><strong>组合</strong>也就是将结点 i 的原始表示信息和它的多层信息进行综合：<br>
$$<br>
u_i^k = f_s(h_i^k) + z_i^k<br>
$$</p>
<p>这里的 $h_i^k$ 也就是结点 i 的原始第 k 层表示信息，而 $f_s$ 同理可以由 MLP 实现</p>
<p>注意到在层数比较大的时候，  GNN 很容易遇到平滑问题（smoothing problem ），也就是整个 GNN 中的结点都很相似而没有区分度。为了避免平滑，此时在组合的部分加入一种门机制（gating mechanism）：<br>
$$<br>
g_i^k = sigmoid(f_g([u_i^k ; h_i^k])) \\<br>
h_i ^{k+1} = \tanh (u_i^k) \odot g_i^k + h_i^k \odot (1-g_i^k)<br>
$$</p>
<p>这里的 $f_g$ 同理通过 MLP 实现（注意原文用的是单层的 MLP），注意这里实际上是通过 $g_i^k$​ 来控制到底多少信息来自于结点 i 的原本表示 h ，又多少信息来自 HDE graph 推断后的表示 u</p>
<p>经过 k 次处理（K 次信息传递），得到每一个结点的最终表示 $h_i^{k}$</p>
<br>
<br>
<hr>
<h3 id="2-3-候选答案打分-Score-accumulation">2.3 候选答案打分  Score accumulation</h3>
<p>得到图最终的表示后，可以基于图中的表示来为候选答案进行打分以提取最终答案<br>
$$<br>
a = f_C (H^C) + ACC _{max} (f_E (H^E))<br>
$$</p>
<p>这里的 $H^C$ 是所有候选答案结点的表示，C 是候选答案个数，$H^E$ 是所有和候选答案相连的实体结点的表示，$ACC_{max}$ 取和某一个候选答案结点相连的所有的实体结点中的最高分，这里的 $f_E, f_C$ 都是通过两层的 MLP 实现的，激活函数还是用的 $\tanh$，最后的输出 $a \in R^{C*1}$ 则表示此时 C 个候选答案各自为正确答案的概率（得分经过标准化)</p>
<p>这里得到最后的 a，则利用 a 和真实的答案标签 → 交叉熵损失函数来进行整体模型的训练</p>
<br>
<br>
<hr>
<h2 id="3-实验部分">3 实验部分</h2>
<p>原文使用的是 WikiHop 数据集 进行最后的模型测试。（43K 训练集，2.5K 测试集）</p>
<p>注意这里作者依据经验将整个 query 分为了 relation 和 subject 两类，预训练的词向量用的是 300-dimensional GLoVe 和 100-dimensional character n-gram embeddings</p>
<p>原文里作者还搞了一个结合了 15 个模型的集成学习（用了不同的超参数和随机数种子），融合的时候用的是简单的多数投票策略</p>
<p>现在来看看结果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022040839926.png" alt="image-20231022040839926" style="zoom:80%;" />
<p>为了考察整个模型的不同部分的贡献，原文还做了消融实验：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022040914997.png" alt="image-20231022040914997" style="zoom:80%;" />
<p>可以看出此时 HDE graph 的贡献还是蛮显著的，也就是说花这么大力气又是提取实体构建 HDE graph 又是在上面做多跳信息融合确实也算有效果 ...</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>KT-NET: 结合丰富知识增强预训练语言表达以辅助机器阅读理解</title>
    <url>/2023/10/30/20210306-paper-note-KTNET/</url>
    <content><![CDATA[<p>原文写于 20210306，存档如下</p>
<blockquote>
<p>An Yang, Quan Wang, Jing Liu, Kai Liu, Yajuan Lyu, Hua Wu, Qiaoqiao She and Sujian Li; Key Laboratory of Computational Linguistics, Peking University, MOE, China, Baidu Inc., Beijing, China;  <strong>Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYWNsd2ViLm9yZy9hbnRob2xvZ3kvUDE5LTEyMjYucGRm">https://www.aclweb.org/anthology/P19-1226.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cDovL2dpdGh1Yi5jb20vcGFkZGxlcGFkZGxlL21vZGVscy90cmVlL2RldmVsb3AvUGFkZGxlTkxQL1Jlc2VhcmNoL0FDTDIwMTktS1RORVQ=">official<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<p>原文写于</p>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br>
<h3 id="1-1-background">1.1 background</h3>
<p>当前机器阅读理解问题已经取得了较好的成效，而这些模型往往依赖于预训练模型：也就是首先在众多未标记文本上进行预训练，以先得到能够较好地捕捉复杂语言的模型，再进一步地利用于机器阅读理解问题中。在这里 BERT 模型凭借多层 transformer 在众多预训练模型中表现较好。</p>
<p>但是注意到，在众多阅读理解问题中，整体模型不止需要 <strong>捕捉语义信息 / 理解语言的能力</strong> ，同时还需要 <strong>足够的背景知识以支持问题推理</strong></p>
<p>举个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022041544251.png" alt="image-20231022041544251" style="zoom:80%;" />
<p>注意上面的例子，此时得到正确的答案同时需要背景知识来自 wordnet 的背景知识：</p>
<ul>
<li>Trump is the person who leads US</li>
<li>sanctions has a common hypernym with ban</li>
</ul>
<p>这些知识在文本中没有体现，可能是由于此时的文本默认大家已经有了类似的常识，人类在进行测试的时候可以轻松过地依赖这样的常识给出答案。但是机器没有，它只能依赖给定的文本去作推断（因为此时的预训练模型有的仅仅是 → 捕捉当前给定的文本的语义信息 的能力），这也就是 BERT 难以得到正确答案的原因</p>
<p>也就是说，此时不止需要整体的关于文本的阅读 + 问题的理解 = 对给定的文本的语义的捕捉，如果此时机器模型可以像人一样，在做阅读理解题目的时候同时已经具有了一定的自己的相关的背景知识，则理应可以在各类阅读理解问题上取得更好的表现（个人理解就类似 gre RC的 assumption 题，选项都是在阅读文本 + 题目中没有出现的内容，此时需要的是个人的背景知识配合对文本的逻辑理解来判断哪一些选项确实是文本作者默认已经成立的前提假设）</p>
<p>则此时需要考虑的问题转化为了 → 如何进一步改进机器阅读理解所应用的预训练模型？使得它在学习如何捕捉已经给定文本的语义信息的同时（也就是阅读给定文本 + 阅读题目并提取信息的能力，BERT 已经较好地实现了）也像人一样具备了一定的和当前文章+问题相关的基础背景知识（本文的目标）</p>
<br>
<h3 id="1-2-this-work">1.2 this work</h3>
<p>综上，为解决上述问题并进一步提升机器阅读理解模型的效果，本文从其所依赖的预训练模型部分入手，提出了同时融合了语言-知识融合模型（KT-NET；Knowledge and Text fusion NET），作为较之 BERT 更为优秀的预训练模型以辅助后续的机器阅读理解问题的解决。</p>
<p>这里提供给预训练模型学习用的外部知识包括：</p>
<ul>
<li><strong>WordNet</strong>：包含了词汇之间的词义关系信息（ lexical relations between words）</li>
<li><strong>NELL</strong>：包含了多种实体信息（ beliefs about entities）</li>
</ul>
<p>注意在具体进行融合的时候采用的不是符号事实（symbolic facts），而是 <strong>KB embedding</strong> 的方法（具体在 2 会解释），优势如下：</p>
<ul>
<li>此时融合的知识不只是和阅读文本相关，同时和整体 KB 的信息是相关的</li>
<li>可以更好地帮助同时融入多个 KB 进入预训练模型</li>
</ul>
<br>
<br>
<hr>
<h2 id="2-Knowledge-Embedding-and-Retrieval-针对背景知识的嵌入和检索">2  Knowledge Embedding and Retrieval 针对背景知识的嵌入和检索</h2>
<p>可以看到前面重点提到了一个东西叫 KB embedding，这里来解释一下它的相关内容</p>
<p>注意到此时我们存在两个需求，一个是前面提到的 <strong>KB embedding</strong>，也就是说需要先将背景知识 encode 为 KB embedding  的形式，再尝试将它融入到预训练模型中；另一个是 <strong>Retrieval 检索</strong>，注意到针对每一个文章 + 问题，我不能让机器为了这一个题学完世界上所有的背景知识，也就是我需要检索什么样的背景知识和当前问题+文章是相关的，在让预训练模型去学习</p>
<br>
<h3 id="2-1-KB-embedding-背景知识嵌入">2.1 KB embedding 背景知识嵌入</h3>
<p>KB embedding 可以理解为背景知识的 embedding，这里用到了两个 KB（也就是背景知识集合）： WordNet 和 NELL，每一个 KB 都储存为三元组的形式：$$ (subject, relation, object)$$这里 WordNet 主要是词义方面的（比如 organism, hypernym of, animal）而 NELL 是实体关系方面的（比如 Coca Cola, headquartered in, Atlanta）或者对于一个概念的解释（比如 Coca Cola, is a, company）</p>
<p>但是这里并不是直接采用符号事实的方式进行信息的存储，而是考虑将它们编码到一个连续的向量空间中，也就是说给定一个三元组 $(s, r, o)$，此时我想要学习到 subject s，relation r，object o 三者的向量表示。这样做的好处是我就可以在向量空间内来衡量这个三元组的可信度（validity）</p>
<p>这里的具体实现采用的是 BILINEAR model（也就是双线性模型），利用双线性函数来进行 validity 的衡量：$$f(s,r,o) = s^Tdiag(r)o$$，注意这里的 s，r，o 分别为 subject，relation，object 的向量表示且 $\in R^{d_2}$，$diag(r)$ 是一个对角线由 r 给出的对角矩阵</p>
<p>认为已经存储在 KB 中的三元组是具有高 validity 的，则此时可以利用 KB 提供的信息学到三元组的向量表示，也就是最终通过学习可以得到两个 KB 中各个实体 + 关系的各自的向量表示</p>
<p>这里的具体训练原文参考的是<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE0MTIuNjU3NXY0LnBkZg==">Yang et al., 2015<i class="fa fa-external-link-alt"></i></span> 的思路，该论文的<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rcmVzZWFyY2gvUHlUb3JjaC1CaWdHcmFwaA==">源码戳这里<i class="fa fa-external-link-alt"></i></span>（pytorch）</p>
<br>
<h3 id="2-2-KB-Concepts-Retrieval-背景知识概念检索">2.2 KB Concepts Retrieval 背景知识概念检索</h3>
<p>此时还需要对所有两个 KB 提供的背景知识进行检索，以筛选出解决当前文章 + 问题的阅读理解问题所需要的背景知识再让预训练模型去学</p>
<p><strong>针对 WordNet</strong>，此时给定问题和文章段落，将其中词汇的同义词集作为概念返回。也就是说这里只是用到了 WordNet 的同义词集，WordNet 本身就是标识各个词之间语义关系的 KB</p>
<p><strong>针对 KEEL</strong>，需要首先从给定的问题和文章段落中识别实体（因为 KEEL 是指定实体之间关系的 KB），再直接用字符串匹配的方式去 KEEL  中找这些实体，并把所有和这些实体相关的其他实体也提取出来。注意这里提取到的 subword 也会共享检索结果，比如只是提取到了 coca，但是它本身可以作为 coca-cola 的一部分从 KEEL 中链接到 company 这个实体并提取出来。</p>
<p>经过上述的步骤，我们可以从两个 KB 中提取出和文章和问题相关的 concept 的集合。再结合前面对 KB 中所有 concept 的向量编码，此时可以得到一个候选 concept 的向量集合且每一个向量 $\in R^{d_2}$</p>
<p>这个候选集在后续模型中会用到。</p>
<br>
<br>
<hr>
<h2 id="3-Our-Approach-模型介绍">3  Our Approach 模型介绍</h2>
<br>
<h3 id="3-1-overview">3.1 overview</h3>
<p>先来看看整体模型：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022041717379.png" alt="image-20231022041717379" style="zoom:80%;" />
<p>此时的整体目标还是给定带有 m 个 token 的文本 P，n 个 token 的问题 Q，最后输出文本中的某一段连续序列（contiguous span in the passage）作为答案 A</p>
<p>整体主要包括四个模块：</p>
<ul>
<li><strong>BERT encoding layer → 基于 BERT  的编码</strong>：和前序研究相同，利用预训练的 BERT 模型来捕捉阅读文本 + 问题的上下文语义信息并进行 embedding</li>
<li><strong>knowledge integration layer → 背景知识整合</strong>：也就是从背景知识记忆中选择相关的可能需要的背景知识（以 KB embedding 的形式）并和 BERT embedding 的结果进行整合</li>
<li><strong>self-matching layer → 自注意力层</strong>：利用自注意力机制进一步处理此时得到的 embedding，进一步地丰富学到的背景知识和 BERT 对文本+问题编码之间的交互</li>
<li><strong>output layer → 最终预测</strong>：注意这里目标同理是给出答案，也就是预测答案部分在文章 passage 中的开始位置和结束位置 = 预测文章各个部分作为开始部分的概率和结束部分的概率。</li>
</ul>
<br>
<h3 id="3-2-BERT-Encoding-Layer（利用-BERT-进行-embedding）">3.2 BERT Encoding Layer（利用 BERT 进行 embedding）</h3>
<p>也就是正常的 BERT，就不多说了。这里给定文章 P 和问题 Q，注意输入的形式：</p>
<p>$$S = [<CLS> , Q, <SEP>,P , <SEP>]$$</p>
<p>，也就是将问题和文章都贴在一起扔进去了，CLS 和 SEP 也就是传统 BERT 模型中的作用，注意这里本文并没有用到 CLS（只是为了满足 BERT 保持了这个形式）</p>
<p>针对 S 中的每一个 token，此时的输入实际上使用的是 token, position, segment 编码，也就是：$$h_i^0 = s_i^{tok}+s_i^{pos}+s_i^{seg}$$，注意对于 Q 中的所有的词使用的都是同一个 segment。</p>
<p>这里 BERT 的输出记作 ${h_i^L}_{i=1}^{m+n+3}$，m 是 P 中的 token 数目，n 是 Q 中的 token 数目，共 L 层</p>
<br>
<h3 id="3-3-Knowledge-Integration-Layer（上下文信息与KB信息整合）">3.3 Knowledge Integration Layer（上下文信息与KB信息整合）</h3>
<p>也就是将 KB 中可能相关的背景信息和 BERT 得到的 embedding 进行整合，也就是整个模型的核心部分。可以直观理解为将 BERT 最后结果的 $h_i^L$ 作为输入，利用 KB  背景信息对其所含信息进行进一步的丰富，使得此时的预训练模型不仅能够充分掌握问题和文章提供的上下文信息（BERT 部分），同时能够像人一样具有一定的相关背景知识（KB 部分）</p>
<p>给定 BERT 对于每一个 token $s_i$ 的表示，也就是 $h_i^L \in R^{d_1}$，和一个来自 KB 的候选集 $C(s_i)$，利用注意力机制从候选集中选取相关的 KB concept。这里的 KB 候选集 $C(s_i)$ 也就是前面 2 部分提取出的 KB 的 concept 候选集，标识着所有可能和问题和文章相关的 concept，且此时得到的是 KB embedding 的标识，也就是一个向量集合。</p>
<p>当然前面的 KB 候选集筛选只是初筛，还会存在大量实际上对我们解决问题并没有帮助的 concept，这里进一步使用注意力机制来处理：令 $c_j$ 标识 KB 候选集 $C(s_i)$ 中的 concept，$c_j \in R^{d_2}$，文章+问题的输入 S 中的任意一个 token 记作 $s_i$，利用双线性测量来判断 cj 和 si 之间的相关度 → 也就是计算注意力权重：<br>
$$<br>
\alpha _{ij} \varpropto exp(c_j^T Wh_i^L)<br>
$$</p>
<p>这里的 W 是模型学习参数。注意到这里的 si 和 cj 可能是全不相关的，这里引入一个知识定点（knowledge sentinel）$\bar{c} \in R^{d_2}$，这里用相同的方法先计算知识定点的注意力权重：<br>
$$<br>
\beta_i \varpropto exp(\bar{c} ^T Wh_i^L)<br>
$$</p>
<p>则最后汇总得到一个经过了和 token si 相关的注意力权重加权整合的 KB 信息表示：<br>
$$<br>
k_i = \sum _j a _{ij} c _j + \beta _i \bar{c}<br>
$$</p>
<p>这里满足 $\sum_j a_{ij} + \beta_i = 1$</p>
<p>注意 $k_i$ 的特点：由于引入了知识定点 $\bar{c}$，此时即使 si 和 某一个 ci 是完全不相关的，ci 的一部分信息也可以作为 $\bar{c}$ 的一部分以某种权重对 $s_i$ 的信息进行补充，也就是前面优势部分所提到的：<strong>不只融合和阅读文本相关的知识，同时某种程度上融合了和整个 KB 的信息相关的知识</strong></p>
<p>这里的 $k_i$ 可以视为一个知识状态向量（knowledge state vector），也就是针对当前的 token si ，通过（结合了 si 特点的注意力机制）分配权重，为 token $s_i$ 准备的它所相关的 KB 信息</p>
<p>最后将 $k_i$ 表示和 BERT 输出的 $s_i$ 表示连起来，输出：</p>
<p>$$u_i = [h_i^L, k_i] \in R^{d_1+d_2}$$</p>
<br>
<br>
<h3 id="3-4-Self-Matching-Layer-（进一步丰富上下文知识和背景知识的交互）">3.4 Self-Matching Layer （进一步丰富上下文知识和背景知识的交互）</h3>
<br>
<p>这里将上一步得到的 ui 作为输入，目标是通过自注意力机制进一步地融合上下文信息（BERT 的输出，也就是 hi）和相关的背景知识信息（前面的 KB 经过注意力权重后的表示 ki）</p>
<p>这里分别针对  <strong>直接交互</strong> 和 <strong>间接交互</strong> 进行处理。</p>
<br>
<h4 id="3-4-1-直接交互">3.4.1 直接交互</h4>
<p>给定两个 token：si 和 sj（也就是它们对应的 ui 和 uj 表示），用 trilinear 函数来计算它们之间的相似度：<br>
$$<br>
r _{ij} = w^T [u_i, u_j , u_i \odot u_j]<br>
$$</p>
<p>这里的 ⊙ 是 element-wise 的乘法，w 是学习参数，最后得到的是一个相似度矩阵 R，每一个元素 rij 衡量的就是 ui 和 uj 之间的相似度</p>
<p>进一步地对 R 逐行作 softmax 运算，得到自注意力的权重矩阵 A</p>
<p>再对每一个 token si （表示为 ui）计算自注意力向量 vi：<br>
$$<br>
a_ij = \frac {exp(r _{ij})} {\sum _j {exp(r _{ij})}} \\<br>
v_i = \sum _j {a _{ij} u_j}<br>
$$</p>
<p>直观理解就是此时通过自注意力，将不同 ui 之间的信息同样做了融合</p>
<br>
<h4 id="3-4-2-间接交互">3.4.2 间接交互</h4>
<p>考虑到 si 之间可能还存在多跳的交互，比如 si 和 sj 之间通过 sk 进行交互</p>
<p>这里直接对原始注意力矩阵作自乘的运算，也就是：<br>
$$<br>
\bar {A} = A^2 \\<br>
\bar {v}_i = \sum_j \bar{a} _{ij} u_j<br>
$$</p>
<p>这里的 $\bar{a}_{ij}$ 也就是 $\bar{A}$ 中的元素，这里的 $\bar{v}_i$ 表示了所有的 sj 如何通过可能的中间 token sk 与我们的 si 进行了交互。</p>
<br>
<p>最后得到本层的输出：</p>
<p>$$o_i = [u_i, v_i, u_i-v_i,u_i \odot v_i, \bar{v}_i, u_i - \bar{v}_i] \in R^{6d_1+6d_2}$$</p>
<br>
<br>
<h3 id="3-5-Output-Layer-（输出层）">3.5 Output Layer （输出层）</h3>
<br>
<p>这里还是遵循 BERT 的思路并采用线性输出层配一个简单的 softmax，来预测答案的边界（也就是每一个位置是答案开始 / 结束边界的概率）</p>
<p>任意一个 token  si 是开始或结束边界的概率为：<br>
$$<br>
\begin{align}<br>
p_i^1 = \frac {exp(w_1^T o_i)} {\sum _j {exp(w_1^T o_j)}} \\<br>
p_i^2 = \frac {exp(w_2^T o_i)} {\sum _j {exp(w_2^T o_j)}}<br>
\end{align}<br>
$$</p>
<p>这里的 oi 就是上一层最后的输出，w1 和 w2 是学习参数，注意最后的答案选择：</p>
<ul>
<li>满足 开始位置 a &lt; 结束位置 b</li>
<li>且此时对应的 $p_a^1 p_b^1$ 是最大的</li>
</ul>
<p>最后的训练函数是利用真实开始结束位置来计算的对数似然函数：<br>
$$<br>
\mathcal{L} = - \frac{1}{N} \sum^N _{j=1} {(\log{p^1 _{y_j^1}} + \log {p^2 _{y_j^2}})}<br>
$$</p>
<br>
<br>
<hr>
<h2 id="4-experiment-实验部分">4 experiment 实验部分</h2>
<p>先来看看数据集：原文用的是  <code>ReCoRD</code> 和 <code>SQuAD1.1</code></p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022042529388.png" alt="image-20231022042529388" style="zoom:67%;" />
<p>再看看在两个数据集上分别的效果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022042602756.png" alt="image-20231022042602756" style="zoom:80%;" />
<p>可以看到这里还是有一定的提升的。注意 SQuAD 的部分， KT-NET - NETwordnet 的反而是效果最好的，可以认为 SQuAD 是一个不那么地依赖外部信息来作答的数据集 (...)</p>
<p>同时作者做了一个和 BERT 的直接的对比（case study 部分）</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022042641082.png" alt="image-20231022042641082" style="zoom: 60%;" />
<p>这里热力图展示的是问题和文章之间的相关性，主要是一列一列地看：可以了解到此时 KT-NET 可以帮助每一个问题中的词汇对不同的文章有更加不同的相关性，也就是每一列内的元素相关性差距拉大，表明相对于 BERT 确实是有一定提升的。</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>attention：浅谈注意力机制与自注意力模型（附键值对注意力 + 多头注意力）</title>
    <url>/2023/10/30/20210309-summary-attention/</url>
    <content><![CDATA[<p>原文写于 20210309，存档如下</p>
<blockquote>
<p>划水休息两天不看论文了 ~ 来重新复习一下基础qaq</p>
<p>以下讲解参考大名鼎鼎的 nndl <span class="exturl" data-url="aHR0cHM6Ly9ubmRsLmdpdGh1Yi5pby8=">邱锡鹏 《神经网络与深度学习》<i class="fa fa-external-link-alt"></i></span> 部分内容（详见第八章，注意力与外部记忆）是对于不太行的初学者也比较友好的一本，当然不能要求一本书既全面又深入，阅读过程还是建议自己去更多地从别的渠道了解细节内容，但个人觉得即使是顺着通读亦对关于深度学习的整体框架搭建蛮有帮助的qaq</p>
<p>同时参考了这篇综述：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDQuMDI4NzQucGRm">An Attentive Survey of Attention Models<i class="fa fa-external-link-alt"></i></span>，具体这篇论文的阅读笔记也蛮多的就不找时间再写了（<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20veWRjb2RlL3AvMTEwNDA4MTEuaHRtbA==">https://www.cnblogs.com/ydcode/p/11040811.html<i class="fa fa-external-link-alt"></i></span> 这篇就写的很好~）</p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-background">1 background</h2>
<br>
<p>注意力机制本身想要解决的问题很简单，就是算不动了</p>
<p>在整体模型越来越庞大的情况下，大家明显地觉得运算开始吃力了，这样的问题下直观的思想就是考虑如何<strong>按重要性更好地将手头有限的计算资源进行分配</strong>，以保证更多的计算资源可以分配到确实重要的内容上，而尽量不要太浪费在所谓不重要的内容上。人脑面对海量信息往往利用 <strong>注意力</strong> 将部分不重要的信息略去而只关注于重要的信息，这里将注意力分为两种：</p>
<ul>
<li>
<p>自上而下的有意识的注意力，也就是 <strong>聚焦式注意力（Focus Attention）</strong>：此时的注意力是确定地有一个目的的，也就是会主动地去关注某一个特定的对象，本身依赖目的，存在预定的任务（举例阅读理解问题，此时给定问题以后，关注的只是和问题相似的文本段落对象，对其他对象可以少输入或不输入模型以节约计算资源）</p>
</li>
<li>
<p>自下而上的无意识的注意力，也就是 <strong>基于显著性的注意力（Saliency Based Attention）</strong>：也就是说此时并没有预先根据某种目的或任务关注某一个特定的对象，而是单纯地当某一个对象表现出某种特征的时候，比如某一个对象值很大时则转而主动关注这样的对象（举例 max 池化，门控机制）</p>
</li>
</ul>
<p>这里来一个 <code>nndl</code> 中的例子：</p>
<blockquote>
<p>一个和注意力有关的例子是鸡尾酒会效应。当一个人在吵闹的鸡尾酒会上和朋友聊天时，尽管周围噪音干扰很多，他还是可以听到朋友的谈话内容，而忽略其他人的声音（聚焦式注意力）。同时，如果背景声中有重要的词（比如他的名字），他会马上注意到（显著性注意力）</p>
</blockquote>
<br>
<p>从这个思路出发，当前已经进行了较多的尝试，比如最简单的 <strong>池化层</strong>：最大池化本身也就是选择一个范围内的最大值保存下来，直观理解可以认为就是只关注了值最大的部分而将其他部分内容舍去，以更好地将更宝贵的计算资源放在可能重要的部分</p>
<p>进一步地从当前主流的 encode - decode （编码器 - 解码器）模型来讨论一下 <strong>注意力机制</strong> 的优势。传统的编码器解码器模型存在以下两个很大的问题：</p>
<ul>
<li>编码器需要把输入的信息<strong>转化为一个定长的序列</strong>才能给到解码器进行处理，也就意味着此时容易造成信息的损失（非要塞到一个定长的序列里）</li>
<li>此时输入的序列和最后解码器的输出本身<strong>难以作对齐</strong>，以翻译问题来说，我输入 Tom chase Jerry，此时由于编码器 RNN 是平等地对每一个词来进行编码操作的，也就是说我最后翻译出的 汤姆 本身是依赖了相同权重的 Tom 、chase、 Jerry 这三个词。但明显 汤姆 的翻译应该更多地依赖 Tom 才对，这就造成了本身输入序列和输出序列的不对齐。这同样也影响了本身神经网络的解释性问题，将所有输入的东西都以相同的权重看待将导致难以解释我最后的结果到底是依赖什么得出的。</li>
</ul>
<p>而 <strong>注意力机制</strong>，也就是尝试 <strong>在输入的信息上计算注意力分布</strong> → 从而得到 <strong>不同输入信息对应当前任务的重要性分布 = 不同的权重</strong> → 再根据不同的重要性，也就是不同的权重 <strong>计算当前输入信息的加权平均</strong>，以实现（对重要的，和任务相关的信息赋予更高的权重，而将不重要的信息基本忽略或赋予较低的权重）以更有效率地利用计算资源</p>
<br>
<br>
<hr>
<h2 id="2-整体架构">2 整体架构</h2>
<br>
<p><strong>注意力机制</strong> 本身只是一种思想，并不依赖某一个特定的模型（虽然总是依赖编码器 - 解码器的模型来解释它），可以简单地总结为两个步骤：</p>
<ul>
<li><strong>在给定的信息上计算注意力分布</strong>（也就是判断什么信息重要，什么信息不重要，分别赋予不同的权重）</li>
<li><strong>根据注意力分布来计算所有输入信息的加权平均</strong></li>
</ul>
<br>
<h3 id="2-1-计算注意力分布">2.1 计算注意力分布</h3>
<p>简化问题，考虑此时输入 N 个向量 ：$[x_1, ... , x_N]$，我想要从中选出对于我的目标而言比较重要的信息，需要引入我的目标任务的表示，称为 <strong>查询向量（query vector）</strong>，则此时问题可以转换为考察 <strong>输入的不同内容和查询向量之间的相关度</strong>，一个简单的思路就是通过一个 <strong>注意力打分函数</strong> 对不同内容进行打分，赋予与我当前任务比较相关的部分更大的权重，再直接地通过一个 <code>softmax</code> 层得到分布，也就是输入信息的不同部分的权重。</p>
<p>这里的注意力打分函数主要有以下几种：</p>
<ul>
<li>加性模型：$s(x,q) = v^T tanh(Wx + Uq)$</li>
<li>点积模型：$s(x,q) = x^Tq$</li>
<li>缩放点积模型：$s(x,q) = \frac{x^Tq}{\sqrt{D}}$</li>
<li>双线性模型：$s(x,q) = x^TWq$</li>
</ul>
<p>上面的 W U 都是可以学习的参数，D是输入向量的维度</p>
<p>比较常用的就是 <strong>点积模型</strong>，简单 + 有效</p>
<p>通过每一个输入 x 和 q 计算得分函数 → 再通过 <code>softmax</code> 层，则第 i 个输入 xi 对应的权重也就是 $$softmax(s(x,q))$$</p>
<br>
<br>
<h3 id="2-2-计算加权分布">2.2 计算加权分布</h3>
<p>这里分为两种方式：</p>
<ul>
<li>
<p><strong>软性注意力机制</strong>：也就是每一个输入的按各自权重的加权平均</p>
<p>$$att(X,q) = \sum_{n=1}^N a_n x_n$$</p>
</li>
<li>
<p><strong>硬性注意力机制</strong>：也就是只关注某一个向量，此时用某一个向量来直接代替所有输入的信息，而将其他的信息都一概忽略</p>
<p>主要有以下两种形式：</p>
<ul>
<li>
<p>选择权重最大的向量</p>
</li>
<li>
<p>在注意力分布上进行随机采样（也就是权重越大的向量越容易被采到）</p>
</li>
</ul>
</li>
</ul>
<p>但是注意到，这里硬性注意力机制的最大的问题就是它本身是不可导的（比如选择权重最大实际上就是通过了一个 max 函数），也就是说这一步会导致无法使用反向传播算法，一般只能依赖强化学习进行训练</p>
<br>
<h3 id="2-3-在-encode-decode-中的应用举例">2.3 在 encode-decode 中的应用举例</h3>
<p>在这里举个例子，考虑 seq2seq 框架下的 编码器 - 解码器模型中注意力机制最简单的应用方式</p>
<p>整体如下，此时左边是正常的编码器-解码器模型，右边是加入了注意力模块的 （图片参考 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDQuMDI4NzQucGRm">ref Fig.2<i class="fa fa-external-link-alt"></i></span>）</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022043935192.png" alt="image-20231022043935192" style="zoom: 50%;" />
<p>经过 encode，此时输入 x1 x2 x3 对应的得到三个隐藏状态 h1 h2 h3，考察上一步中解码器已经得到的隐藏状态 s2，可以将 s2 作为查询向量，计算所有的隐藏状态 h1 h2 h3 和 s2 的相关度（这里的得分是通过一个前馈神经网络来学习的） → 得到注意力分布 → 得到 h1 h2 h3 的聚合内容，也就是图中的 c2，再进一步依据模型设计将 c2 用于解码器</p>
<br>
<br>
<hr>
<h2 id="3-常用注意力机制的变体">3 常用注意力机制的变体</h2>
<br>
<p>实际使用的时候直接利用最原本的模式的情况是不多的，这里讲几个应用比较广泛的变体：</p>
<br>
<h3 id="3-1-键值对注意力-key-value-pair">3.1 键值对注意力 key-value pair</h3>
<p>也就是利用 <strong>键值对</strong> 的方式来输入信息，此时不再是只输入一个 x，而以：</p>
<p>$$(K,V) = [(k_1, v_1), (k_2, v_2) , ... , (k_N, v_N)]$$</p>
<p>的方式输入 N 组信息。这里满足：</p>
<ul>
<li>键 = k 用来计算注意力分布</li>
<li>值 = v 用来基于注意力分布最后计算聚合后的信息</li>
</ul>
<p>其他内容和基本形式是一样的，也就是说此时的聚合信息可以表示为（如果利用软性的信息聚合，打分函数为 s）：</p>
<p>$$att((K,V), q) = \sum_{n=1}^N softmax(s(q, k_n)) v_n$$</p>
<ul>
<li>阶段1 → 通过打分函数，利用查询向量 q，对此时输入的 （键 key）的部分进行打分</li>
<li>阶段2 → 通过 <code>softmax</code> 将不同的打分作归一化处理，得到各个部分的注意力权重，也就是注意力分布</li>
<li>阶段3 → 通过输入的 （值 value）结合注意力分布进行信息聚合</li>
</ul>
<p>K=V 的时候也就是普通的模型</p>
<br>
<br>
<h3 id="3-2-多头注意力-Multi-Head-Attention">3.2 多头注意力 Multi-Head Attention</h3>
<p>也就是此时存在多个查询 Q：</p>
<p>$$Q = [q_1, ... , q_M]$$</p>
<p>来通过一种 <strong>并行</strong> 的方式从输入中搜索需要的信息。直观理解就是解决问题需要很多不同的方面的信息，每一个不同的 qi 考察的都是不同的方面，此时利用不同的 qi 从不同的角度给输入信息的重要性进行打分，再进行某种程度的聚合。</p>
<p>一般不同查询对应得到的聚合信息直接用向量拼接的方式：</p>
<p>$$att((K,V), Q) = att((K,V), q_1) \oplus ... \oplus att((K,V), q_M) $$</p>
<br>
<br>
<hr>
<h2 id="4-自注意力-Self-Attention">4 自注意力 Self-Attention</h2>
<br>
<p>考虑当前针对输入序列的编码方式，如果我们需要将输入序列转化为一个定长的序列，此时卷积和循环神经网络均是较好的选择，但是注意到以上两种均只是一种局部编码的方式（循环神经网络本身由于长程依赖问题 / 梯度消失，实际上也只能建模局部的信息）</p>
<p>换一个思路，如果我想要捕捉整个输入序列中的某种长程依赖关系，此时常用的方法包括：</p>
<ul>
<li>构建深层网络来捕捉关系 → 也就是增加神经网络的层数，但是大家这么干过都知道直接粗暴增加层数是很消耗计算资源的</li>
<li>构造全连接网络 → 但是无法处理变长的序列，也就是说此时输入的序列必须要是等长的 = 输入层的神经元个数</li>
</ul>
<p>想要模拟全连接神经网络的思路来构建一种更好的，可以处理变长输入序列 + 捕捉长距离关系的模型，可以考虑利用注意力机制来 <strong>动态地</strong> 生成权重，这也就是 <strong>自注意力模型</strong> 的主要思路</p>
<br>
<br>
<h3 id="4-1-查询-键值对注意力模型-Query-Key-Value，QKV">4.1 查询 - 键值对注意力模型  Query-Key-Value，QKV</h3>
<p>考虑到往常的使用频率，这里先介绍一下最常用的 <strong>查询 - 键值对注意力模型（Query-Key-Value，QKV）</strong>，实际上为了增强模型效果，基本不会使用上面广义形式对应的自注意力模型</p>
<p>假设此时的输入序列为 x，则自注意力模型可以分为以下几个步骤：</p>
<ul>
<li>将输入的 x <strong>线性投影到三个不同的空间</strong>，以分别得到查询向量 qi，键向量 ki，值向量 vi
<ul>
<li>注意这里线性投影的含义就是学习到三个不同的矩阵 Wq Wk Wv：$$Q = W_qX;  \text{ }\text{ }\text{ } K = W_kX; \text{ }\text{ }\text{ } V = W_vX$$也可以看作是一个简单的前馈神经网络。注意这里因为自注意力模型的打分函数常常使用点积形式，所以这里得到的 qi ，ki，vi 三个结果往往是相同维度的</li>
</ul>
</li>
<li>利用上述得到的查询向量，键向量和值向量，通过上述的<strong>键值对注意力机制得到输出</strong>。也就是说如果这里得到的查询向量，键向量和值向量分别为：$$Q = [q_1,..., q_N]; \text{ } K = [k_1, ... , k_N]; \text{ } V = [v_1, ..., v_N]$$，则此时直接通过键值对注意力机制的方式来计算最后的输出：$$h_n = att((K,V),q_n) = \sum_{j=1}^N softmax(s(k_j, q_j))v_j$$</li>
</ul>
<p>整体图解如下：（图片来源 nndl Fig.8.4）</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022044952815.png" alt="image-20231022044952815" style="zoom:67%;" />
<p>也就是说，输入三个（这里设 N=3）X 序列，每一个长度为 Dx，则此时得到三个查询向量，每一个查询向量得到一个对应的 （这三个 x 序列的线性组合），则此时得到三个结果，对应拼在一起，不改变输入的 X 的对应 N 这部分的维度，但是将长度 Dx 改变为了 Dv（这里的 Dv 是可以任意设置的，只要通过操作此时从 X 到值 V 的投影操作对应的矩阵 Wv 就可以了）</p>
<p>也就是说通过上述操作，此时可以将不定长的序列 Dx 动态地生成适合的权重并转化为某一个定长 Dv</p>
<br>
<br>
<h3 id="4-2-多头自注意力-Multi-Head-Self-Attention">4.2 多头自注意力 Multi-Head Self-Attention</h3>
<p>其实也就是上述的自注意力操作加上了自注意力的思路</p>
<p>比如说此时对应的 x 是 Dx 维度，共 N 个，我每一次通过一个矩阵 Wq 将其投影为一个查询矩阵的时候都可以一次性得到 N 个查询向量，这 N 个查询向量可以保证后续输出的结果还是共 N 个（只是另一个维度由值向量的维度 Dv 决定），这是我们上一节的思路</p>
<p>考虑多头注意力，也就是说此时我们考虑能不能得到多个查询矩阵，以从不同的角度来捕捉 X 的重要情况，则此时我采用多个矩阵 Wqi 将它投影到 m 个不同的空间分别得到 m 个查询矩阵，共 m*N 个向量，再分别计算输出，最后采用向量拼接的方式把它拼起来得到最后的结果，这里思路是十分接近的，就不多说了。</p>
<br>
<br>
<hr>
<h2 id="5-summary">5 summary</h2>
<br>
<p>简单总结一下注意力机制的几个优点：</p>
<ul>
<li>直观上了解，它可以同时捕捉全局和局部的联系，也就是说每一个 xi 的对应的权重都是和全局比较后得出的（也就是 softmax 部分）</li>
<li>大大减少了计算时间，直观理解也就是更多地将算力用在了确实需要注意的，与任务更加相关的重要的部分</li>
<li>支持并行处理 ，注意力机制的计算都不依赖一层一层的结果输出，所以可以并行进行操作计算</li>
<li>本身模型很简单（可能只是简单的点积 / 前馈神经网络，最后再加入一层 softmax），也就是说并不会为当前的模型带来太大的负担，本身参数也不多，训练容易</li>
<li>某种程度上或许可以帮助提高神经网络模型的解释性，也就是说通过计算注意力分布，我可以知道我当前的答案或许是更多地来自哪一个输入，从而更好地为未来的结果提供一定的解释</li>
</ul>
<br>
<p>但是可以注意到此时缺点也是很明显的：</p>
<ul>
<li>将所有的输入（对比到 encode - decode 模型也就是 encoder 部分的 隐藏层 h1 h2 h3）均平行对待，也就是说并没有考虑输入可能存在位置关系（比如 h2 就是在 h1 和 h3 之间输入的），而是并行地计算它们和查询向量 q 的关系，对于 nlp 任务来说本质上是损失了信息的</li>
</ul>
<p>当然后续的模型大多加入位置信息 embedding 来帮助缓解这个问题（比如 BERT 就是这么干的），所以并不认为这就是 attention 用在 nlp 上的致命伤</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>基础整理</category>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>深度学习基础</tag>
        <tag>注意力机制</tag>
      </tags>
  </entry>
  <entry>
    <title>AGGCN：基于注意力导向图卷积神经网络的关系提取模型</title>
    <url>/2023/10/30/20210311-paper-note-AGGCN/</url>
    <content><![CDATA[<p>原文写于 20210311，存档如下</p>
<blockquote>
<p>Zhijiang Guo, Yan Zhang and Wei Lu, StatNLP Research Group, Singapore University of Technology and Design; <strong>Attention Guided Graph Convolutional Networks for Relation Extraction</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDYuMDc1MTB2OC5wZGY=">https://arxiv.org/pdf/1906.07510v8.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0NhcnR1cy9BR0dDTg==">official * pytorch<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br>
<p>关系提取（relation extraction），也就是从一段文本中检测学习各个实体之间的关系。本身在多个 nlp 相关的任务中均有较为显著的作用，从生物医学文献的挖掘到问答系统均有应用。</p>
<p>来一个例子，此时有两个句子，三个实体（L858E, EGFR and gefitinib），自此时的目标就是学习三个实体之间的关系：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022045807639.png" alt="image-20231022045807639" style="zoom: 65%;" />
<p>传统的关系提取模型主要分为以下两种：</p>
<ul>
<li>基于序列的（ sequence-based）：基于词语之间的序列关系来讨论实体之间的关系</li>
<li>基于依赖关系的（dependency-based）：基于依存树（dependency tree）来进行实体间的关系建模</li>
</ul>
<p>其中效果较好的为基于依赖关系的关系抽取模型，也就是说此时不仅仅关注单词序列，整体基于关系依赖树进行关系提取，树的结构可以学到更多从单纯序列处理中无法得到的信息，比如一些非位置的句法关系。为获得更好的模型效果并更好地从无关的信息中提取关系信息，针对关系依赖树提出了许多不同的剪枝策略，而其中大多是基于规则的（rule-based pruning strategies）。这些剪枝策略在某种程度上反而会造成信息的损失，并不适于达到某种保留重要信息和删去无关信息之间的平衡。</p>
<p>为了解决上述问题，本文提出了 “软剪枝” 策略（“soft pruning” strategy）以将原式的 <strong>依存树（dependency tree）转化为全连通的带权图（a fully connected edge-weighted graph）</strong> ，这里的 图结点之间的 <strong>权重可以看作是不同实体之间的关系强弱</strong>，后续将会通过 <strong>端到端 + 注意力机制的方式</strong>来学习</p>
<p>同时为了编码这个全连接的图，这里需要用到 <strong>密集连接的多层图卷积神经网络</strong>（GCNs with dense connections）。注意此时浅层的图卷积神经网络是不足以来捕捉这种非位置的关系的，如果想要捕捉 k-hop 的关系则此时需要 k 层参与。而密集连接进一步帮助我们训练整个网络并捕捉更多的丰富信息</p>
<br>
<br>
<hr>
<h2 id="2-Attention-GUided-GCNs-模型解释">2 Attention GUided GCNs 模型解释</h2>
<br>
<h3 id="2-1-overview">2.1 overview</h3>
<p>还是先来看一下整体模型的结构</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022045841258.png" alt="image-20231022045841258" style="zoom:60%;" />
<p>AGGCN 共有 M 个block，每一个 block 的输入为 <strong>每一个 node 的 embedding</strong> + <strong>当前的邻接矩阵 adjacency matrix</strong></p>
<br>
<p>每一个 block  包括三个部分：</p>
<ul>
<li>注意力导向 （<strong>attention guided layer</strong>）：输入的邻接矩阵通过多头自注意力  得到 N 个新的权重矩阵，每一个就代表一个新的全连接图，这里的每一个边的权重可以看作是对结点之间关系强弱程度的度量</li>
<li>共 N 个密集连接层（<strong>densely connected layer</strong>）：前面多头自注意力得到的结果分别输入 N 个独立的密集连接层以得到新的表示，每一个有 L 层</li>
<li>一个线性连接组合层（<strong>linear combination layer</strong>）：通过一个线性组合的层将所有的前面的 N 个输出综合得到一个隐藏表示</li>
</ul>
<p>下面来分别看看每一个部分的内容</p>
<br>
<br>
<h3 id="2-2-GCNs-图卷积神经网络">2.2 GCNs 图卷积神经网络</h3>
<p>开始之前先简单来讲一下 GCN</p>
<p>图卷积神经网络，也就是 graph convolutional network，本质上就是直接在图结构上运行的神经网络。考虑此时存在 n 个结点的图（无向图），则可以利用一个 n*n 的邻接矩阵 A 来表示这个图的信息。</p>
<p>这里考虑针对依赖树来编码：先为树的每一个结点都增加一个和自己连接的边（self-loop），如果此时树模型中 i ，j 两个结点是直接相连的，则设置 $A_{ij} = A_{ji} = 1$，否则为 0</p>
<p>此时进一步考虑在这样一个图上的卷积运算：在 l 层上的第 i 个结点的计算定义为<br>
$$<br>
h_i ^{(l)} = \rho (\sum _{j=1} ^n A _{ij} W ^{(l)} h_j ^{(l-1)} + b ^{(l)})<br>
$$</p>
<p>这里的 W 和 b 都是学习参数，ρ 是一个激活函数</p>
<p>假设此时的初始输入  $x_i = h_i^{(0)} \in R^d$</p>
<br>
<h3 id="2-3-Attention-Guided-Layer-注意力导向层">2.3 Attention Guided Layer 注意力导向层</h3>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022050025408.png" alt="image-20231022050025408" style="zoom:80%;" />
<p>注意这里实际上有 M 个 block，每一个 block 都包括了一个注意力导向层</p>
<p>当前的大多数策略还是以剪枝为主，但是这样的 hard 的方法容易导致一些似乎不重要的信息直接完整的被删去而带来的信息损失（也就是 不重要 ≠ 一无是处），这里利用注意力机制来更好地整合信息</p>
<p>这里的目标：也就是 <strong>通过输入的原始的依存树生成一个全连接的带权图 = 生成它的邻接矩阵$\tilde{A}$</strong></p>
<p>原始的做法是直接利用剪枝的策略：先预先定义好一定的固定的剪枝策略 → 将此时的依存树通过剪枝得到 subtree  → 利用 subtree 直接构建邻接矩阵，不存在的边全部一概设置为 0。而这么做的缺点就是预先定义好的剪枝策略可能会造称不必要的信息损失</p>
<p>这里利用 <strong>键值对 - 多头自注意力</strong> 来对这一步骤进行改进：先将原始的树（也就是不进行剪枝的 fulltree）直接转化为邻接矩阵作为初始输入，再通过键值对多头自注意力得到新的邻接矩阵 $\tilde{A}$ ，经过该 block 结束后，再将上一个 block 的输出作为下一个该层的输入</p>
<p>自注意力部分计算如下：<br>
$$<br>
\tilde {A} ^{(t)} = softmax (\frac {QW_i^Q \times (KW_i^K) ^T} {\sqrt{d}})<br>
$$</p>
<p>这里的 $K = Q = h^{(l-1)}$，均为上一层的输出（指的是上一个 block 的输出，整个模型共有 M 个 block，每一个 block 最后的输出是通过了最后的  linear combination layer 的那个），$W_i^Q$ 和 $W_i^K$ 是需要训练的 ，分别负责通过当前的 Q = K 得到第 i 个查询矩阵和键矩阵，i 标记是第 i 个投影矩阵（因为这里是多头自注意力，i = 1，...，N)</p>
<p>注意这里自注意力部分的得分函数的计算，需要 / √d，这里的 d 是维度</p>
<p>在实际使用的时候，原始的句子的 fulltree 得到的邻接矩阵就是第一个 block 的最初始的输入</p>
<br>
<h3 id="2-4-Densely-Connected-Layer-密集连接层">2.4 Densely Connected Layer 密集连接层</h3>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022050201073.png" alt="image-20231022050201073" style="zoom:67%;" />
<p>目的是为了加深整个模型的层数，以更好地捕捉丰富的局部信息和 k-hop 的信息，因为上面的注意力导向层产生了 N 个不同的邻接矩阵 $\tilde{A}$，则这里使用 N 个密集连接层来进行操作</p>
<p>先定义 $g_j^{(l)}$ 为 ：<br>
$$<br>
g_j ^{(l)} = [x_j;h_j ^{(1)} ; ... ; h_j ^{(l-1)}]<br>
$$</p>
<p>这里的 xj 是结点 j 的初始表示，$h_j^{(l)}$ 为对应的第 l 层的输出中对应的 结点 j 的表示，这里直接用级联的方式得到 gj</p>
<p>则此时对于第 t 个密集连接层（对应第 t 个多头自注意力的查询矩阵）的每一个子层sublayer，其输出中的结点 i 的值可以如下计算：<br>
$$<br>
h _{t_i} ^{(l)} = \rho (\sum ^n _{j=1} \tilde{A} ^{(t)} _{ij} W_t ^{(l)} g_j ^{(l)} + b_t ^{(l)})<br>
$$</p>
<p>这里的 W 和 b 是待学习参数，$\tilde{A}$​ 是前面学到的新的邻接矩阵（共学了 N 个不一样的这个东西摆着），ρ 是激活函数</p>
<p>此时每一个子层都输出一个上面的 $h_{t_i}^{(l)}$，最后将多个子层的输出进行拼接，得到最后的该密集连接层的输出</p>
<p>注意一下这里每一个密集连接层的隐藏层的维数：每一个密集连接层有 L 个 sublayer（每一个 block 有 N 个密集连接层，N*L 个子层），注意这里的 sublayer 的大小是不一定要求大于等于输入维度的，也就是说可以将它设置得相对小以减少需要训练的参数个数。原文使用的为：$d_{hidden} = d/L$</p>
<p>简单来说就是如果我的输入维度为 300，此时用 3 个子层，则每一个的 d_hidden 都是 300/3 = 100，我的输出也就是维度 100 的，再三个子层的 100 的输出拼在一起，就是最后的 300 的输出，不变</p>
<br>
<h3 id="2-5-Linear-Combination-Layer-线性组合层">2.5 Linear Combination Layer 线性组合层</h3>
<p>也就是把 N 个密集连接层的输出连在一起：<br>
$$<br>
h _{comb} = W _{comb} h _{out} + b _{comb}<br>
$$</p>
<p>这里的 $h_{out}$ 也就是共 N 个密集连接层的输出的拼接：$h_{out} = [h^{(1)}; ... ; h^{(N)}] \in R^{d*N}$，Wcomb 是要学习的权重矩阵，bcomb 是要学习的偏差向量</p>
<br>
<br>
<hr>
<h2 id="3-AGGCNs-for-Relation-Extraction-实现关系提取">3 AGGCNs for Relation Extraction 实现关系提取</h2>
<br>
<p>回到此时我们的目的：也就是为了文本中的实体关系抽取</p>
<p>以上的 h 得到的是句子中的实体的表示，此时进一步地得到句子的表示：<br>
$$<br>
h _{sent} = f(h _{mask}) = f(AGGCN(x))<br>
$$</p>
<p>这里的 $h_{mask}$ 是被掩蔽的部分的表征，也就是句子中非实体的部分的表征（因为前面的部分不断地在针对实体得到实体的更优秀的表征)，f 是一个最大池化方程，目标是 $R^{d<em>n}$ → $R^{d</em>1}$，也就是得到一个向量来表征这个句子</p>
<p>同理，此时可以通过最大池化得到实体的表征：$$h_{e_i} = f(h_{e_i})$$<br>
这里的 $h _{e_i}$ 是前面的输出</p>
<p>将上面句子的表征（实际上就是去掉了实体的部分的表征 + 最大池化得到的向量）和实体表征（也就是前面 AGGCN 的输出经过了最大池化得到的向量）进行拼接，再经过一个前馈神经网络 FFNN，得到最后的表征：<br>
$$<br>
h _{final} = FFNN([h _{sent}; h _{e_i}; ...; h _{e_i}])<br>
$$</p>
<p>此时的 $h_{final}$ 即为最后的表示，将最后的表示放入简单的逻辑回归分类器来判断选定的实体对之间是否存在关系</p>
<br>
<br>
<hr>
<h2 id="4-Experiments-实验部分">4  Experiments 实验部分</h2>
<br>
<h3 id="4-1-dataset-和实验设置">4.1 dataset 和实验设置</h3>
<p>注意这里实际上是有监督学习，用来训练和测试的数据集都有了人工标记（标记是否存在关系，什么样的关系 / 也就是关系的不同分类）</p>
<p>这里分为两个部分，一个是 <strong>多个句子的 n 元关系抽取</strong>，一个是 <strong>句子级关系抽取</strong></p>
<p>对于 多个句子的 n 元关系抽取 的评估数据集用的是 PubMed，每一个例子都有多个句子，包含多个有着不同关系的实体对。这里考察了两种，一种是只将实体关系分类为（有关系 /  没关系）来进行分类，也就是二元问题；另一个是多分类问题，此时不同的实体对可能有多种关系（“resistance or nonresponse”, “sensitivity”, “response”, “resistance” , “None”）</p>
<p>对于 句子级关系抽取 的评估用的是 TACRED dataset，也就是说这里不再是用的多句子的形式，实体对可能出现的关系有 41 种，就还是多分类问题</p>
<br>
<h3 id="4-2-几个细节">4.2 几个细节</h3>
<p>关于超参数的部分，比较重要的有 block 个数 M，多头自注意力个数 N，和此时密集连接层的子层 sublayer 个数 L</p>
<p>通过初步实验发现：</p>
<ul>
<li>N=2，M=2，L1=2，L2=4，d_hidden=340 → 多句子的 n 元关系抽取 → 效果最好</li>
<li>N=3，M=2，L1=2，L2=4，d_hidden=300 → 句子级别关系抽取 → 效果最好</li>
</ul>
<p>可以看到此时 block 的个数 / 子层个数 / 多头自注意力个数都不会太大</p>
<p>词向量一开始初始化的时候用的是 <code>GloVe</code>，评估用的是五折交叉验证</p>
<br>
<h3 id="4-3-result">4.3 result</h3>
<p>来看看效果</p>
<p><strong>多个句子的 n 元关系提取任务</strong>：注意这里的 binary-class 就是只是分类有关系和没关系，multi-class 就是多分类问题，需要进一步预测到底是什么样的关系</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022050559497.png" alt="image-20231022050559497" style="zoom:55%;" />
<p><strong>TACRED 上的句子级关系抽取</strong></p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022050649064.png" alt="image-20231022050649064" style="zoom:60%;" />
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>Self-Training MRC (STM): 基于软证据提取的机器阅读理解自训练方法</title>
    <url>/2023/10/30/20210312-paper-note-STM/</url>
    <content><![CDATA[<p>原文写于 20210311，存档如下</p>
<blockquote>
<p>Yilin Niu, Fangkai Jiao, Mantong Zhou, Ting Yao, Jingfang Xu, Minlie Huang, <strong>A Self-Training Method for Machine Reading Comprehension with Soft Evidence Extraction</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzIwMDUuMDUxODkucGRm">https://arxiv.org/pdf/2005.05189.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源代码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1NwYXJrSmlhby9TZWxmLVRyYWluaW5nLU1SQw==">https://github.com/SparkJiao/Self-Training-MRC （official ** pytorch）<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br>
<h3 id="1-1-background-论文背景与思路">1.1 background 论文背景与思路</h3>
<p>当前大多数经典的机器阅读理解模型（MRC）往往包括以下两个结构：</p>
<ul>
<li>证据提取器（evidence extractor）：也就是负责检索出可能对解决这个问题有帮助的部分文本，此时检索的结果可能是一个句子 / 一段片段 etc，著名的 SQuAD 和 CoQA 数据集给出的任务都是这个思路</li>
<li>答案预测器（ answer predictor）：从前面提取出的片段种割出一个部分作为答案，也就是常见的那种任务为预测答案开始位置和结束位置的论文的思路</li>
</ul>
<p>也就是说，此时证据标签（evidence labels）对于整个模型的训练是很重要的，也就是说我需要知道我所提取出的部分是不是真的对的答案的出处。对于 <strong>抽取式</strong> 的阅读理解任务是很好训练的，因为本身的答案也就是从整个文本中进行抽取的。但是这一标签对于 <strong>非抽取式</strong>的机器阅读理解任务往往是难以获得的，比如答案为 Yes/No 的问题，或者一些类似于选择题 / 多选题的形式，本身不存在对应的文中的出处，也就是说只有答案，但是没有答案对应的文章部分的 span，缺少证据标签导致在这类非抽取式任务上难以直接对证据提取器进行训练。</p>
<p>举一个非抽取式的例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022051018029.png" alt="image-20231022051018029" style="zoom:60%;" />
<p>针对这类非抽取式的机器阅读理解任务，经典方法有：</p>
<ul>
<li>人工标注 gold answer：费时间且贵，需要钞能力来雇佣生物型人工智能，不现实</li>
<li>远程监督：往往会依赖于一些人工手动设置的规则或一些外部资源来生成 distant label ，有效性有待商榷</li>
<li>强化学习：本身强化学习的训练往往是不稳定的</li>
</ul>
<p>为了解决针对非抽取式阅读理解问题缺乏用于训练的证据标签的问题，原文提出了一种 <strong>自训练方法</strong>（Self Training method ，STM），直观来说也就是在迭代的过程中，自动生成证据标签并用来训练我们的证据提取器。每一个迭代中，用正确答案（gold answer）和噪声标签（noisy evidence labels）同时来训练基础的机器阅读理解模型（MRC），再利用这个模型来预测伪标签（也就是我们的 MRC 认为是对的的标签，但是并没有经过人工的验证步骤），并加入监督下一轮的训练。整个过程不需要手动舍设定的规则或外部信息，同时具有较好的可迁移性。</p>
<br>
<h3 id="1-2-self-training-自训练">1.2 self-training 自训练</h3>
<p>开始之前先稍微说说什么是自训练</p>
<p>自训练本身提出就是为了用在缺少标注的数据上的，通过让模型自己学习，自己创建可能的标签，再不断训练迭代的方式来学习。</p>
<p>具体思路如下：</p>
<ul>
<li>将此时的数据分为训练集和测试集和未标记数据，注意这里的训练集是得到标记的，也就是说一开始需要一定的已标记数据来启动模型，但是不需要标记所有数据，自训练的优势也就是在于可以将未标记数据利用到模型中</li>
<li>利用训练集中的数据（已标记）来训练模型</li>
<li>利用当前训练的模型来尝试标记没有人工标记的数据，选择正确率足够高的一些标签作为 “伪标签”，这里的伪标签的选取可以全部都要或者根据一定的置信度加权</li>
<li>将上一步得到的 “伪标签” 数据和原始的训练数据放到一起，再一同用于训练模型</li>
<li>重复上面的步骤，直到此时还未被标记的数据本身少于某一个数值，或者此时模型进行的预测不足以获得新的伪标签（比如新的预测对应的置信度都卡住了高不上去了）</li>
<li>最后在测试集上测试分类器性能，注意这里的测试集是人工标注的数据</li>
</ul>
<p>也就是说，此时只是需要少量一部分的已标注数据（一部分作为训练集来启动模型，一部分作为测试集来进行评估），而同时可以利用大量的未标注数据，属于半监督学习的方式。</p>
<br>
<br>
<hr>
<h2 id="2-Methods-模型介绍">2 Methods 模型介绍</h2>
<br>
<h3 id="2-1-overview">2.1 overview</h3>
<p>先来看看模型的整体结构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022051056629.png" alt="image-20231022051056629" style="zoom:60%;" />
<p>此时有两个数据池， U 和 L，沿用自训练的思路，此时 L（labeled data） 中的数据是已经经过了标记的少量数据，而 U（unlabeled data） 中的数据是大量未标注数据，也就是说 U 中的没有对应的证据标签（答案出处）而只有正确答案</p>
<p>整体 STM 模型的思路如下：</p>
<ul>
<li><strong>MRC 模型同时在 U 和 L 两个数据池上进行训练</strong>（注意这里是同时在训练的，也就是对应图中 ① 的两个箭头）</li>
<li><strong>MRC 对未标注数据池 U 中的数据进行预测</strong>，也就是预测 U 中的只有正确答案的数据其对应的证据标签</li>
<li><strong>Selector 进行选择</strong>，从上一步 MRC 的所有预测中选择有一定置信度的预测，将<strong>选中的预测从数据池 U 移到 L 中</strong>，这一步也就是选择伪标签并加入训练集以监督下一轮训练的部分</li>
</ul>
<br>
<h3 id="2-2-Base-Model-阅读理解部分模型">2.2 Base Model  阅读理解部分模型</h3>
<p>先来看一下 STM 中 MRC 部分模型的结构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022051131978.png" alt="image-20231022051131978" style="zoom:67%;" />
<p>同理，此时由 三个部分 组成：<strong>编码层（encoder layer）+ 证据提取（evidence extractor）+ 答案预测（answer predict）</strong></p>
<p>第一个编码层也就是用了文档 D （token 单位的）和问题 Q  的 embedding，没啥好说的，主要看看后两个</p>
<br>
<br>
<h4 id="2-2-1-evidence-extractor-证据提取">2.2.1 evidence extractor 证据提取</h4>
<p>此时将问题 Q 和文档 D 作为输入，编码层负责获得输入的上下文表示。设此时文档 D 包括句子 S：$D = {S_1 , S_2, ... , S_m}$，而 $h^D_{i,j}$ 表示文档 D 中第 i 个句子中的第 j 个单词的表示，$h^Q_i$ 为问题 Q 中的第 i 个单词的表示。</p>
<p>encoder 层还是依赖于注意力机制，这里使用了 <strong>token 级别的 attention</strong> 和 <strong>句子级别的 attention</strong> 来获得文档的上下文表示 $h^D$：</p>
<h5 id="token-level-attention：">token-level attention：</h5>
<p>也就是通过注意力模块得到句子的上下文表示，这里以句子中的多个 token 为单位</p>
<p>首先以问题 <strong>Q 为查询向量</strong>，通过打分函数 + softmax 得到权重后融合各个 token，得到最后句子的向量表示 $h_i^D$：<br>
$$<br>
h_i^D = \sum _{j} ^{|S_i|} {a _{i,j} h _{i, j} ^D} \text{ , } \alpha _{i, j} \varpropto exp(F^S(h^Q, h^D _{i,j}))<br>
$$</p>
<p>再对整个句子作<strong>自注意力</strong>，也就是利用可学习的参数将原句子投影到新的空间作为查询矩阵，这里得到句子本身的自注意力向量表示 $s_i^D$：<br>
$$<br>
s_i^D = \sum _j ^{|S_i|} \beta _{i, j} h _{i, j} ^D \text{ , } \beta _{i,j} \varpropto exp(w_sh _{i,j} ^D + b_s)<br>
$$</p>
<p>一点小细节，这里原文的打分函数用的是双线性的形式 bilinear form</p>
<br>
<h5 id="sentence-level-attention">sentence-level attention</h5>
<p>也就是以 sentence 句子为单位，通过注意力计算各个句子的权重以得到整个文档 D 的表示 $h^D$：<br>
$$<br>
h^D  = \sum _i ^m \gamma_i h_i^D \text{ , } \gamma_i \varpropto exp(F^D (h^Q, s_i^D))<br>
$$</p>
<p>注意这里用的是句子 i 本身的自注意力后的向量表示 si 和问题的表示 hQ 来计算得分函数的</p>
<p>这里其实有一点类似于那种通过问题匹配来寻找答案可能出现的范围的问题，此时这个句子的权重越高说明问题越可能来自于这里</p>
<br>
<h4 id="2-2-2-answer-prediction-答案预测">2.2.2 answer prediction 答案预测</h4>
<p>注意以上两个注意力模块最后的输出实际上是最后的 $h^D$，也就是文档的向量表示，此时将文档的向量表示和问题的向量表示 $h^Q$ 一同输入来进行答案的预测</p>
<p>如果此时是<strong>抽取式问题</strong>，也就是需要给出文档的一部分内容作为答案，则此时使用两个 MLP 多层感知机来分别预测每一个 token 的位置是 （答案的开始位置）和是（答案的结束位置）的概率，再选取答案</p>
<p>如果此时是 <strong>Yes/No</strong> 的问题，直接使用一个简单的线性分类器；如果是 <strong>多项选择问题</strong> 则使用 MLP + softmax 的形式给出各个答案的概率</p>
<br>
<h3 id="2-3-Loss-Function-损失函数">2.3 Loss Function 损失函数</h3>
<p>这里定义两个损失函数，分别对应任务的损失函数和证据提取的损失函数</p>
<br>
<h4 id="2-3-1-task-specific-loss-任务部分损失函数">2.3.1 task-specific loss 任务部分损失函数</h4>
<p>这里直接使用的是极大似然法（用的是负对数的那个似然函数）<br>
$$<br>
L_A (D, Q, A) = -\log P(\hat {A} = A|D, Q)<br>
$$</p>
<p>这里的 A 是正确答案（gold answer)，而 $\hat{A}$ 是我预测的答案</p>
<br>
<h4 id="2-3-2-evidence-loss-证据提取部分损失函数">2.3.2 evidence loss 证据提取部分损失函数</h4>
<p>这里的证据理解为句子级别的，也就是选出 K 个可以作为证据的句子（这里的 K 是一个预先决定的超参数）。注意因为可能有 k 个句子，故这里一步一步地计算 loss：</p>
<ul>
<li>选出最可能的那个句子（也就是权重最大的）</li>
<li>在所有没有被选过的句子上计算 loss，也就是把被选过的句子 mask 掉</li>
</ul>
<p>重复上面的步骤 k 次，也就是每一次都从当前剩下的句子里选出一个最大的，再算剩下的。最后的 loss 是上面 k 步 loss 的平均值</p>
<p>这里利用了一个 <strong>BP-able</strong> 来选择 top-K 最可能为证据的句子。</p>
<p>考虑：<br>
$$<br>
L_E(D, Q, E) = \frac{1}{K} \sum _{k=1} ^K H(D,Q,E,M^k)<br>
$$</p>
<p>这里的 M 表示 mask，也就是 $M^k = {M_1^k ,...,M_m^k}$，文章 D 中共 m 个句子，而每一个 $M^k_i \in {0,-\infty }$，表示为第 k 轮是句子 i 的 mask，如果 mask = 0 表示此时这个句子还没有被选中，而选中的句子为 $-\infty$，注意第 k 轮中新被选中的句子的对应 Mk 的 mask 也是 $-\infty$​<br>
$$<br>
M_i^k =<br>
\begin{cases}<br>
-\infty &amp;i = \arg\max_j (\lambda _j ^{k-1} E_j) \\<br>
M_i ^{k-1} &amp;otherwise<br>
\end{cases}<br>
$$</p>
<p>这里的 $E_i \in {0,1}$ 用来标识当前的 第 i 个句子是不是真的是证据</p>
<p>在每一轮都需要选择出当前所有还没有被选择的句子中的一个最可能的句子，则此时在每一轮都计算所有未被选择句子的注意力分布：<br>
$$<br>
\lambda _i ^k = \frac{exp(F^D (h^Q, s_i) + M_i^k)} {\sum_j (exp(F^D(h^Q, s_j) + M_j^k))}<br>
$$</p>
<p>这里的 si 是句子的自注意力表示，打分函数出来后经过 softmax</p>
<p>选出句子后计算它的 loss：<br>
$$<br>
H(D, Q, E, M^k) = -\log \max _i (\lambda _i ^k \cdot E_i)<br>
$$</p>
<p>这里的 $E_i \in {0,1}$ 用来标识当前的 第 i 个句子是不是真的是证据</p>
<p>H 是对应第 k 步的结果，最后总体的损失函数也就是 k 个 H 的均值</p>
<br>
<p>综上，此时总体的损失函数就是上面两种损失函数的加权组合：<br>
$$<br>
L = \sum _{(D,Q,A) \in U \cup L} {L_A (D, Q, A) + \eta \sum _{(D,Q,A) \in L} L_E (D,Q,A)}<br>
$$</p>
<p>η 本身是一个超参数</p>
<br>
<h3 id="2-4-Self-Training-MRC-STM-整体模型">2.4  Self-Training MRC (STM) 整体模型</h3>
<p>现在来看看整体模型的结构：</p>
<p>首先，<strong>利用真实答案来训练 MRC 部分的模型</strong>，这里同时用到了 U 和 L 两个数据集，训练 MRC 的时候不需要证据标签，只要直到正确答案就可以</p>
<p>这里的 MRC 的训练用的是上面那个同时（任务导向）+（证据提取部分导向）的总的损失函数</p>
<p><strong>进一步通过给定的（D,Q,A），也就是文章+问题+答案 来进行证据标签的标注</strong>，这里标注依赖于：<br>
$$<br>
\hat {E} = \arg\min _{E'} L_E {(D, Q, E')}<br>
$$</p>
<p>也就是说我本来是依赖真实的（是否为证据 Ei）来计算损失函数，则此时我同样可以来考虑使得损失函数最小的 Ei 是什么样的，由此得到未标记（指的是未标记证据出处)数据的证据标签的估计 $\hat{E}$</p>
<p>则此时对于 $(D,Q,A,\hat{E})$​，这个组合的置信得分定义为：<br>
$$<br>
c(D, Q, A, \hat{E}) = exp(-L_A (D, Q, A)) \cdot exp(-L_E(D, Q, \hat{E}))<br>
$$</p>
<p>同时用到了任务导向的损失函数 和 证据标签部分的 loss</p>
<p>而这里的 <strong>selector 的选择依据</strong>：</p>
<ul>
<li>要求组成上面置信得分的两个损失函数都在某一个阈值以下（防止其中一个很低而另一个不行导致的总体得分高，需要两个任务上都差不多不错）</li>
<li>在满足 1 的情况下，达到置信得分最高</li>
</ul>
<p>一个小细节，在初始的时候数据池 L 实际上是空的，而证据提取器的训练是由远程监督完成的</p>
<p>整体模型的流程如下所示：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022052441091.png" alt="image-20231022052441091" style="zoom:70%;" />
<br>
<br>
<hr>
<h2 id="3-Experiments-实验部分">3 Experiments 实验部分</h2>
<br>
<h3 id="3-1-dataset">3.1 dataset</h3>
<p><strong>Yes/No Question Answering (YNQA)</strong> ：二元选择回答的数据集，非抽取，包括如下几个：</p>
<ul>
<li>CoQA</li>
<li>BoolQ</li>
<li>MS MARCO</li>
</ul>
<p><strong>Multiple-choice MRC</strong>：多项选择的数据集</p>
<ul>
<li>RACE</li>
<li>DREAM</li>
<li>MultiRC</li>
</ul>
<p><strong>Open-domain QA (ODQA)</strong>：开放</p>
<ul>
<li>Quasar-T</li>
</ul>
<br>
<h3 id="3-2-result">3.2 result</h3>
<p>看看在几个类型上的结果：</p>
<p>对于二元选择：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022052513753.png" alt="image-20231022052513753" style="zoom:67%;" />
<p>多项选择：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022052532575.png" alt="image-20231022052532575" style="zoom:55%;" />
<p>开放：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022052607856.png" alt="image-20231022052607856" style="zoom:60%;" />
<p>由于用到的是自学习，这里验证了一下 <strong>Error propagation</strong> 的问题，也就是一开始就预测错了，但是又被拿去作训练，导致整个模型坚定不移地学着错的东西</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022052705215.png" alt="image-20231022052705215" style="zoom:67%;" />
<p>约有 4% 的错误的证据反而被复用了（就是又被拿去学了），但是它们中有接近一半的在后面的 tire 又被纠正了，在此可以认为 STM 并不会陷入严重的 error propagation 导致整个的崩溃</p>
<br>
<br>
<br/>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>KAR: 实现机器阅读理解中对常识知识的显示应用</title>
    <url>/2023/10/30/20210313-paper-note-KAR/</url>
    <content><![CDATA[<p>原文写于 20210313，存档如下</p>
<blockquote>
<p>Chao Wang and Hui Jiang, Department of Electrical Engineering and Computer Science, Lassonde School of Engineering, York University, <strong>Explicit Utilization of General Knowledge in Machine Reading Comprehension</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE4MDkuMDM0NDl2My5wZGY=">https://arxiv.org/pdf/1809.03449v3.pdf<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<p>当前机器阅读理解模型 MRC 和人类行为之间的差距往往体现在：</p>
<ul>
<li><strong>缺少足够数据样例来训练</strong>：MRC 模型的训练需要大量的文本 passage，对应的问题 question，真实的答案 gold answer，对于抽取式问题甚至还需要答案提取的证据 span。但是对于人类而言，只需要比较少的例子即可以通过分析快速地学到更多的信息和解题方法。</li>
<li><strong>对于噪声缺乏一定的鲁棒性</strong>：研究表明特意加入的噪音能够大大影响整体 MRC 模型的性能，而本文认为造成这一问题的主要原因是机器太过于依赖本身文本给定的信息，而人类可以利用常识来进行判断。</li>
</ul>
<p>针对第二个问题举个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022053124295.png" alt="image-20231022053124295" style="zoom:55%;" />
<p>facilitate 本身是 help 的同义词，而这一个同义词的关系并没有体现在文本中，也就是说如果机器只是阅读了 passage，它连 help 这个词都没见过，本身也就不会学习到 help 和 facilitate 之间的相关性</p>
<p>也就是说，如果此时能够让机器同时具有人类阅读时具有的常识（general knowledge），或许能够帮助机器更好地理解任务并给出解答。</p>
<p>想要让机器同时利用人的常识来进行阅读理解，此时主要目标为解决以下两个问题：</p>
<ul>
<li><strong>结合文章-问题对，提取出相关的常识信息</strong>：不能让机器为了解答一个问题学遍全世界所有的常识，故这里需要根据文章问题 pair 提取出可能帮助机器解答问题的相关的常识</li>
<li><strong>利用常识并帮助标注答案span</strong>：也就是如何将外界学到的常识信息利用进入整个 MRC 模型中</li>
</ul>
<p>第一个问题很好解决，本文利用 <strong>WordNet (Fellbaum, 1998)</strong> 作为外界知识库（这个东西可以简单地理解为一个同义词库）</p>
<p>第二个问题，当前常用的解决方式为：得到相关常识的向量标识（也就是编码到一个向量空间），再利用它丰富 word 级别的上下文语义表示，此时也就是将常识的信息和表示结合，再进行后续的 MRC 预测。但是注意到这样的方式本身是隐形的，也就是说我们很难知道这样被融入进去的表达能够怎样帮助我们最后的预测。</p>
<p>本文尝试提出一种能够帮助实现 <strong>于机器阅读理解中显式利用常识信息</strong> 的方法，主要贡献包括：</p>
<ul>
<li>提出一种<strong>数据增强方法</strong>（data enrichment method）：也就是利用 WordNet 提取出和当前 passage-question pair 相关的同义词用来完成某种程度上的数据增强</li>
<li>提出<strong>端到端的机器阅读理解模型 nowledge Aided Reader (KAR)</strong>：显式利用提取出来的常识来帮助注意力机制部分的学习</li>
</ul>
<br>
<br>
<hr>
<h2 id="2-数据增强方法">2 数据增强方法</h2>
<p>这里利用 WordNet 来实现数据增强，也就是主要采取同义词的信息来完成，目标为提取出同当前文章-问题对相关的外部知识信息，也就是外部知识和 passage-question pair 中 word 的语义联系</p>
<br>
<h3 id="2-1-Semantic-Relation-Chain-语义关系链">2.1  Semantic Relation Chain  语义关系链</h3>
<p>WordNet 本身就是同义词库，但是注意到本身一个词在不同的应用场景下会存在不同的含义，自然也就存在不同的同义词。在 WordNet 中定义了共 16 种语义关系，以标注两个同义词确实为同义所需要的应用上下文环境。</p>
<p>则此时可以将 WordNet 中的语义关系看作语义关系链的形式，比如词汇 A 通过关系种类 1 与词汇 B 相连，而词汇 B 通过关系种类 2 与词汇 C 相连，通过不同的链的类型，不同的词汇可以连成语义关系链的形式。</p>
<p>对于词汇 A 的同义词集，此时还有词可能和 A 是通过多跳的形式相连的，这些词可能和 A 也存在一定的潜在关系。这里将两个不同的词之间通过多种不同的语义关系相连的路径定义为语义关系链，并将其中一个词作为一个 hop 看待（类似于 图 的形式）</p>
<br>
<h3 id="2-2-Inter-word-Semantic-Connection-单词间语义联系">2.2  Inter-word Semantic Connection 单词间语义联系</h3>
<p>注意到本身利用同义词信息来进行数据增强的重点问题就是在考察当前的两个问题之间到底有没有语义联系。考虑单词 w，此时 WordNet 会给出它的同义词集合 $S_w$，这里使用 $S_w^*$ 来表示单词 w 的扩充同义词集合（extended synsets），集合包括所有可以通过上面定义的语义关系链和单词 w 相连的单词。</p>
<p>但是注意到如果此时不加限制可能整个 WordNet 中的词汇都能够相连，故在此设定超参数 $\kappa \in N$ 来规定所有可以被加入 $S_w^<em>$ 的单词涉及的最大跳数，这里对于 0 跳的时候，S</em> 也就是 Sw</p>
<p>注意这里不对当前连接不同单词之间的 relation 的类型加限制，只要是相连了就行</p>
<br>
<h3 id="2-3-General-Knowledge-Extraction-常识提取">2.3 General Knowledge Extraction 常识提取</h3>
<p>此时根据给定的 passage-question pair 来抽取相关的常识：</p>
<p>此时认为所有和当前 passage 的词汇存在一定同义词关系的词汇都是我想要学习的外部常识。令任意一个词汇 w，则此时我想要抽取集合 $E_w$，包含所有 <strong>和词汇 w 存在同义词关系的 passage 中的词汇在 passag 中的位置信息</strong>：</p>
<ul>
<li>这里只是抽取<strong>位置信息</strong>，也就是找到所有和当前词汇 w 存在同义词关系的，且在 passage 中的词汇，且记录它们的位置信息。注意如果此时 w 词本身也在 passage 中，略过它自己在 passage 中的信息。</li>
<li>利用规定了最大 hop 的超参数 <strong>κ 来控制此时抽取的数量</strong>，也就是说只有文章中的词汇 y 本身在当前词汇 w 的 κ-hop 内，才记录 y 在 passage 中的位置信息</li>
</ul>
<br>
<br>
<hr>
<h2 id="3-Knowledge-Aided-Reader-模型介绍">3 Knowledge Aided Reader 模型介绍</h2>
<br>
<h3 id="3-1-overview">3.1 overview</h3>
<p>先来看看整体的模型结构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022053427122.png" alt="image-20231022053427122" style="zoom:60%;" />
<p>注意这里还是 attention 主导的模型，主要包括两种：</p>
<ul>
<li><strong>mutual attention</strong>：主要目标是将问题表示和文章表示融合，可以得到经过了问题表示融合的文章表示（question-aware passage representation），这一步也是传统的 MRC 会处理的</li>
<li><strong>self-attention</strong>：通过（经过了问题表示融合的文章表示）与自己的自注意力模块得到最后的最终文章表示</li>
</ul>
<p>而整个文章的创新点便在于 <strong>利用了前面抽取出的外部知识（常识）来辅助上述的注意力机制</strong>，与一般的直接将外部知识 embedding 和当前文章表示 embedding 进行融合的方式，这里针对外部知识的应用方式是显式的。</p>
<p>定义：</p>
<ul>
<li>$P = {p_1, ... , p_n}; \text{ } Q = {q_1, ..., q_m}$  文章 - 问题的集合</li>
<li>当前目标则为预测答案的 span（抽取式问题）：$[a_s,a_e]$</li>
</ul>
<br>
<h3 id="3-2-Overall-Architecture-模型各层介绍">3.2  Overall Architecture 模型各层介绍</h3>
<p>KAR 本身作为一个 端到端 的阅读理解模型，可以表示为以下五层的拼接：</p>
<h4 id="Lexicon-Embedding-Layer">Lexicon Embedding Layer</h4>
<p>图中蓝色部分，分别对文章和问题来做</p>
<p>也就是通过词汇 word 得到 lexicon embedding，每一个 lexicon embedding 包括两个部分：<strong>word embedding（词向量） + character embedding（字符向量）</strong>，这里使用 <strong>GloVe预训练</strong> 来得到词向量，用 <strong>CNN</strong> 来得到字符向量</p>
<p>将得到的两个向量拼在一起扔进一个全连接层 + ReLU 激活以得到最后的综合表示 lexicon embedding，则可以得到文章 passage 的表示 $L_P \in R^{d<em>n}$ 和 问题的表示 $L_Q \in R^{d</em>m}$</p>
<h4 id="Context-Embedding-Layer">Context Embedding Layer</h4>
<p>图中红色部分，分别对文章和问题来做</p>
<p>也就是分别将文章和问题编码好的 lexicon embedding 扔到一个 <strong>参数共享的双向 LSTM = BiLSTM</strong> 中，这里的隐藏层维度为 d/2（d 是前面 embedding 的维度），此时进一步地将前向和后向的输出直接作向量拼接，分别得到文章的上下文表示 $C_P\in R^{d<em>n}$ 和问题的上下文表示 $C_Q\in R^{d</em>m}$</p>
<h4 id="Coarse-Memory-Layer">Coarse Memory Layer</h4>
<p>黑色部分，将 question 与 passage 融合</p>
<p>也就是通过  knowledge aided mutual attention （这个在下一节介绍）来实现 question 和 passage 的 context embedding 的融合，再通过一个 <strong>BiLSTM</strong>（隐藏层的大小还是 d/2），将前后的输出作向量拼接得到最终表示 G，这里的 G 也就是融合了问题信息的文章表示（question-aware passage representations）</p>
<h4 id="Refined-Memory-Layer">Refined Memory Layer</h4>
<p>橙色部分</p>
<p>利用 knowledge aided self-attention （下面介绍）将上一部分得到的 融合了问题信息的文章表示（question-aware passage representations） 进行进一步的聚合</p>
<p>将输出还是通过一个隐藏层为 d/2 的 <strong>BiLSTM</strong>，同理将前后的输出作向量拼接得到最终表示 H，这里的 H 也就是最终的文章表示</p>
<h4 id="Answer-Span-Prediction-Layer">Answer Span Prediction Layer</h4>
<p>绿色部分，目标是得到答案的 span，也就是开始和结束位置</p>
<p>将问题的上下文表示，也就是 C_Q 经过一个 <strong>attention pooling</strong> 得到 $r_Q$，计算答案开始 span 对应的概率：<br>
$$<br>
t_i = v_s ^T  \tanh (W_s h _{p_i} + U_s r_Q) \in \mathbb{R}<br>
$$</p>
<p>$$<br>
o_s = softmax({t_1, ..., t_n}) \in \mathbb{R} ^n<br>
$$</p>
<p>这里的  W 和 U 和 v 都是待学习参数，实际上就是一个连接层 + tanh 激活 + softmax 输出概率</p>
<p>同理，得到 os 开始概率后来预测结束的概率：<br>
$$<br>
t_i = v_e^T \tanh {(W_e h _{p_i} + U_e [r_Q; Ho_s])} \in \mathbb{R}<br>
$$</p>
<p>$$<br>
o_e = softmax ({t_1, ..., t_n}) \in \mathbb{R}^n<br>
$$</p>
<p>预测结束后，得到一个预测矩阵：$$O = uptri(o_so_e^T)\in R^{n*n}$$，注意这里的 uptri 指的是得到该矩阵的上三角矩阵</p>
<p>这里的损失函数也就是针对每一个真实答案的开始位置 as 和结束位置 ae，最小化 $-log(O_{a_s,a_e})$</p>
<br>
<h3 id="3-3-Knowledge-Aided-Mutual-Attention-知识辅助注意力">3.3 Knowledge Aided Mutual Attention 知识辅助注意力</h3>
<p>注意这东西是用在 <strong>Coarse Memory Layer</strong> 中的，这里利用问题和文章的上下文表示 $C_P, C_Q$ 来进行聚合操作</p>
<p>注意力聚合也就是计算文章中的每一个 embedding $c_{p_{i}}$ 和问题中的每一个 embedding $c_{q_i}$ 的相似度，这里的相似度方程定义为：<br>
$$<br>
f(c _{p_i}, c _{q_j}) = v_f^T [c _{p_i}; c _{q_j} ; c _{p_i} \odot c _{q_j}] \in \mathbb{R}<br>
$$</p>
<p>这里的 vf 也就是训练参数，而 $\odot$ 表示元素之间的乘法，但是考虑到此时我们需要将 <strong>外部知识 = 常识引入</strong>，则采用上述式子改进的式子：<br>
$$<br>
f^* (c _{p_i}, c _{q_j}) = v_f^T [c ^* _{p_i}; c ^* _{q_j} ; c ^* _{p_i} \odot c ^* _{q_j}] \in \mathbb{R}<br>
$$</p>
<p>为得到这里的 c* 作如下操作：</p>
<ul>
<li>
<p>对于当前词汇 w，得到它对应的 Ew，也就是所有（和词汇 w 存在 κ-hop 内同义词关系且在文章内的词在文章中的位置信息）</p>
</li>
<li>
<p>找到 Ew 中所有的词汇对应的 context embedding 的集合，记作 $Z \in R^{n*|E_w|}$</p>
</li>
<li>
<p>计算对应的 c+：<br>
$$<br>
\begin{align}<br>
t_i &amp;= v_c^T \tanh (W_c z_i + U_cc_w) \in \mathbb {R} \\<br>
c_w ^+ &amp;= Z softmax({t_1, ..., t _{|E_w|}}) \in \mathbb{R} ^d<br>
\end{align}<br>
$$</p>
<p>这里的 vc 和 W 和 U 都是训练参数，将得到的 c+ 和 c 作向量拼接，再通过一个 ReLU 激活函数，最后输出维度为 d，记作 c*</p>
</li>
</ul>
<p>得到 c* 后，我们可以通过上面的公式计算问题和文章的相似度矩阵，记作 A，则此时 A 的 i,j 位置元素也就是文章的第 i 个 embedding 和问题的第 q 个embedding 之间的相似度</p>
<p>通过 A 来计算（融合了问题信息的文章表示）和（融合了文章信息的问题表示）：<br>
$$<br>
\begin{align}<br>
R_Q &amp;= C_Q \text{ softmax} _r^T (A) \in \mathbb{R} ^{d \times n} \\<br>
R_P &amp;= C_P \text{ softmax} _c (A) \text{ softmax} _r^T (A) \in \mathbb{R} ^{d \times n}<br>
\end{align}<br>
$$</p>
<p>这里的 softmax r 是只d对行作 softmax，softmax c 是对列</p>
<p>最后将 $C_P, R_Q, C_P\odot R_Q, R_P\odot R_Q$ 作向量拼接，再扔进一个全连接层 + ReLU 激活函数，注意这里的输出维度还是 d，作为最终结果</p>
<br>
<h3 id="3-3-Knowledge-Aided-Self-Attention-知识辅助自注意力">3.3 Knowledge Aided Self Attention 知识辅助自注意力</h3>
<p>和前面的思路是一样的，但是注意因为作自注意力的时候，实际上大多数文章中的单词和其他单词之间是没啥关系的， 如果用惯用的自注意力的方式会浪费资源</p>
<p>考虑文章中的单词 pi，对应的 coarse memory 层的输出为 $g_{p_i}$，同理我有这个词对应的外部常识集合 $E_{p_i}$，得到其中的 word 对应的 coarse memory 的集合，记作 Z，这里计算 g+：<br>
$$<br>
t_i = v_g^T \tanh (W_g z_i + U_g g _{p_i}) \in \mathbb{R}<br>
$$</p>
<p>$$<br>
g _{p_i}^+ = Z \text{ softmax} ({t_1, ..., t _{|E _{p_i}}}) \in \mathbb{R} ^d<br>
$$</p>
<p>注意这里的 g+ 本质上是基于 gpi 的 Z 的信息的融合</p>
<p>进一步将 g+ 和 g 作拼接，再通过一个全连接层 + ReLU激活，最后得到该部分的输出 H</p>
<br>
<br>
<hr>
<h2 id="4-experiment-实验部分">4 experiment 实验部分</h2>
<p>这里的 MRC 部分的数据集用的是 <strong>SQuAD 1.1</strong>，但是考虑到本身提出 KAR 的目标就是要 <strong>利用外部知识（常识）来增强当前 MRC 模型的鲁棒性</strong>，故这里采用 <strong>AddOneSent 和 AddSent</strong> 向 SQuAD 添加噪声，再评估模型</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022054918162.png" alt="image-20231022054918162" style="zoom:50%;" />
<p>可以看到此时鲁棒性确实增强了</p>
<p>另一个提出的目标是 <strong>通过数据增强的方法常识在更小的训练集上获得更好的效果</strong>，来看看训练效果和训练的数据集的关系：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022054953766.png" alt="image-20231022054953766" style="zoom:67%;" />
<p>确实训练集越小此时效果下降越明显，但是还是比现有的几个方法要高，可以热为此时引入常识确实是有帮助的</p>
<p>下面看一下超参数，特别是常识提取部分的 κ-hop</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022055023970.png" alt="image-20231022055023970" style="zoom:60%;" />
<p>可以看到这里做到 3-hop 就比较好了</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>Retro-Reader: 基于回溯式阅读器的机器阅读理解模型</title>
    <url>/2023/10/30/20210317-paper-note-RetroReader/</url>
    <content><![CDATA[<p>原文写于 20210317，存档如下</p>
<blockquote>
<p>Zhuosheng Zhang, Junjie Yang, Hai Zhao, Department of Computer Science and Engineering, Shanghai Jiao Tong University, <strong>Retrospective Reader for Machine Reading Comprehension</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzIwMDEuMDk2OTR2NC5wZGY=">https://arxiv.org/pdf/2001.09694v4.pdf<i class="fa fa-external-link-alt"></i></span><br>
源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2Nvb2VsZi9Bd2Vzb21lTVJD">https://github.com/cooelf/AwesomeMRC （**official）<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<p>当前是 SQuAD 上第四名的成绩（2020/3/16）看了看作者主页应该是被 AAAI2021 接收了</p>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br>
<p>当前大多机器阅读理解模型大多建立在（所给定的问题都是可以回答的 = 在原文的某一个范围内一定存在答案）的假设上，但是真实的业务场景并不如此。举个例子（来自 SQuAD2.0 MRC task）：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022055414086.png" alt="image-20231022055414086" style="zoom:60%;" />
<p>此时要求机器能够判别当前的问题是否真的是可以回答的，而不是对于任何问题都勉强给出一个似是而非的答案。基于此我们的主要任务包括：1）检查问题的可回答性 answerability; 2)对可以回答的问题再作进一步的阅读理解</p>
<p>也就是说此时除了传统的 MRC 所重点关注的 encoder 模块，我同时需要一个 verification 的部分来区分这些不可回答的问题，而当前的大多数模型要么直接假设所有的问题都是可以回答的，要么就是单纯地将所有的 verification 的模块简单地集成入了 encoder 或者 decoder 的部分，而这样的操作往往效果不是很好</p>
<p>传统的 MRC 模型主要包括以下几个结构设计：</p>
<ul>
<li>直接的 encoder + decoder 的模型，也就是说此时认为所有的问题都是可以回答的，直接不对本身的问题作 verification<br>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022055456837.png" alt="image-20231022055456837" style="zoom:67%;" /></li>
<li>将 verification 的部分包括在 encoder 内或者 decoder 内，但相对地效果不佳<br>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022055527245.png" alt="image-20231022055527245" style="zoom: 67%;" /></li>
</ul>
<p>考虑一下真的人类是怎么做的：先通读一遍文章 + 再重新回到文章中进行精度进一步确认答案。基于人类的行为，这里提出一个新的模型 <strong>retrospective reader (Retro-Reader)</strong>，主要执行以下两个步骤：</p>
<ul>
<li>粗略地阅读文章，并掌握文章和问题之间的关系，给出一个初始的判断</li>
<li>进一步精度文章，再验证答案并给出最后的预测</li>
</ul>
<p>简单表示如下：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022055650407.png" alt="image-20231022055650407" style="zoom:67%;" />
<br>
<br>
<hr>
<h2 id="2-Our-Proposed-Model-模型介绍">2  Our Proposed Model 模型介绍</h2>
<br>
<h3 id="2-1-overview">2.1 overview</h3>
<p>这里主要关注的还是抽取式的阅读理解问题（ span-based MRC task），也就是目标为在文档中划出一个 span 来作为答案。</p>
<p>也就是说此时给定的信息为一个 &lt;文章 P ，问题 Q，答案 A &gt; 的三元组，则此时我们的任务是 1）从给定的文章 P 中进行 A 开始和结束位置的预测 = 在文中划出一个 span 作为候选答案 2）或对于不可回答的问题，回复一个 null 表示此问题本身是得不到答案的</p>
<p>本文将阅读理解任务分为两个阶段（two-stage reading process）：</p>
<ul>
<li><strong>sketchy reading</strong>：通过略读大概掌握关系并给出一个粗糙的判断，这一步的主要目标是初步判断这个问题是不是可以回答的</li>
<li><strong>intensive reading</strong>：通过精读进一步得到候选答案（也就是得到 answer span）+ 最后判断问题是否是可以回答的 + 给出最后的预测</li>
</ul>
<p>整体模型结构如下：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022055725058.png" alt="image-20231022055725058" style="zoom:70%;" />
<br>
<h3 id="3-2-Sketchy-Reading-Module-泛读模块">3.2  Sketchy Reading Module 泛读模块</h3>
<h4 id="Embedding">Embedding</h4>
<p>这部分的目标是通过一些预训练模型得到 P 文章和 Q 问题的向量表示（embedding），将两个向量表示作拼接，再将这些表示作为输入扔给后面的部分</p>
<p>具体来说，首先将输入的句子通过 tokenizer 切割为词语 / subword，比如此时切割为 n 个，记作 $T = {t_1, ... , t_n}$；每一个 subword 的 token 都是三个部分的加和：<strong>自身的 token + 位置 embedding + token 类型 embedding</strong>，设最后的输出为 $X = {x_1 ,x_2, ... , x_n}$</p>
<h4 id="Interaction">Interaction</h4>
<p>将上一步 embedding 得到的最后输出 X 作为输入，目标为得到输入的上下文表示</p>
<p>这里可以通过一个多层 Transformer（multi-layer Transformer）的 encoder 部分来实现（本身 Transformer 就是编码器 - 解码器的结构，Transformer 详解 <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NTIyNjg4L2FydGljbGUvZGV0YWlscy8xMTQ1NTg5ODY=">戳这里<i class="fa fa-external-link-alt"></i></span>），设最后一个隐藏层的输出为 $H = {h_1,h_2,...,h_n}$</p>
<h4 id="External-Front-Verification-（E-FV）">External Front Verification （E-FV）</h4>
<p>得到上一步给出的上下文表示，可以认为此时机器已经完成了通读任务，但是此时需要机器给出一个粗糙的判断，此时通过 E-FV 来构造一个二分类器，让机器来初步判断此时的问题是不是可以回答的</p>
<p>这里的输入是上一层输出的隐藏层的值 H，将 H 的第一个 token，也就是 [CLS] 对应的部分，也就是 h1 作为整个序列的表示，直接扔进一个全连接层（注意不是扔全部的 H，只要 h1 部分就行）来判断此时的问题是否是可以回答的。给出的输出是预测概率 $\hat{y_i}$：$$\hat{y_i}\varpropto softmax(FFN(h_1))$$</p>
<p>用交叉熵函数来训练：<br>
$$<br>
\mathbb{L} ^{ans} = -\frac {1}{N} \sum^N _{i=1} [y_i \log {\hat{y} _i} + (1-y_i) \log (1-\hat{y}_i)]<br>
$$</p>
<p>注意这里同时计算了一个 external verification score，在后面的部分会用到这个值：$$score_{ext} = logit_{na} - logit_{ans}$$，注意这里的 na 表示问题不能回答，ans 表示可以回答</p>
<br>
<h3 id="3-3-Intensive-Reading-Module-精读模块">3.3  Intensive Reading Module 精读模块</h3>
<p>这一部分的模型需要完成：</p>
<ul>
<li>最后拍板到底是不是可以回答的问题</li>
<li>给出候选答案，也就是预测 span</li>
<li>给出最后的预测结果</li>
</ul>
<h4 id="Embedding-interaction">Embedding + interaction</h4>
<p>和前面略读部分是一样的（原理一样但并不是共享参数，是两个独立训练的部分），最后获得文章 P 和问题 Q 的上下文表示 $H$，但是注意到和普通的 BERT 模型之流不一样的地方在于，此时并不是直接将上下文表示送进一个线性层来预测结果，而是后续备用继续处理</p>
<p>个人感觉这里不太对，问题在于等于要作两遍上下文表示训练，因为本身这个模型的略读和精读模块就是并行的，只是将它们的输出做了一个融合，而并不是让它俩耦合从而存在一种互相依赖的关系，则这里的两个上下文表示应该是并行训练的，这内存消耗（一言难尽（</p>
<h4 id="Question-aware-Matching">Question-aware Matching</h4>
<p>此时的输入是 embedding + interaction 得到的表示 H，首先注意到 H 本身是带有位置 embedding 的，将 H 分为两个部分，分别对应文章 $H^P$ 和问题对应的 $H^Q$（或者说这里的输入表示本身就是 $[CLS],Q,[SEP]P,[SEP]$ 的形式，切分还是很方便的）</p>
<p>这里想要作 question aware，这里可以用如下两个注意力：</p>
<ul>
<li>
<p><strong>交叉注意力 multi-head cross attention (CA)：</strong><br>
这里实际上是一个多头注意力，查询向量为 $H^P$，键K = 值V = $H$</p>
<ul>
<li>这里的 Q 共有 p 个 token，此时也就是 p*d 的维度（d 是 embedding 的维度），此时是多头注意力，也就相当于存在 p 个查询向量，每一个向量都能够对应得到一个注意力分布，得到一个综合后的 V = H 的表示，也就是一个向量</li>
<li>这里的多头注意力的最后的输出的维度应该是和 $H^P$ 相同的，可以看作是一个文章 embedding 经过 question 的注意力后的一个表示</li>
</ul>
</li>
<li>
<p><strong>匹配注意力 Matching Attention：</strong><br>
实际上也就是一个普通的注意力模块，利用问题表示 $H^P$ 来计算 H 的注意力分布<br>
$$<br>
\begin{align}<br>
M &amp;= \text{softmax} (H (WH^Q + b \otimes e)^T) \\<br>
H' &amp;= MH^Q<br>
\end{align}<br>
$$</p>
</li>
<li>
<p>这里的 H 的注意力后的表示计算如下，W b 可学习，e 是一个全是 1 的向量</p>
</li>
<li>
<p>和前面不同的是这里直接用 $H^Q$ 作为整个查询，也就是说最后得到的表示和 H 本身是同大小的，可以认为这里得到的 H‘ 是一个 passage + question 集合的上下文表示 H 对应的 question 注意力后的表示</p>
</li>
</ul>
<h4 id="Span-Prediction">Span Prediction</h4>
<p>将上面得到的 H’ 扔进来预测候选答案，也就是确定 span</p>
<p>具体操作也就是扔进一个全连接层 + softmax 输出每一个 token 分别是 start 位点 和 end 位点的概率 $$s,e \varpropto softmax(FFN(H'))$$</p>
<p>这里的损失函数还是用的交叉熵函数：<br>
$$<br>
\mathbb{L} ^{span} = - \frac{1}{N} \sum ^N _i [\log (p^s _{y_i^s}) + \log (p^e _{y^e_i})]<br>
$$</p>
<p>这里对应的 $y_i^s$ 也就是第 i 个位置到底是不是 gold answer 的开始位点的 0-1 标签，后面的 $y_i^e$ 同理</p>
<h4 id="Internal-Front-Verification-（I-FV）">Internal Front Verification （I-FV）</h4>
<p>再来进一步确认这个问题是不是可以回答的，输入为上面得到的表示 $H'$ 的第一个表示 $h_1$，将 h1 扔进一个全连接层，再通过（基于分类方法）或（基于回归方法）得到最终的概率</p>
<p>这里还是给定几个可选的方法：</p>
<ul>
<li>
<p><strong>直接作 softmax</strong>：也就是将全连接层的输出通过一个 softmax，再利用交叉熵进行训练<br>
$$<br>
\begin{align}<br>
\bar {y} _{i,k} &amp;= \text{softmax} (FFN(h_1')) \\<br>
\mathbb {L} ^{ans} &amp;= - \frac{1}{N} \sum _{i=1}^N \sum _{k=1} ^K [y _{i,k} \log \bar{y} _{i, k}]<br>
\end{align}<br>
$$</p>
</li>
<li>
<p><strong>用二元交叉熵函数作损失函数</strong>：也就是说这里通过一个 sigmoid：<br>
$$<br>
\begin{align}<br>
\bar{y} _i &amp;= \text{sigmoid} (\text{FFN} (h_1)) \\<br>
\mathbb{L} ^{ans} &amp;= - \frac{1}{N} \sum _{i=1} ^N [y_i \log {\bar{y} _i} + (1-y_i) \log (1-\bar{y}_i)]<br>
\end{align}<br>
$$</p>
</li>
<li>
<p><strong>用回归 regression 的思想来处理</strong>：直接用 MSE 来作损失函数：<br>
$$<br>
\begin{align}<br>
\bar{y} _i &amp;= FFN(h_1') \\<br>
\mathbb{L} ^{ans} &amp;= \frac{1}{N} \sum _{i=1}^N (y_i - \bar{y}_i)^2<br>
\end{align}<br>
$$</p>
<p>注意到这里实际上我们存在两个任务 → 也就是预测是否是可以回答的问题，一个是确定此时的答案 span，则此时的最终损失函数应该是 verification 部分的损失函数和 answer predicate 两个部分的损失函数：<br>
$$<br>
\mathbb{L} = \alpha_1 \mathbb{L} ^{span} + \alpha_2 \mathbb{L} ^{ans}<br>
$$</p>
<p>这里以某一个权重 αi 来对两个损失函数作融合</p>
</li>
</ul>
<h4 id="Threshold-based-Answerable-Verification">Threshold-based Answerable Verification</h4>
<p>最后拍板问题是不是可回答的</p>
<p>此时令该问题对应的文章中各个 token 为开始 / 结束位置的概率的向量分别为 s 和 e，则分别计算：存在答案的得分 $score_{has}$ 和不存在答案的得分 $score_{null}$：<br>
$$<br>
\begin{align}<br>
score _{has} &amp;= \max(s_k + e_l) \text{ , } 1&lt;k\leqslant l \leqslant n \\<br>
score _{null} &amp;= s_1 + e_1<br>
\end{align}<br>
$$</p>
<p>这里继续计算上面两个概率的差值：$$score_{diff} = score_{has} - score_{diff}$$​ 留下备用</p>
<br>
<h3 id="3-4-Rear-Verification">3.4 Rear Verification</h3>
<p>也就是最后确认到底有没有答案</p>
<p>注意到这里同时有两个 verification，也就是 E-FV 和 I-FV，分别代表（略读后对问题是否有答案的判定）和 （精读后对问题是否有答案的判定），此时考虑以某种方式将它们融合起来</p>
<p>定义：<br>
$$<br>
v = \beta_1 score _{diff} + \beta_2 score _{ext}<br>
$$</p>
<p>这里的 $\beta_1$ 和 $\beta_2$ 是对应权重，将这里的 v 认为是最终判断有答案的概率，如果这个 v &gt; 预先设定的阈值 $\delta$，此时认为问题确实存在答案，反之不存在，且返回一个空字符串作为 span 预测的结果</p>
<br>
<br>
<hr>
<h2 id="4-experiment-实验部分">4 experiment 实验部分</h2>
<p>用到的数据集包括 <strong>SQuAD2.0</strong> 和 <strong>NewsQA</strong>，是两个确实引入了回答不了的问题的数据集</p>
<p>看看在 SQuAD 上的效果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022061101106.png" alt="image-20231022061101106" style="zoom:67%;" />
<p>这里的 TAV 也就是直接使用 score_diff 的部分（上面 3.3 的最后一部分）来判断到底有没有答案，如果 score_diff 确实大于某一个阈值 δ 则认为有答案。也就是说 TAV 本身没有用到 E-FV 给出的判断。通过比较可以看到此时同时设置 E-FV 和 I-FV 或许真的可以帮助提升</p>
<p>再看看在 newsQA 的效果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231022061124279.png" alt="image-20231022061124279" style="zoom:67%;" />
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>EPAr: 探索+提议+组装：多跳阅读理解的可解释模型</title>
    <url>/2023/10/30/20210318-paper-note-EPAr/</url>
    <content><![CDATA[<p>原文写于 20210318，存档如下</p>
<blockquote>
<p>Yichen Jiang, Nitish Joshi, Yen-Chun Chen Mohit Bansal ; UNC Chapel Hill <strong>Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MDYuMDUyMTAucGRm">https://arxiv.org/pdf/1906.05210.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ppYW5neWNUYXJoZWVsL0VQQXI=">https://github.com/jiangycTarheel/EPAr<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br>
<p>多跳阅读理解问题为当前的阅读理解问题提出了新的挑战，在这里首先解释以下什么是多跳阅读理解问题，这里还是借用 CogQA 论文里的例子：</p>
<p><strong>多跳阅读理解问题</strong> 可以直观地理解为需要多次跳转，将不同的信息进行进一步整合才能得到答案的阅读理解问题。举个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021084007009.png" alt="image-20231021084007009" style="zoom: 80%;" />
<p>这个问题本身问的是导演，但是没有给出电影的名字，首先需要后面的信息去推断是哪一部电影，才能进一步去寻找该电影的导演。直观理解就是此时需要从多个文档中收集信息并经过一定的多重推导过程才能得到最后答案。</p>
<p>简单来说，正确求解多跳阅读理解问题需要模型掌握（将来自于不同位置的信息作联合 + 统一分析）的能力，需要模型定位不同的信息（这里的信息是分散在不同的位置的），对相关的信息作整合，再将问题和文本的信息作联系。这样的任务为当前的机器阅读理解模型提出了几个新的挑战：</p>
<ul>
<li>此时输入的文本往往较长（甚至是多文档的，跨文档的），而大多数 MRC 模型往往难以对这么长的文本直接作处理，也就是说此时或许需要先提取问题和文本之间的逻辑关系，再有选择地构造逻辑链，再作下一步处理</li>
<li>由于此时本身是多跳的阅读理解问题，即使在已经给定了相关的逻辑链的情况下，也需要模型能够将分布在不同位置的信息作整合，再最后给出答案</li>
<li>考虑此时可能存在很多不同的逻辑链均能够连接分散的证据信息，需要模型衡量不同逻辑链 / 路径的不同的权重并将它们所提供的信息作整理</li>
</ul>
<p>传统的模型往往从如下几个思路出发来解决上述的问题：</p>
<ul>
<li>只着重阅读和问题相关的部分文档，而不是直接阅读全部部分的文档</li>
<li>阅读过程中每一个 hop 只阅读一个文档，并更新整体的记忆细胞，再选择下一个文档来阅读</li>
<li>再进行推断部分，从词语级别的角度来顺着逻辑链条来进行逻辑推断并预测最后的答案</li>
</ul>
<p>但是注意到上面的模型本身是存在缺陷的，举个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023095120511.png" alt="image-20231023095120511" style="zoom:80%;" />
<p>注意上面的例子，如果此时一个问题存在多个可能的推理路径，以上传统模型的思路会造成问题：此时通过问题文本定位到文档一，但是文档一出发可以有两条可能的路径，分别对应文档 2 和 3，而此时的模型并没有能力判断到底那一条推断路径是正确的，或者可能发现某一条路径后就直接沿着推断，而并没有关注可能的多条逻辑路径。也就是说，我们希望模型可以衡量不同的推断路径的权重并综合不同路径表示的不同的信息</p>
<p>本文提出的解决思路为：将前述 搜索文档并寻找逻辑路径 的部分循环执行多次，以得到多条发散的逻辑路径，也就是从一个点发散的，类似于树的结构。再进一步基于这个树的结构来寻找最终的预测答案：寻找所有的 根 → 叶子 的路径的综合表示，则此时得到不同的跨文档的推断路径表示，再根据这样的表示和问题之间的相关关系来寻找最后正确的路径，以引向正确的答案。通过这样的树的结构，也就将原本的跨文档的，分散的信息作了进一步的综合，不同的路径表示的也就是不同的推断逻辑。得到这样的综合信息表示后，原本的多跳阅读理解问题也就可以转化为一个简单的 QA 问题。</p>
<p>基于上述思路，原文将三个部分作整合，提出新模型 <strong>EPAr (Explore-Propose-Assemble reader)</strong>，以通过探索（explore）+ 提议（propose）+ 整合（assemble）三个模块来实现对多跳阅读理解问题的解答</p>
<br>
<br>
<hr>
<h2 id="2-Model-模型结构">2 Model 模型结构</h2>
<br>
<h3 id="2-1-overview">2.1 overview</h3>
<p>先来看看模型的整体结构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023095156568.png" alt="image-20231023095156568" style="zoom:60%;" />
<p>整个模型可以分为三个部分：</p>
<ul>
<li><strong>Document Explorer (DE) 文档搜索</strong>：本身是一个 T-hop 的文档搜索模型，每次选择一个文档进行阅读并更新 memory cell，再循环地选择不同的文档作为下一个阅读目标，任务为搜索所有相关的信息并组成可能的逻辑推断链条（reasoning chain）</li>
<li><strong>Answer Proposer (AP) 答案提议</strong>：也就是基于上一步得到的逻辑链条进行逻辑推断（词级别的推断），并给出可能的答案预测</li>
<li><strong>Evidence Assembler (EA) 证据组装</strong>：也就是同时综合所有可能的逻辑推断链条给出的证据，敲定最后的答案</li>
</ul>
<p>此时整体模型实际上模拟的是人类的阅读行为：先通过粗读（也就是 DE 部分）得到大概的逻辑链条，再通过当前掌握的逻辑给出几个可能的答案（AP 部分），最后通过精读敲定答案</p>
<p>这里三个模块都有对应的损失，最后训练的时候是整体训练的，最小化三个模型的损失和</p>
<p>进一步注意，由于原论文实验的数据集主要为 <strong>WikiHop 和 MedHop</strong>，这两个数据集对应的问题是分为两个部分的：1）subject，例如 The Haunted Castle，是问题对应的对象，记作 $q_{sub}$；2）body，也就是具体问题，一般指示的是问题对象 subject 和答案之间的关系，例如 located in the administrative territorial entity，记作 $q_{bod}$；</p>
<p>每一个问题对应一个候选答案的集合，记作 $A = {c_1,...,c_L}$（注意这里是给出了候选答案集合的，不是抽取式的确定 span，有点让模型做选择题的意思 / 这里用到的 WikiHop 也本身就是（问题三元组，答案选择题）的形式），每一个问题存在一个 gold answer，记作 $a$，此时三者之间满足逻辑：$q_{bod}$ 表示 $q_{sub}$ 和 $a$ 之间的关系</p>
<br>
<h3 id="2-2-Retrieval-and-Encoding-检索和编码">2.2 Retrieval and Encoding 检索和编码</h3>
<h4 id="retrieval-支持文档的预筛选">retrieval 支持文档的预筛选</h4>
<p>令此时给定的文档 D 共有 N 篇，注意到如果将全部的文档都扔进系统会带来巨大的计算开销，故这里先采用一个 <strong>2-hop 的文档检索</strong> 对所有文档作筛检处理：</p>
<ul>
<li>首先选取和给定的问题有最短的 TF-IDF 距离的文档（这也就是 1-hop）</li>
<li>再计算所有余下文档和第一个文档之间的 TF-IDF 距离，选择最近的 $N'-1$ 篇文档（也就是 2-hop）</li>
</ul>
<p>此时得到的 N‘ 篇文档则是我们会扔进模型的支持文档。注意这里预先作 retrieval 操作的意义：1）大大减少了计算开销；  2）通过预先缩小 DE 部分的搜索范围，使得 DE 部分的训练更有效</p>
<h4 id="encoding-编码表示">encoding 编码表示</h4>
<p>这里采用 GloVe embedding 来得到文档和问题的表示（词级别），编码维度记作 d，则此时输出三个矩阵：$X\in R^{N' * K * d}; Q_{sub} \in R^{J_s<em>d}; Q_{bod} \in R^{J_b</em>d}$</p>
<p>再进行以下处理以得到不同角度下的信息表示：</p>
<ul>
<li>
<p>通过一个 <strong>双向 LSTM-RNN</strong> 来得到文档和问题的上下文表示，隐藏单元个数设为 v，此时对于 N' 个候选文档的集合：$H = {h_1,...,h_{N'}} ； h_i \in R^{K<em>2v}$，同理对于问题：$U_{sub} \in R^{J_s</em>2v}；U_{bod} \in R^{J_b*2v}$</p>
</li>
<li>
<p>利用 <strong>自注意力模块</strong> 得到  N’ 个支持文档的压缩综合表示，记作 $P = {p_1, ... , p_{N'}}$（<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NTIyNjg4L2FydGljbGUvZGV0YWlscy8xMTQ1MDE3MjA=">自注意力部分看这里<i class="fa fa-external-link-alt"></i></span>）</p>
</li>
<li>
<p>对于候选答案集合 A 中的任意一个候选答案 ci，找到 ci 在支持文档集合 H 中第一次被提及的位置（也就是 H 中第一个提及了 ci 的文档）（这里作者表示用了不同位置的 mention 做实验，结果差距不大），将该文档中对 ci 包含的几个词（这里的 ci 可以是多个单词）的 embedding 做 <strong>平均</strong>（也就是多个向量的元素对元素的平均，得到一个新的向量），将平均的 embedding 作为候选答案 ci 的 embedding</p>
</li>
</ul>
<br>
<h3 id="2-3-Document-Explorer-DE-文档探索">2.3 Document Explorer (DE) 文档探索</h3>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023095246334.png" alt="image-20231023095246334" style="zoom:80%;" />
<p>本质是一个层级的记忆网络，主体利用的为 GRU，目标是通过循环建立多文档的逻辑链（reasoning chain）。在每一步的时候都选择一个和当前的记忆状态相关联的文档并更新内部记忆</p>
<h4 id="Read-Unit">Read Unit</h4>
<p>先计算一个衡量候选文档（这里用前面得到的文档自注意力处理后的 P 来表示）和当前记忆状态 m 相关程度的分布，这里采用的是双线性的方法计算相似度，具体如下：<br>
$$<br>
\begin{align}<br>
&amp;x_n = p_n^T W_r m^t \\<br>
&amp;\chi  = \text{softmax}(x) \\<br>
&amp;P(d_i) = \chi_i<br>
\end{align}<br>
$$</p>
<p>得到分布 P 后，通过<strong>采样</strong>的方式选取出一个文档来作为后续处理的目标文档，记作 di（注意这里每次只是对一个文档进行操作）</p>
<h4 id="Write-Unit">Write Unit</h4>
<p>计算上一步得到的目标文档 di 中每一个词表示 hi 和当前记忆状态 m 的相关程度，并得到一个关联程度的分布 ω，计算方式如下：<br>
$$<br>
\begin{align}<br>
w_k &amp;= h_k^T W_w m \\<br>
\omega &amp;= \text{softmax}(w)<br>
\end{align}<br>
$$</p>
<p>通过分布 ω  对每一个词表示 hi 作加权整合，得到进一步的文档 di 的表示 $\tilde{h}$​，将这一表示和当前的记忆状态 m 一起扔进 GRU，更新记忆状态 m<br>
$$<br>
\begin{align}<br>
\tilde{h} &amp;= \sum _{k=1} ^K h_k\omega_k \\<br>
m ^{t+1} &amp;= GRU(\tilde{h}, m^t)<br>
\end{align}<br>
$$</p>
<h4 id="T-hop-reasoning-tree">T-hop + reasoning tree</h4>
<p>此时将上述步骤重复 T 次，要求每一次选择的目标文档 di 都是没有被选择过的，则此时可以得到 T 个不重复的文档组成的序列，记作 $\hat{H} = {\hat{h}_1, ... , \hat{h}_T}$，每更新一次记忆状态 m 就选取出一个文档 hi，上述序列展示了 T-hop 的一个文档选取，且得到的序列 $\hat{H}$ 本身也就是一条文档的逻辑推断链条（reasoning chain）</p>
<p>将上述步骤再重复多次，此时可以得到多个 reasoning chain，组成文档搜索的 reasoning tree，此时每一个从根到叶子的路径都是一个可能的答案推断逻辑</p>
<br>
<h3 id="2-4-Answer-Proposer-AP-答案提议">2.4 Answer Proposer (AP) 答案提议</h3>
<p>每一次选取一条 reasoning tree 中的路径（也就是一条 reasoning chain）作为输入，并从这条 chain 的最后一个文档 $h_T$ 中给出一个可能的答案</p>
<p>此时记最后一个文档 $h_T\in R^{K*2v}$，则先将 h_T 放入一个 <strong>LSTM-RNN</strong> 并经过注意力编码（注意这里是前面的 T-1 个文档参与的注意力）以得到 ${h_1,...,h_{T-1}}$-aware 的表示，记作 y</p>
<p>同时计算文档表示 $h_T$ 中每一个词 hi 和当前的问题表示之间的相关关系，以得到相似程度的分布，并利用对应的权重计算得到新的词表示的集合，记作 $\tilde{h}_T = {h_T^1, ... , h_T^K}$</p>
<p>此时选择所有的候选答案集 A 中和上述得到的 $\tilde{h}_T$ 最为相似的候选答案 ci 作为此时给出的预测答案</p>
<p>注意这里的计算方式：<br>
$$<br>
\begin{align}<br>
e_i^k &amp;= v^T \tanh(W_h \hat{h} ^i _{cct} + W_s s^k + b) \\<br>
a^k &amp;= \text{softmax}(e^k) ; \text{ } c^k = \sum_i {a_i^k h^i _{cct}} \\<br>
y^k &amp;= LSTM(\hat{h} _T ^{k-1} , s ^{k-1}, c ^{k-1}) \\<br>
w^k &amp;= \alpha(y^k, u_s) + \alpha(y^k, u_b); \text{ } \epsilon = \text{softmax}(\omega) \\<br>
a &amp;= \sum _{k-1} ^K \hat{h}_T^k \epsilon_k; \text{ } Score_l = \beta(c_l, a)<br>
\end{align}<br>
$$</p>
<p>这里的 $\hat{h}<em>{cct}^i = [\hat{h}</em>{1,..., T-1}]$ 是所有的前 T-1 个文档的向量拼接（在词的 dimension 上拼接)，$u_s$ 和 $u_b$ 分别是 $U_{sub}$ 和 $U_{bod}$ 的最终表示，$s^k$ 是 LSTM 第 k 步隐藏层的输出，此时计算每一个 $c_l \in A$ 对应的 $score_l$，选择得分最高的 $c_l$ 作为此时的答案预测结果</p>
<p>注意这里得到了整个逻辑链条上的文档的综合表示，也就是说并不是只考察了整个逻辑链条的最后 leaf 的文档 $h_T$，而是将整个逻辑链条的序列均纳入考虑，并综合表示了 root 文档和 leaf 文档之间的交互关系</p>
<p>综上，此时不断从 reasoning tree 中选择不同的 reasoning chain，重复进行 AP 的操作，则可以得到多个逻辑链条对应的多个预测答案 $c_l$</p>
<br>
<h3 id="2-5-Evidence-Assembler-EA-证据组装">2.5 Evidence Assembler (EA) 证据组装</h3>
<p>注意因为此时存在多个可能的逻辑推理链条，可以得到多个可能的答案。这里通过 EA 来实现多条逻辑链提供的信息的聚合，并进一步从上面得到的多个 $c_l$ 中拍板得到最终的预测结果</p>
<p>首先将所有的包含了任意一个候选答案 $c_l$ 的句子都提取出来，组成一个新的文档 h’，这里的 文档 h’ 也就是一个信息高度集中的文档。进一步利用一个双向注意力流模型（bidirectional attention flow model (Seo et al., 2017)）来计算文档 h' 中每一个词的权重，并得到加权的词表示，记作 $\tilde{h'} = {h'^1,...,h'^K}$</p>
<p>最后计算每一个候选答案 $c_l$ 和这里的 $\tilde{h'}$ 的相似度，选择相似度最高的一个答案为最终预测</p>
<br>
<h3 id="2-6-Joint-Optimization-模型训练">2.6  Joint Optimization 模型训练</h3>
<p>这里先得到每一个部分（共三个部分）的损失函数，再整体优化三个损失函数的加和</p>
<p>注意到 DE 实际上存在一个按分布 sample 文档的步骤，故这里使用弱监督的方式来评价。这里用（同问题有着最近的 TF-IDF 距离的文档）来监督每条 reasoning chain 的第一个文档，再用（至少提到了一次正确答案的文档）来监督每条 reasoning chain 的最后一个文档，这样的评判方式可以让 DE 学会如何从问题出发，通过某种逻辑链寻找到正确答案。注意在监督最后一个文档的时候，提到了正确答案的文档可能有很多，这里采用随机抽样的方式选择一个</p>
<p>而对于 AP 和 EA 部分，由于给出的直接就是候选答案，则直接用交叉熵函数来作为损失函数</p>
<br>
<br>
<hr>
<h2 id="3-Experiments-and-Results-实验结果">3 Experiments and Results 实验结果</h2>
<br>
<p>这里选用的数据集为 <strong>WikiHop</strong> 和 <strong>MedHop</strong>，这里的两个数据集均包含需要多跳推理才能解答的多跳阅读理解问题，且在 WikiHop 中是标名了当前的答案是否需要多跳获得的（也就是 single 或 multiple 的标签）</p>
<p>来看看在 WikiHop 上的结果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023100056573.png" alt="image-20231023100056573" style="zoom:70%;" />
<p>可以看到提升还是有的，但是到底算不算特别出色有点尴尬（</p>
<p>注意到这里 WikiHop 数据集标注了是否是多跳阅读理解问题，来看看效果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023100117712.png" alt="image-20231023100117712" style="zoom:80%;" />
<p>可以看到上述的方法在解决多跳阅读理解问题上确实提升明显</p>
<p>再看看MedHop：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023100142190.png" alt="image-20231023100142190" style="zoom:80%;" />
<p>注意到这里整体模型的设计使得最后答案选择的 <strong>可解释性</strong> 得到了保障（最后倒数几页终于提到题目里的可解释模型了 ...）由于此时最后被选择到的答案对应的 reasoning chain 是十分明确的，此时可以通过被选定的 reasoning chain 很清楚地了解到机器对当前答案的推断思路</p>
<p>来一个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023100211603.png" alt="image-20231023100211603" style="zoom:65%;" />
<p>这个例子本身存在多条可能的推断路径，且指向了多个不同的答案，可以明显地展示出当前模型设计的优势</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>CorefQA: 基于QA模式（提出问题 + 片段预测）的共指消解 / 指代消解模型</title>
    <url>/2023/10/30/20210319-paper-note-CorefQA/</url>
    <content><![CDATA[<p>原文写于 20210319，存档如下</p>
<blockquote>
<p>Wei Wu, Fei Wang, Arianna Yuan, Fei Wu and Jiwei Li, Department of Computer Science and Technology, Zhejiang University Computer Science Department, Stanford University, ShannonAI; <strong>CorefQA: Coreference Resolution as Query-based Span Prediction</strong></p>
<p>论文原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MTEuMDE3NDYucGRm">https://arxiv.org/pdf/1911.01746.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1NoYW5ub25BSS9Db3JlZlFB">official - tensorflow<i class="fa fa-external-link-alt"></i></span> ** <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0ZlaVdhbmc5Ni9Db3JlZlFBLXB5dG9yY2g=">pytorch<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br/>
<p>共指消解问题至今仍是各类 nlp 任务中绕不开的难题，一方面对文章本身内容中的指代了解不清将导致对整体文章的语义理解出现问题，另一方面随着部分多轮问答式 QA 数据集的兴起，此时后一题提出的问题中可能只包含指代词而不再包含具体的实体名称。</p>
<p>传统的共指消解模型主要分为以下两个步骤作处理：</p>
<ul>
<li>充分考虑整篇文章中的所有的 span，从所有的文本片段中选择出所有可能的 指代 mention</li>
<li>为每一个当前找到的可能的指代找到它对应的前序指代（antecedent），也就是为当前的指代分类，把它和它指代的对象的其他 mention 放在一起</li>
</ul>
<p>但是注意到这样的处理方式存在一定的问题：</p>
<ul>
<li>所有的被遗漏的共指词一旦第一次没有被捉住，后面就再也没有机会改正。
<ul>
<li>因为此时下游的模型是完全基于已经给出的共指词的，且本身共指的数据集能够提供的改正的信息是有限的（并没有明确地标签标识当前的 span 到底是什么样的共指）</li>
<li>也就是说此时需要模型能够重新回顾检查遗漏的指代 mention</li>
</ul>
</li>
<li>在大多数模型中，当前的端到端训练的模型只是基于最后输出层的这两个词的上下文表示来为一对共指打分
<ul>
<li>也就是说此时本身打分的方式并没有考虑到当前两对共指词的上下文信息（本身其编码得到的上下文信息在最后的输出层表示中的体现是很少的）</li>
</ul>
</li>
</ul>
<p>为了缓解传统的处理方式带来的问题，本文尝试将原本的 <strong>共指消解问题转化为片段预测任务</strong>，也就是利用 <strong>QA 的方式来训练模型学习多个 mention 之间的指代关系</strong></p>
<p>首先选出可能的指代 mention，再依据该 mention 的上下文信息来生成问题，模型再尝试从文档中抽取片段以回答这个问题，则此时整个针对于共指消解的问题可以转化为一个针对抽取式 QA 问题的 span prediction 的问题</p>
<p>这里来看一个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023100636083.png" alt="image-20231023100636083" style="zoom:67%;" />
<p>通过阅读文本 → 不断回答生成的问题 → 此时模型可以不断地扩充可能的指代同一个实体的 mention 的集合</p>
<p>同时，从第二个传统模型存在的问题出发，此时发挥作用的不再是一个简答地综合上下文信息的模型，而是一个 MRC 类的 span prediction 的模型，也就是说此时最后输出层的输出将能过够更好地将上下文信息进行融合，使得后续基于输出层表示的共指词评分更加准确，更好地辅助模型的训练</p>
<br>
<br>
<hr>
<h2 id="2-Model-模型介绍">2  Model 模型介绍</h2>
<br>
<h3 id="2-1-overview">2.1 overview</h3>
<p>先来看看模型整体结构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023100704428.png" alt="image-20231023100704428" style="zoom: 60%;" />
<p>此时整体模型主要分为两个部分，</p>
<ul>
<li><strong>mention proposal model 指代提取模块</strong>：也就是负责从全文中提取出所有可能的指代词 mention</li>
<li><strong>mention linking model 指代连接模块</strong>：也就是负责为所有提取出来的 mention 作分类，类似于一个聚类的操作，将所有的指向同一个实体的指代综合起来</li>
</ul>
<p>设此时输入的文章包含 n 个 token，记作 $X = {x_1, ... , x_n}$，则此时可能的文本片段共有 $N = n*(n+1)/2$ 个<br>
（共 n+1 个可以插入的空 / 包括头尾，选定一个 为 n+1，再选定结束位置为 n*(n+1)，最后因为一个位置可以重复两遍再 /2），</p>
<p>此时定义 $e_i$ 为第 i 个可能的文本片段，则此时 $e_i$ 对应着一组开始的 index $FIRST(i)$ 和结束位置的 index $LAST(i)$</p>
<p>则此时整体的任务即是为所有的可能的 N 个 span 寻找前序 mention，如果此时该 span 并不作任何指代，则将它的前序指代定义为一个 dummy token $\epsilon$</p>
<br>
<h3 id="2-2-Input-Representations-输入表示">2.2 Input Representations 输入表示</h3>
<p>首先需要得到文档 X 的每一个 token 的表示 xi，这里使用 <code>SpanBERT</code> 来完成</p>
<p>注意到本身叙述者（speaker）的信息对于指代问题是十分重要的（比如一个文本两句话，第一句是你说的，你说的你指的是我，但是第二句是我说的，此时我说的你就是你），但是前序的大多数研究只是将 speaker 的信息简化为一个二元的变量，以标识两个 mention 是否是来自同一个 speaker。</p>
<p>本文直接将 speaker 的名称和它对应的语句直接作向量拼接操作，在后续的实验部分会证明这样操作的优越性</p>
<p>同时注意到为了将较长的文档输入 SpanBERT，这里采用了滑动窗口的方式，为每 T/2 个 token 创造一个 T 大小的片段，再各自输入 SpanBERT 来得到 embedding，作为后续的输入表示</p>
<br>
<h3 id="2-3-Mention-Proposal-指代提出模块">2.3 Mention Proposal 指代提出模块</h3>
<p>此时的输入是 上述经过 SpanBERT encode 后的结果，目标为充分考虑文本中可能的 span，并提取出所有可能的指代</p>
<h4 id="prune-the-candidate-spans">prune the candidate spans</h4>
<p>首先规定一个 span 的最大长度，记作 L，也就是说只考虑长度在 L 以下的指代（过长的指代确实很怪），为了进一步减小可能的 span 个数，这里需要通过计算所有的 span 的 mention score 来对所有的 候选span 作进一步的修剪</p>
<p>对于第 i 个可能的 span 计算它的 mention 得分 $s_m(i)$ ：</p>
<ul>
<li>
<p>计算开始位置 $x_{FIRST(i)}$：<br>
$$<br>
s_m(x _{FIRST(i)}) = FFNN([x _{FIRST(i)}])<br>
$$</p>
</li>
<li>
<p>计算结束位置 $x_{LAST(i)}$​：<br>
$$<br>
s_m(x _{LAST(i)}) = FFNN([x _{LAST(i)}])<br>
$$</p>
</li>
<li>
<p>将此时的开始位置和结束位置的两个 embedding 直接作向量拼接再计算：<br>
$$<br>
s_m(x _{FIRST(i)}, x _{LAST(i)}) = FFNN_m ([x _{FIRST(i)}, x _{LAST(i)}])<br>
$$</p>
</li>
<li>
<p>最后计算综合的 mention score，也就是上述三个部分的平均：<br>
$$<br>
s_m(i) = [s_m (x _{FIRST(i)}) + s_m (x _{LAST(i)}) + s_m(x _{FIRST(i)}, x _{LAST(i)})]/3<br>
$$</p>
<p>这里的 FFNN 是一个前馈神经网络，注意上面用到的三个 FFNN 是独立训练的，各用各的参数</p>
</li>
</ul>
<p>对于一篇文章共 N 个指代，此时只是选择前 λN 个得分最高的 span 作为可能的 mention，进入后续的操作</p>
<h4 id="Mention-Proposal-Pretraining-预训练">Mention Proposal Pretraining 预训练</h4>
<p>注意上述的操作需要经过预训练，如果此时直接将所有可能的 span 扔进去让模型从头开始会造成巨大的计算开销。这里的预训练采用三个联合的分类器：</p>
<ul>
<li>判断 $x_{FIRST(i)}$ 是否是 mention 的开始</li>
<li>判断 $x_{LAST(i)}$ 是否是 mention 的结束</li>
<li>判断 $x_{FIRST(i)}$ 和 $x_{LAST(i)}$ 是否应该合并（也就是说它俩是不是真的来自一个 mention）</li>
</ul>
<p>三个分类器采用联合训练的方式，损失函数就用它们再上面的 mention score 的得分情况公式来计算：<br>
$$<br>
\begin{align}<br>
Loss(m) &amp;= \text{sigmoid} (s_m(x _{FIRST(i)})) \\<br>
&amp;+ \text{sigmoid} (s_m(x _{LAST(i)})) \\<br>
&amp;+ \text{sigmoid} (s_m(x _{FIRST(i)}, x _{LAST(i)}))<br>
\end{align}<br>
$$<br>
<br></p>
<h3 id="2-4-Mention-Linking-as-Span-Prediction-通过片段预测实现指代聚类">2.4 Mention Linking as Span Prediction 通过片段预测实现指代聚类</h3>
<p>输入某一个来自 proposal 的指代 mention，此时 linking 的任务就是寻找到这个 mention 的前序指代，比如此时我已经有了 {特*普，他，总统，川宝，川建国}，此时给定的 mention 是川普，则我的任务就是为这个 mention 找到它的前序 = 川建国，同理川建国的前序也就是川宝</p>
<p>此时给定 span $e_i$，计算 ei 和前一个 mention ej 的得分 $s_a(i,j)$，而这一步是通过 QA 的模式实现的，也就是基于一个三元组：$${context(X), query(q), answer(a)}$$</p>
<p>上述的 上下文 context X 也就是输入的文档（注意是整个 document）</p>
<p>接下来生成 query ：对于给定的 mention ei ，这里使用 ei 所在的那个句子作为 query，记作 $q(e_i)$，注意对于 query 中的 ei 本身用特殊的 token $<mention>$ 作封装</p>
<p>此时根据上述的 context 和 query 尝试回答问题得到 a，这里可以看作是一个抽取式的 MRC 问题，但是此时的问题可以是没有答案的，将没有答案的情况归类为以下两种情形：</p>
<ul>
<li>此时给定的 span ei 本身就不是一个 mention</li>
<li>ei 确实有所指代，但是这个 指代 并没有其他指向同一个实体的指代 mention</li>
</ul>
<p>对于给定的 span ei，它对应的 $q(e_i)$，此时我们想要计算任意一个 span j 是这个 query 的答案的得分，按如下步骤：</p>
<ul>
<li>将 query $q(e_i)$ 和上下文 X 作拼接，输入 BERT，用 BERT 的输出作为 $x_{FIRST(i)}$ 和 $x_{LAST(i)}$ 的表示</li>
<li>将 FIRST 和 LAST 作向量拼接，再输入一个前馈神经网络 FFNN，得到对于问题 i 此时 span j 作为答案的得分：<br>
$$<br>
s_a(j \vert i) = FFNN _{j \vert i} [x _{FIRST(j) \vert i}, x _{LAST(j) \vert i}]<br>
$$</li>
</ul>
<p>但是注意到 <strong>上述的打分是单向的</strong>，也就是说只判断了 span j 是否是 query i 的答案，但是如果 span i 和 span j 指向同一个实体，则此时 span i 同理应该是 query j 的答案，此时作进一步操作以实现双向的打分：同理将 span j 所在的句子作为 query，重复上述操作，得到 （span i 为 query j 的答案的得分），记作 $s_a(i|j)$​ ：<br>
$$<br>
s_a(i \vert j) = FFNN _{i \vert j} [x _{FIRST(i) \vert j}, x _{LAST(i) \vert j}]<br>
$$</p>
<p>注意这里的表示 x 还是来自于加入了 query j 的 BERT 的输出</p>
<p>最后 span i 和 span j 的得分为上述两个得分的均值：<br>
$$<br>
s_a(i,j) = \frac{1}{2} (s_a (j\vert i) + s_a (i \vert j))<br>
$$</p>
<p>进一步考虑，如果此时 span i 和 span j 确实指向同一个实体，此时要求：1）span i 和 span j 都是 mention；2)此时它们共指</p>
<p>则此时定义总体的 overall 得分：<br>
$$<br>
s(i, j) = \lambda[s_m(i) + s_m(j)] + (1-\lambda)s_a(i, j)<br>
$$</p>
<p>这里的 $\lambda$ 还是超参数</p>
<br>
<h3 id="2-5-Antecedent-Pruning-前序指代修剪">2.5 Antecedent Pruning 前序指代修剪</h3>
<p>注意到此时给定一个文档 X ，含有 n 个 token，则此时可能的 span 是 $O(n^2)$ 级别的，而计算它们两两 span 的得分 $s(i,j)$ 就是 $O(n^4)$ 级别的</p>
<p>此时考虑对于给定的一个 span i，我只对一部分的 span j 作打分：</p>
<ul>
<li>给定 span i，得到 query i，再通过 BERT ，计算 span i 和所有的 span j 的第一轮得分 = span j 确实是 query i 的答案的得分 = $s_a(j|i)$</li>
<li>选择 $s_a(j|i)$ 得分最高的 C 个 span j 保留，继续反过来计算</li>
</ul>
<br>
<h3 id="2-6-Training-整体训练">2.6 Training 整体训练</h3>
<p>对于任意一个给定的 span ei，此时我依据它和 span j 的总得分 $s(i,j)$，选择 C 个 span j 作为 span i 的可能的前序 mention。同时这里存在一个 dummy token $\epsilon$ 来标记不存在共指的 mention</p>
<p>这里通过数据集给出的 gold cluster 来训练模型：对于每一个给定的 ei，此时任意一个 ej 是它的共指的概率为：<br>
$$<br>
P(e_j) = \frac{e ^{s(i, j)}} {\sum _{j' \in C} {e ^{s(i, j')}}}<br>
$$</p>
<p>这里用优化（所有出现在 gold cluster 中的 mention)对应的对数似然函数来 <strong>端到端地训练模型</strong></p>
<p>注意此时如果将一个文档中的所有 span 视作结点，则通过 s(i,j) 得到了两个结点 i 和 j 之间的 边 的权重，此时只保留每一个结点对应的所有边中最大的，则对于mention i 此时它构成的连通子图也就是所有和它指向同一个实体的 mention 的集合</p>
<br>
<h3 id="2-7-Data-Augmentation-using-Question-Answering-Datasets-利用-QA-数据集作数据增强">2.7 Data Augmentation using Question Answering Datasets 利用 QA 数据集作数据增强</h3>
<p>注意到中间是通过 QA 的思路来判断两个 mention 是否是共指的，则此时解答 QA 部分的模型的能力同样十分重要</p>
<p>这里利用 <strong>Quoref</strong> 和 <strong>SQuAD</strong> 两个数据集来对 <strong>mention linking</strong> 模块作预训练</p>
<br>
<br>
<hr>
<h2 id="3-Experiments-实验部分">3 Experiments 实验部分</h2>
<br>
<p>先提一下几个细节的地方：</p>
<ul>
<li>针对 mention linking 模块的 speaker 和 mention，这里采用两个特殊的 token $<speaker></speaker>$ 和 $<mention></mention>$ 来处理</li>
<li>对于 SpanBERT 的部分，选用滑动窗口大小 T = 512</li>
<li>保留的最大的可能的候选前序mention 个数 C= 50</li>
</ul>
<p>这里实验用到的是共指消融的两个很经典的数据集：<strong>CoNLL-2012 + GAP</strong></p>
<br>
<h3 id="3-1-CoNLL-2012-数据集">3.1 CoNLL-2012 数据集</h3>
<ul>
<li>2,802/343/348 → train / development / test</li>
<li>包含七种不同的体裁</li>
</ul>
<p>训练结果如下：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023101704245.png" alt="image-20231023101704245" style="zoom:60%;" />
<p>可以看到整体的提升还是很明显的（超明显的）</p>
<br>
<h3 id="3-2-GAP-数据集">3.2 GAP 数据集</h3>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023101736590.png" alt="image-20231023101736590" style="zoom:67%;" />
<br>
<h3 id="3-3-其他评价">3.3 其他评价</h3>
<h4 id="各组件影响">各组件影响</h4>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023101757541.png" alt="image-20231023101757541" style="zoom:67%;" />
<p>可以看到 QA 部分的影响超大，可以认为这里用 QA 的思路来判断两个 mention 是否是共指的想法确实有一定合理性</p>
<h4 id="speaker-的影响">speaker 的影响</h4>
<p>前面提到 CorefQA 对 speaker 信息的处理和传统模型是不同的，这里来看看效果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023101844368.png" alt="image-20231023101844368" style="zoom:67%;" />
<p>论文里图咋这样了，，，总之从左到右是黄蓝黑</p>
<p>可以看到 speaker 人数较多的时候，本文特殊的处理方式优势明显</p>
<h4 id="召回率">召回率</h4>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023101909090.png" alt="image-20231023101909090" style="zoom:67%;" />
<p>注意这里更改了不同的 λ 以控制被保留的 mention，可以注意到即使一个 mention 一开始被略过了（也就是 λ 比较低的时候）此时它仍然可以被整个模型重新捡回来，故在 λ 比较低的时候整体模型较传统模型的提升是很明显的</p>
<br>
<br>
<br/>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>HGN: 基于分层图网络的多跳阅读理解模型</title>
    <url>/2023/10/30/20210330-paper-note-HGN/</url>
    <content><![CDATA[<p>原文写于 20210330，存档如下</p>
<blockquote>
<p>Yuwei Fang, Siqi Sun, Zhe Gan, Rohit Pillai, Shuohang Wang, Jingjing Liu<br>
Microsoft Dynamics 365 AI Research; <strong>Hierarchical Graph Network for Multi-hop Question Answering</strong></p>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MTEuMDM2MzEucGRm">https://arxiv.org/pdf/1911.03631.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3l1d2Zhbi9IR04=">official ** pytorch<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<p>多跳阅读理解数据集 HotpotQA 排名第六（2021/3/29）</p>
<br/>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<br>
<p>相较于传统的阅读理解问题，多跳阅读理解为模型提出了新的挑战。此时为了正确回答问题，需要模型同时有从多个文档，多个段落收集信息并将各个信息进行一定的逻辑整合推理的能力。看下面一个来自于多跳阅读理解问题的经典数据集 HotpotQA 的例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023102208496.png" alt="image-20231023102208496" style="zoom:67%;" />
<p>此时为了回答问题需要先通过问题中提到的 “Big Stone Gap” 找到 director（支持文档 S1），再顺次推理得到最后的答案（支持文档 S4），也就是说此时不仅限于传统的阅读理解数据集的要求，同时需要模型能够将多个文档的信息进行整合（比如 S1 和 S4 共同作用）再利用相关信息推理得到最后的答案。</p>
<p>存在的挑战之一为如何融合不同粒度的信息（这里中间步骤的信息可以是文章 / 段落 / 句子 / 实体）以推理得到最后的答案。某些方法采用实体图（entity graph）的方法，通过在图上进行推理以得到最后的答案。但是注意到这样的操作存在一定的问题：</p>
<ul>
<li>部分模型直接选取实体图中的实体作为答案（显然不合理，答案不一定是实体）</li>
<li>部分模型将实体的表示重新放回原本文档的表示以获得答案 ans span（举例大名鼎鼎的 DFGN），但是此时只是为了得到答案而作的操作，无法利用实体图的特点得到推理过程和对应的 evidence</li>
<li>同理，大多数模型进行的推理过程比较简单，难以支持较为复杂的问题</li>
</ul>
<p>直观来说，想要从一系列文档中得到一个需要多跳推理的阅读理解问题的答案，需要经过以下几个步骤：</p>
<ul>
<li>选择出和问题相关的段落</li>
<li>从段落中取出相关证据 evidence</li>
<li>利用证据推理得到最后答案</li>
</ul>
<p>基于以上的思路，本文提出一个新的帮助多跳阅读理解问题解答和推理的模型：<strong>Hierarchical Graph Network (HGN)</strong>，这里使用构造分层图（hierarchical graph）的形式来整合不同粒度的信息</p>
<p>这里包含四种类型的结点：<strong>问题 questions + 段落 paragraphs + 句子 sentence + 实体 entities</strong>，首先用预训练模型（BERT / RoBERTa）来进行上下文信息的编码（contextual encoding），得到这些分层图中结点的初始表示；再将上面得到的表示通过一个 GNN 来完成图传播，得到更新的表示后再用于后续的几个子任务。注意到最后的答案不一定就是 GNN 中的实体，此时同时使用一个 span prediction 的模块来得到最后的 ans span</p>
<br>
<br/>
<hr>
<h2 id="2-Hierarchical-Graph-Network">2 Hierarchical Graph Network</h2>
<br>
<h3 id="2-1-overview">2.1 overview</h3>
<p>先来看看模型整体结构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023102242711.png" alt="image-20231023102242711" style="zoom:60%;" />
<p>此时主要分为四个主要的部分：</p>
<ul>
<li><strong>Graph Construction Module 图构造模块</strong>：用于构造分层图（hierarchical graph）以连接不同粒度，不同来源 source 的信息。</li>
<li><strong>Context  Encoding Module 上下文编码模块</strong>：也就是通过一个  RoBERTa-based 的编码器得到图中各个结点的初始表示</li>
<li><strong>Graph Reasoning Module 图推理模块</strong>：利用基于图注意力的方法（graph-attention-based）完成结点的表示更新</li>
<li><strong>Multi-task Prediction Module 多任务预测模块</strong>：同时完成多个子任务以得到最后的答案：选择段落 + 寻找支持证据 + 实体预测 + 提取 answer span</li>
</ul>
<br>
<h3 id="2-2-Graph-Construction-图构造模块">2.2 Graph Construction 图构造模块</h3>
<p>主要目标是构造分层图，也就是得到里面的结点和边的关系</p>
<p>这里主要分为两个部分完成：</p>
<ul>
<li>选取得到相关的多跳段落（multi-hop paragraphs）</li>
<li>对选取段落的对应的 句子 / 实体 之间添加边作连接</li>
</ul>
<h4 id="Paragraph-Selection">Paragraph Selection</h4>
<p>首先寻找第一跳的结点，也就是从问题出发得到的初始结点，具体按照以下步骤进行 →</p>
<p>① 寻找 title 和问题 Q 中的任何一个 phrase 匹配的段落（title matching）</p>
<p>② 同时训练一个段落评分器（paragraph ranker），具体就是预训练的 RoBERTa 后面接上一个二分类器，判断各个段落内确实有支持证据的概率</p>
<p>③ 如果此时有多个段落通过 title matching 被选中，则只有评分最高的两个段落会被最后保留</p>
<p>④ 如果此时 title matching 没有选中任何一个段落，继续搜索段落内出现了 Q 问题中涉及的实体 entity 的段落</p>
<p>⑤ 如果还是没找到任何一个段落，此时选取通过 ranker 后评分最高的段落</p>
<p>进一步考察第二跳的结点：第二跳的结点应该是和第一跳结点存在一定的相连关系的实体，但是这里不考虑直接依赖实体匹配（会引入大量噪声），这里利用的是第一跳的段落中的超链接（hyperlink）来寻找可能存在的第二段落，并构建两个结点之间的边，注意这里的边是双向的。</p>
<p>同理为了避免引入过多噪音，多跳操作的每一个引入新的 paragraph 都通过 ranker 保留前 N 个评分最高的段落，其他舍弃</p>
<h4 id="Nodes-and-Edges">Nodes and Edges</h4>
<p>注意此时提取得到的结果本身就是自带一种层级关系的 → 比如段落内包含句子 → 句子包含实体</p>
<p>此时共存在四种结点：<strong>问题结点 + 段落结点 + 句子结点 + 实体结点</strong></p>
<p>此时按照如下规则建立结点和结点之间的边的关系（共七种）</p>
<ul>
<li>问题结点和段落结点相连（first-hop 的段落）</li>
<li>问题结点和问题中本身出现的实体结点相连</li>
<li>将当前段落结点（paragraph node）和该段落的所有句子结点（sentence node）相连</li>
<li>句子结点通过句子中包含的超链接和其他段落结点相连</li>
<li>针对每一个句子结点，此时提取出该句子中的所有实体，并将所有实体结点和该句子结点相连</li>
<li>段落之间相连</li>
<li>出现在同一个段落的句子之间相连</li>
</ul>
<br>
<h3 id="2-3-Context-Encoding-上下文编码模块">2.3 Context Encoding 上下文编码模块</h3>
<p>这里给定一个建立好框架的分层图，负责得到所有图中的结点的对应的初始表示（ initial representations）</p>
<p>将所有选取出的段落 paragraphs 拼接得到上下文 C，再和当前问题 Q 向量拼接 → 扔进一个预训练好的 RoBERTa + 一个跟在后面的 bi-attention layer（也就是双向注意力），此时得到上下文表示 C 和问题表示 Q：$$Q = {q_0 , q_1, ... , q_{m-1}} \ \in R^{m<em>d}$$ $$C = {c_0 , c_1 , ... , c_{n-1}} \in R^{n</em>d}$$<br>
这里的 m 和 n 分别是问题和上下文的长度，注意这里的每一个 qi 和 ci 都是长度为 d 的向量</p>
<p>再把这里得到的表示 C 放进一个双向的 LSTM （ BiLSTM ，注意这里是实际上使用的时候是共享参数的），得到的输出记作 $M \in R^{n*2d}$</p>
<p>此时通过 M 得到 C 中不同的三种结点的不同的表示（段落 paragraph + 句子 sentence + 实体 entity），此时基于 （backward LSTM 的起始结点的隐藏状态）和（forward LSTM 的结束结点的隐藏状态）分别计算 pi 和 si 和 ei：<br>
$$<br>
\begin{align}<br>
p_i &amp;= MLP_1([M[P ^{(i)} _{start}][d:]; M[P ^{(i)} _{end}][d:]]) \\<br>
s_i &amp;= MLP_2([M[P ^{(i)} _{start}][d:]; M[P ^{(i)} _{end}][d:]]) \\<br>
e_i &amp;= MLP_3([M[P ^{(i)} _{start}][d:]; M[P ^{(i)} _{end}][d:]])<br>
\end{align}<br>
$$</p>
<p>这里的 $P^{(i)}<em>{start}, S^{(i)}</em>{start}, E^{(i)}<em>{start}$ 分别表示第 i 个段落/ 句子 / 实体结点的起始位置，而 $P^{(i)}</em>{end}, S^{(i)}<em>{end}, E^{(i)}</em>{end}$ 同理对应结束位置，这里的 $[ ; ]$ 也就是向量拼接，得到的拼接结果再通过一个 MLP 层，注意这里的参数不是共享的</p>
<p>综上，此时得到的 pi 和 si 和 ei 也就是第 i 个 段落 / 句子/ 实体结点的对应的初始表示</p>
<p>同理这里得到问题结点的初始表示，对于 RoBERTa + 一个跟在后面的 bi-attention layer 给出的输出 Q，再通过一个池化层得到问题 Q 的初始表示：$$q = maxpooling(Q)$$</p>
<p>注意这里满足维度都是 d，也就是 $$q, p_i , e_i ,s_i  \in R^d$$</p>
<br>
<h3 id="2-4-Graph-Reasoning-图推理模块">2.4  Graph Reasoning 图推理模块</h3>
<p>负责更新此时分层图中的结点表示，也可以理解为将整体的上下文的信息都融入表示。通过在构造的分层图上进行推理实现，这里定义：</p>
<p>$$P = {p_i} _{i=1} ^{n_p}; \text{ } S = {s_i} _{i=1} ^{n_s}; \text{ } E = {e_i} _{i=1} ^{n_e}; $$</p>
<p>，注意这里的 np 和 ns 和 ne 分别表示三种结点出现在整个图中的数量，同理定义</p>
<p>$$H = {q,P,S,E} \in R^{g*d}; \text{ } g = n_p+n_e+n_s+1$$</p>
<p>这里使用 <strong>Graph Attention Network (GAT)</strong> 来模拟信息在图上传递的过程：GAT 将所有的结点作为输入，对于第 i 个结点的表示 hi，此时通过 i 结点对应的邻居结点 Ni 的情况来更新 hi 的表示得到 h'：<br>
$$<br>
h_i' = \text{LeakyRelu} (\sum _{j \in \mathcal{N} _i} {\alpha _{ij} h_j W})<br>
$$</p>
<p>这里的 $N_i$ 表示结点 i 的所有的邻居结点的集合，W 是需要学习的权重矩阵，这里的 aij 是注意力系数：<br>
$$<br>
\alpha _{ij} = \frac{exp(f([h_i;h_j] w _{e _{ij}}))} {\sum _{k \in \mathcal(N) _i} {exp(f([h_i;h_k] w _{e _{ik}}))}}<br>
$$</p>
<p>这里的 $w_{e_{ij}}$ 是关系类型 ij 对应的权重（也就是结点 i 这种结点和 结点 j 这种结点对应相连的时候的对应的关系对应的权重），这里的 $f()$ 是  LeakyRelu 激活函数，经过推理后得到所有结点的更新表示，记作 H'：</p>
<p>$$H' = {h_0', h_1', ... , h_g'} \in R^{g*d}$$</p>
<br>
<p>再基于门控注意力机制对上面的信息作一个融合，得到后续用于作 span 提取的上下文表示集合 G：<br>
$$<br>
\begin{align}<br>
C &amp;= Relu (MW_m) \cdot Relu(H'W' _m)^T \\<br>
\bar{H} &amp;= Softmax(C) \cdot H' \\<br>
G &amp;= \sigma([M; \bar{H}] W_s) \cdot Tanh([M; \bar{H}] W_t)<br>
\end{align}<br>
$$<br>
这里的 $W_m, W'_m,W_s,W_t$​ 都是需要学习的权重矩阵</p>
<br>
<h3 id="2-5-Multi-task-Prediction-Module-多任务预测模块">2.5 Multi-task Prediction Module 多任务预测模块</h3>
<p>得到结点的更新表示后用于几个子任务：</p>
<ul>
<li>基于 paragraph 结点的段落选择</li>
<li>基于句子结点的支持证据预测</li>
<li>基于实体结点和上下文表示 G 的答案预测</li>
</ul>
<p>对于 <strong>段落选择任务 = 当前的段落到底有没有包含确实的证据</strong> 和 <strong>支持证据预测任务 = 当前的句子结点到底是不是支持证据</strong>，直接通过两层的 MLP 作为一个分类器来实现：<br>
$$<br>
o _{sent} MLP_4(S') \text{ , } o _{para} = MLP_5(P')<br>
$$</p>
<p>这里的 $o_{sent} \in R^{n_s}$ 表示每一个句子是否真的是支持证据，$o_{para} \in R^{n_p}$​ 同理</p>
<p>进一步预测当前实体 E 是不是答案，同理通过一个 MLP：<br>
$$<br>
o _{entity} = MLP_6(E')<br>
$$</p>
<p>注意这里计算的 $o_{entity}$ 本身并不帮助我们得到预测的答案，只是算算而已，用在损失函数里。注意本身正确答案可能就不是任意一个实体，则此时直接将实体的损失函数记作 0</p>
<p>真的拿来作答案决策的为：<br>
$$<br>
o _{start} = MLP_7 (G) \text{ , } o _{end} = MLP_8(G)<br>
$$</p>
<p>这里是从综合上下文表示 G 中选择答案开始和结尾的结点，同理经过两层 MLP，分别预测当前的结点是不是答案的开始 / 结束位置</p>
<p>同理，这里利用 G 的第一个隐藏表示配合 MLP 来预测答案类型：<br>
$$<br>
o _{type} = MLP_9 (G[0])<br>
$$</p>
<p>注意如果这里预测出来的答案类型为 yes 或者 no，就直接回答对应的 yes / no，不再返回上面预测出的起始位置 + 结束位置的答案</p>
<br>
<p>最后的训练是多个子任务共同训练的：<br>
$$<br>
\begin{align}<br>
\mathcal{L} _{joint} &amp;= \mathcal{L} _{start} + \mathcal{L} _{end} \\<br>
&amp;+ \lambda _1 \mathcal{L}  _{para} + \lambda_2 \mathcal{L} _{sent} + \lambda_3 \mathcal{L} _{entity} + \lambda_4 \mathcal{L} _{type}<br>
\end{align}<br>
$$</p>
<p>这里的 $\lambda_1, \lambda_2, \lambda_3, \lambda_4$​ 都是超参数，损失函数用的都是交叉熵损失函数（本质都转化为了分类问题）</p>
<br>
<br>
<hr>
<h2 id="3-Experiments">3 Experiments</h2>
<br>
<p>这里用到的数据集是 <strong>HotpotQA</strong>，也就是经典的多跳阅读理解数据集了</p>
<p>针对这个数据集一般存在两个子任务：</p>
<ul>
<li>答案预测</li>
<li>支持证据预测</li>
</ul>
<p>来看看效果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023103151315.png" alt="image-20231023103151315" style="zoom:60%;" />
<p>作者分析了几个点：</p>
<ul>
<li>很多错误集中于（同义但是不同表述的答案），比如 “EPA vs. Environmental Protection Agency” / “American-born vs. U.S. born”，可以认为就还是算是答对了吧这种 ...</li>
<li>缺乏常识帮助模型进行判断，如果将常识同时加入模型或许会有一定的提升（比如模型不知道 “second” means “Code#02”</li>
<li>在需要离散推理的部分表现不好，比如一些需要比较两个东西的问题</li>
<li>可能有的问题存在多个正确的答案，一般模型只能够给出一个</li>
<li>在多跳推理部分出现错误，或者明明给出了正确的对应的支持证据最后还是给了错误的答案</li>
</ul>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>Harnessing Deep Neural Networks with Logic Rules: 结合逻辑规则的深层神经网络</title>
    <url>/2023/10/30/20210406-paper-note-LogicRulesACL16/</url>
    <content><![CDATA[<p>原文写于 20210406，存档如下</p>
<blockquote>
<p>Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric P. Xing, School of Computer Science, Carnegie Mellon University ; <strong>Harnessing Deep Neural Networks with Logic Rules</strong></p>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE2MDMuMDYzMTh2Ni5wZGY=">https://arxiv.org/pdf/1603.06318v6.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1poaXRpbmdIdS9sb2dpY25u">更贴切来说是一个官方应用案例<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<p>当前广泛应用的深度神经网络（例如 DNN）结构存在一定的问题：</p>
<ul>
<li>过于依赖大量的标记数据参与训练</li>
<li>纯数据驱动（data-driven）的学习方式往往缺乏解释性</li>
<li>难以将人类的一些思维模式融合进入模型，或者仅仅局限于昂贵的直接监督学习或专门的初始化方法</li>
<li>人类本身在解决问题的时候不仅仅是依赖于单纯的问题本身提供的信息，而更多地会共同结合自己的常识知识和过往经历进行判断。而当前模型难以将常识知识或者一些人类的思维模式融入任务中</li>
</ul>
<p>综上，考虑将逻辑规则（logic rules）融入传统的神经网络模型，将为 DNN CNN 等模型带来训练，解释性和最终效果多个方面的进步。本文提出了一种<strong>将逻辑规则（logic rules）融入多种不同的传统神经网络（如 CNN DNN 等）的方法</strong>，使得神经网络结构可以同时从作好了标签的实例和逻辑实例中进行学习，并通过一种迭代蒸馏（iterative rule knowledge distillation）的方式，利用逻辑规则中结构化的信息来辅助模型参数的训练。这里的逻辑规则可以看作是一种针对当前给定的数据的一种信息补充，也就使得该方法可以应用于结合未标签数据的半监督学习方式。</p>
<p>本质上本文的方法可以看作是 <strong>知识蒸馏（knowledge distillation）和 后验正则化（posterior regularization - PR）的融合</strong>，也就是说，在每一层循环均从 PR 选择后验的约束规则来建立一个 规则正则化的教师 teacher，再通过模仿教师网络的预测的方式来训练学生网络 student</p>
<br>
<br>
<hr>
<h2 id="2-Method">2 Method</h2>
<br>
<h3 id="2-1-overview">2.1 overview</h3>
<p>本质上来说这个模型可以同时从特殊的例子（specific examples）和常识知识（general rules）中学习</p>
<p>来看看模型的整体结构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023103922691.png" alt="image-20231023103922691" style="zoom:60%;" />
<p>具体流程 → 通过后验的正则化规则来建立 teacher 部分 → 要求 student 部分学习 teacher 部分的预测</p>
<br>
<h3 id="2-2-Learning-Resources-Instances-and-Rule-实例和规则">2.2  Learning Resources: Instances and Rule 实例和规则</h3>
<p>这里使用带有置信区间的 first-order logic (FOL) 规则，记作 $R = {R_l,\lambda_l}^L_{l=1}$，注意这里的 $R_l$ 也就是输入的目标空间 $(x,y)$ 上的第 l 个规则，对应的 $\lambda_l \in [0,\infty]$ 为置信区间，这里的 $\lambda_l  = \infty$​ 则表示为硬规则。这里为了后续编码的灵活性和优化的方便采用软规则（soft logic）来进行 FOL 的编码，也就是说此时的值是连续的，也就是区间 [0,1] 而不是单纯的 01 集合 {0, 1}。这里集合运算的规则如下：<br>
$$<br>
\begin{align}<br>
&amp; A\&amp;B = \max {A + B-1, 0} \\<br>
&amp; A\vee B = min {A + B, 1} \\<br>
&amp; A_1 \wedge ... \wedge A_N = \sum _i A_i /N \\<br>
&amp; \neg A = 1-A<br>
\end{align}<br>
$$<br>
<br></p>
<h3 id="2-3-Rule-Knowledge-Distillation-规则知识蒸馏">2.3  Rule Knowledge Distillation 规则知识蒸馏</h3>
<p>本质一个神经网络即通过当前已知的 x 信息考虑得到一个关于 y 的条件概率 $p_\theta(y|x)$，此时记神经网络通过给定的信息 x 给出的预测结果向量为 $\sigma_\theta(x)$，注意这里的预测结果是一个 K 维的（K分类问题）软分类（soft prediction vector）</p>
<p>对于传统的神经网络而言，本质模型的训练也就是不断将最后输出的 $p_\theta(y|x)$ 同正确的标签比较并更新神经网络的参数 θ，但是这里为了同时向模型中加入规则中蕴含的信息，这里同时要求模型去模仿一个规则正则化的模型给出的 $p_\theta(y|x)$，记作  $q(y|x)$</p>
<p>这里采用 <strong>蒸馏（distillation）</strong> 方法的思路：将模型给出的预测 $p_\theta(y|x)$ 称作 学生（student），而规则正则化模型给出的记作 $q(y|x)$，称为老师（teacher），此时老师本身理解一定的逻辑规则，则老师会为某一个问题给出自己的解答（也就是这里的给定 x 输出 q(y|x)），而学生的任务就是将自己对这个问题的解答（也就是 $p_\theta(y|x)$）同老师给出的解答作对比，不断更正自己的答案以接近老师的答案</p>
<p>具体更新参数 θ 的时候考虑的是 1）预测真的正确的标签 hard label 2）学习规则正则化的模型给出的 $p_\theta(y|x)$ 这两个任务的平衡：<br>
$$<br>
\theta ^{(t-1)} = \arg\min _{\theta \in \Theta} \frac{1}{N} \sum _{n=1} ^N (1-\pi) l(y_n, \sigma _\theta (x_n)) + \pi l(s_n ^{(t)}, \sigma _\theta (x_n))<br>
$$</p>
<p>这里的 $l$ 是对应的任务的损失函数（比如分类任务就是交叉熵损失函数之类），$\sigma_\theta(x_n)$ 也就是模型给出的预测，$s_n^{(t)}$ 是 teacher 部分的针对 xn 的软逻辑预测向量，这里通过 $\pi$ 来控制两个任务之间的比重</p>
<br>
<h3 id="2-4-Teacher-Network-Construction-教师网络构建">2.4 Teacher Network Construction 教师网络构建</h3>
<p>每一轮迭代（设这里是第 t 轮）都需要构造一个教师网络（teacher network），这里利用后验正则化规则来帮助逻辑约束的构建</p>
<p>假设这里有一系列的规则 （FOL rules），记作 $R = {R_l,\lambda_l}^L_{l=1}$，则教师网络的目标就是找到一个对应的 $q(y|x)$，一方面是服从规则的，一方面是接近 $p_\theta$ 的</p>
<ul>
<li>对于要求 q(y|x) 服从规则方面，此时采用 expectation operator 的方式：此时令 $r_{lg}(X,Y)$ 来标识从 X 到 Y 是否是服从规则 $R_l$ 的，则我想要 q(y|x) 在置信区间 $\lambda_l$ 满足 $$E_{q(y|x)}[r_{lg}(X,Y)] = 1 $$</li>
<li>对于要求 q(y|x) 一定程度上接近 $p_\theta$ 方面，实际上也就是要求两个分布尽量接近，则此时衡量接近的程度用 KL 散度</li>
</ul>
<p>综上，此时构造 q(y|x) 也就是在约束下（也就是满足规则 Rl 的约束下）最小化第二个任务的损失函数（也就是 KL 散度）：<br>
$$<br>
\begin{align}<br>
\min _{q, \xi \geq 0} &amp;\text{ } KL(q(Y \vert X) || p _\theta (Y|X)) + C \sum _{l, g_l} \xi _{l, g_l} \\<br>
s.t. &amp;\text{ } \lambda(1-\mathbb{E}_q [r _{l, g_l} (X, Y)]) \leq \xi _{l, g_l} \\<br>
&amp;\text{ } g_l = 1, ..., G_l, \text{ } l = 1, ..., L<br>
\end{align}<br>
$$</p>
<p>本质也就是一个优化问题，这里的 $\xi_{l,g_l}$​​ 是对应的松弛变量（slack variable），注意这里实际上是一个凸优化问题，可以通过原问题的对偶问题解决，此时上述优化任务的对偶问题可以得到如下形式的解：<br>
$$<br>
q ^* (Y|X) \propto p _\theta (Y|X) exp {-\sum _{l, g_l} C\lambda_l (1-r _{l, g_l} (X,Y))}<br>
$$</p>
<br>
<br>
<h3 id="2-5-训练和测试">2.5 训练和测试</h3>
<p>整体的伪代码：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023103947133.png" alt="image-20231023103947133" style="zoom:60%;" />
<p>注意这里每一轮都要新构建一个 teacher，再更新 student 的参数，本质上 teacher 的构建是一个凸优化问题（通过求解其对偶问题得到 q(y|x) 参与 student 的训练），而 student 部分也就是不断更新对应的 θ 参数的过程</p>
<p>注意最后测试的时候可以用 student 给出的 p(y|x)，也可以用 teacher 给出的 q(y|x)，一般来说 q 的 teacher 的表现会好一些，本质上来说 q 对于数据涉及的  / 本身逻辑规则覆盖的情况效果较好，而 p 对于纯粹未知的情况的处理效果较好</p>
<br>
<br>
<hr>
<h2 id="3-Applications">3  Applications</h2>
<p>这里考虑分别在 CNN 和 RNN 两个最为常用的神经网络基本框架上实验效果，这里的 CNN 用于文本情感分类，而 RNN 对标实体识别任务</p>
<h3 id="3-1-Sentiment-Classification-情感分类">3.1 Sentiment Classification 情感分类</h3>
<p>这里采用一通道的 CNN，引入 but 规则：<br>
$$<br>
\begin{align}<br>
&amp;\text{has- 'A-but-B'-structure(S)} \Rightarrow \\<br>
&amp;(1(y=+) \Rightarrow \sigma _\theta(B) _+ \wedge \sigma _\theta (B) _+ \Rightarrow 1(y=+))<br>
\end{align}<br>
$$</p>
<p>$1()$​ 函数标识内部逻辑的正确与否，正确返回 1，错误返回 0；上面这个规则可以直观理解为 but 前后出现情感的转折</p>
<p>这里用三个数据集 <strong>SST2 + MR + CR</strong> 来评价效果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023105846377.png" alt="image-20231023105846377" style="zoom:60%;" />
<p>可以看到这里的提升还是比较明显的，并且 q（teacher） 的表现稍优于 p（student）</p>
<br>
<h3 id="3-2-Named-Entity-Recognition-命名实体识别">3.2  Named Entity Recognition 命名实体识别</h3>
<p>也就是 NER 任务，也就是将句子中的实体文本识别出来并加入不同的实体类别，LSTM 在类似的任务上表现不错，这里考虑用本文的方法优化 LSTM 的 RNN 部分</p>
<p>这里对应的规则：<br>
$$<br>
\text{equal} (y _{i-1}, \text{I-ORG}) \Rightarrow \neg \text{equal} (y_i, \text{B-PER})<br>
$$</p>
<p>也就是 I-ORG 不能跟在 B-PER 后面</p>
<p>注意这里的置信度 $\lambda_l = \infty$，也就是说这里是一个硬规则，一点都不能违反</p>
<p>这里在 <strong>CoNLL-2003</strong> 数据集上进行测试，结果如下：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023110025249.png" alt="image-20231023110025249" style="zoom:60%;" />
<p>同理可以看出这里的 q（teacher） 的表现是要略好于 p（student）的表现的</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器推理Reasoning</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器推理Reasoning</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Module Networks + NLP + Reasoning: 可用于文本推理的模块神经网络</title>
    <url>/2023/10/30/20210706-paper-note-moduleReasoning20/</url>
    <content><![CDATA[<p>原文写于 20210706，存档如下</p>
<blockquote>
<p><strong>Neural Module Networks for Reasoning over Text</strong> ; Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh &amp; Matt Gardner; University of Pennsylvania, Philadelphia, University of California, Berkeley, University of California, Irvine, Allen Institute for AI</p>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE5MTIuMDQ5NzF2Mi5wZGY=">https://arxiv.org/pdf/1912.04971v2.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL25pdGlzaGd1cHRhL25tbi1kcm9w">official，基于 AllenNLP<i class="fa fa-external-link-alt"></i></span> ** <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0NPTVA2MjQ4LVJlcHJvZHVjYWJpbGl0eS1DaGFsbGVuZ2UvQ09NUDYyNDgtUmVwcm9kdWNhYmlsaXR5LUNoYWxsZW5nZS1OTU4tRHJvcC1mb3ItUmVhc29uaW5nLU92ZXItVGV4dA==">pytorch 实现<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-introduction">1 introduction</h2>
<p>本文同理针对需要多跳推理的问题；这里首先解释一下几个概念：</p>
<ul>
<li><strong>KBQA</strong>：基于知识图谱的问答(KBQA) = knowledge base question answering，也就是在三元组上进行推理和查找最后得到答案</li>
<li><strong>机器阅读理解</strong>：多针对自然语言形式的文章，而非已经提取的三元组的形式</li>
<li><strong>多跳推理问题</strong>：可以直观地理解为需要多次跳转，将不同的信息进行进一步整合才能得到答案的问题（多跳阅读理解也就是基于自然语言形式的文章，同理知识图谱领域也存在多跳推理）。这里还是用 CogQA 的图举个例子：</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021084007009.png" alt="image-20231021084007009" style="zoom: 80%;" />
<p>这个问题本身问的是导演，但是没有给出电影的名字，首先需要后面的信息去推断是哪一部电影，才能进一步去寻找该电影的导演。也就是说这里问题的解决需要一个中间的推理步骤（也就是得到 //电影名称// 的中间步骤，这里的电影名称也可以称为 bridge entity）才能得到最终的答案</p>
<p>然而，除去上面此类需要查找中间实体来进行类似于 “多步搜索” 的问题，多跳阅读理解问题同时涉及符号推理问题（例如排序 / 数数问题<br>
举个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023110700618.png" alt="image-20231023110700618" style="zoom:60%;" />
<p>这里不仅是需要寻找对应的 bridge entity，不仅是需要得到一条连接初始实体和最后的答案实体的推理链，而是需要进行信息提取 + 排序 再得到最终的答案。</p>
<p>由此总结，多跳推理问题的解决主要包括以下几个步骤：</p>
<ul>
<li><strong>理解复杂问题的结构</strong>：考虑上面的例子，此时问题 = 谁 + 第二季度（限定） + 最长，首先需要模型理解这个问题的结构 → 也就是（先找到第二季度限定）下的所有得分 → 再比较 → 得到最长</li>
<li><strong>从问题精确提取信息</strong>：还是上面的例子，这里需要模型能够精确提取到 lengths / kickers / filed goal 等词汇，并从文中确实地找到相关信息</li>
<li><strong>执行符号推理</strong>：上面的问题也就是需要对提取到的数字作排序操作 + 得到最长的 → 对应得到最后的答案</li>
</ul>
<p>综上，本文尝试将 <strong>模块化的神经网络 Neural module networks (NMNs; Andreas et al., 2016)</strong> 用于解决多跳推理问题。（实际上 NMNs 已经在 VQA（视觉问答）领域取得了一定的成果（例如 CLEVR），但是针对 nlp 领域的应用还十分有限</p>
<br>
<br>
<hr>
<h2 id="2-模块神经网络-Neural-Module-Networks">2  模块神经网络 Neural Module Networks</h2>
<p>先说说所谓的模块神经网络</p>
<p>还是考虑上面给出的问题：</p>
<blockquote>
<p><strong>Who kicked the longest field goal in the second quarter?</strong></p>
</blockquote>
<p>按照正常人类的思维，读到问题后需要的步骤为：</p>
<ul>
<li>先找出所有的 field goal 的实例</li>
<li>再找出其中符合限定 in second quarter 的</li>
<li>找到它们的 lengths（来自于 longest）</li>
<li>再比较得到其中最长的（比较 / 排序</li>
<li>找到谁踢的作为最终答案</li>
</ul>
<p>而 NMNs 读到上述问题后，会将问题拆解为几个<strong>可执行的模块</strong>，比如上面的问题可以拆解为：$$relocate(find-max-num(filter(find())))$$<br>
先执行最内部的 find = 找到所有的 field goal 的示例，再 filter（符合 in second quarter 的限定）再 find-max-num 取最大值，再找到是谁踢的（relocate）</p>
<p>综上，将 NMN 应用于推理问答，需要：</p>
<ul>
<li>
<p>定义 <strong>Modules 模块</strong>，这里可能的模块限定于预先定义好的几种，具体的功能在后面介绍：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023110727182.png" alt="image-20231023110727182" style="zoom:60%;" />
</li>
<li>
<p>得到<strong>上下文表示</strong>：这里采用 预训练模型 + embedding 的形式得到问题和上下文的 embedding，分别用 BERT 和 双向 GRU 两种方式实现</p>
</li>
<li>
<p>实现 <strong>问题分解 Question Parser</strong>：也就是将问题分解为上述定义好的可执行模块，这里同时利用到了 encoder-decoder 和注意力机制</p>
</li>
<li>
<p>训练 <strong>模块执行器</strong>：也就是训练得到每一个模块，以实现将规定各式的输入给定时（比如给定数字，给定文本，给定日期形式的输入），可以得到我想要找到的输出</p>
</li>
</ul>
<br>
<br>
<hr>
<h2 id="3-整体模型">3 整体模型</h2>
<br>
<h3 id="3-1-问题分解-question-parser">3.1 问题分解 question parser</h3>
<p>首先通过双向 GRU 或 BERT 得到问题的 embedding，利用 GRU 的最后一层的 ht 或 BERT 中的 [CLS] 的 embedding 作为输入，也就是说这里的输入应该是整个问题句子的语义信息</p>
<p>这里选择 LSTM 作为 decoder（见原文附录2，但是 encoder 具体用的是什么好像没有点名，下次读读源码），将我们定义好的 10 种模块作为 vocabulary 来实现问题的分解（具体做法将每一个模块都转化为一个 100 维的 embedding），中间涉及注意力机制的计算是 decoder 和 encoder 的隐藏层之间的</p>
<p>具体 question parser 的结构原文没有给明，还需要读读源码看。总体的结构是 encoder + decoder 的形式，将 10 种模块转化为 embedding 作为最后的 decoder 部分输出用到的 vocabulary</p>
<p>注意这里使用 LSTM 还有别的原因，因为定义的 10 个模块本身存在输入和输出的格式限制（比如 find-num 的输出一定要是 N，但是 find-num 的输入一定要是文段 P，此时如果 find-num → 输出 N → 后面再跟着一个 find-num，则此时的分解就是非法的。而 LSTM 存在（将前一个已经生成的模块再作为下一个生成的输入利用）的特点，此时可以利用 LSTM 的这个特性控制不要生成问题的非法分解。</p>
<br>
<h3 id="3-1-定义模块-module">3.1 定义模块 module</h3>
<p>这里共预先定义了 10 种模块，NMN 也就是用这 10 种模块来表示问题，分别训练每一种模块，再同通过按分解顺序依次执行对应的模块得到最后的答案：</p>
<p>注意这里定义的模块可以分为两种：</p>
<ul>
<li>自然语言推理：也就是从文中找到信息的步骤</li>
<li>符号推理：也就是通过得到的信息来进行客观意义上的推理得到最后的答案（比如计算差值，计数，取最大值，排序等等</li>
</ul>
<p>这里两种类型的模块分别定义了五种，绿色部分是 natural language reasoning，黄色部分是 symbolic reasoning</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023111119568.png" alt="image-20231023111119568" style="zoom:67%;" />
<p>这里的 In 和 Out 表示：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023111235267.png" alt="image-20231023111235267" style="zoom:67%;" />
<p>以下分别介绍每一个模块：</p>
<ul>
<li>
<p>$find(Q) \to P$：也就是输入问题，找到和问题相关的语段；具体利用注意力机制：先计算对应文段的各个 token 和问题的各个 token 之间的相似度矩阵，记作 S；对应的 S 的 i，j 位置元素定义为：$$S_{ij} = w_f^T[Q_i. ; P_j. ; Q_i. \circ P_j.]$$这里的 wfT 是待学习参数；对应的 o 是 elementwise 的乘法；对应得到 S 矩阵后通过 softmax 得到文段和问题之间的注意力矩阵 A，通过注意力的方法从给定的上下文文段中得到最后的输出 P</p>
</li>
<li>
<p>$filter(Q,P) \to P$：也就是通过问题中的限定条件来从给定的 P 中筛选出一部分符合的 P 文段；举例就是上面的问题中实现 in second quarter 的限定条件的部分。实际理解也就是 mask 掉一部分 P 中的内容（不符合的就 mask 掉），则此时计算文段 P 的第 j 个 token 对应的 masking score：$$M_j = \sigma(w_{filter}^T[q ; P_j. ; q\circ P_j.])$$这里的小 q 通过问题的 embedding  = Q 来计算：$q = \sum_i Q_i Q_i. \in R^d$，对应的 σ 是 sigmoid 函数，同理 wfT 是可学习参数，最后对应的输出 P 通过下式得到：$$P_{filter} = normalize(M \circ P)$$</p>
</li>
<li>
<p>$relocate(Q,P) \rightarrow P$：也就是依据问题重新定位，举例就是依照上面的例子，找到 longest 的 field score 后需要找到 who kick；首先计算 P 对 P 的注意力矩阵：$$R_{ij} = w_{relocate}^T [(q+P_i.) ; P_j. ; (q+P_i.)\circ P_j.]$$ $$q = \sum_i Q_i Q_i. \in R^d$$得到 R 后经过 softmax，最后的输出通过 $P_{located} = \sum_i P_i R_i.$ 得到</p>
</li>
<li>
<p>$\text{find-num(P)}\to N \text{ / } \text{find-date(P)} \rightarrow D$：同理是计算对应的文段 P 和文段中的数字 / 日期部分之间的相似度矩阵。以数字为例，假设此时文段 P 中存在 $N_{token}$ 个数字，每一个数字也就是一个 token，则此时计算对应的相似度矩阵 $S^{num}$：$$S_{ij} = P_i.^T W_{num} P_{n_j}.$$ 这里的 Pnj 也就是第 j 次提到的数字对应的 token；对 S 作 softmax 后得到 A，并通过 $T = \sum_i P_i A_i.^{num}$ 得到每一个提及对应为答案的概率，再得到最后的输出。注意这里如果两次提及都是相同的数字，需要将两次提及对应的概率相加；比如此时提及为 2234，对应的概率为 0.1 0.4 0.3 0.2，则此时答案为 234 的概率分别为 0.5 0.3 0.2；对应日期同理</p>
</li>
<li>
<p>$count(P) \rightarrow C$：这部分挺复杂的，建议直接看原文部分可能更清楚一些 ... 本质的思想是计算注意力向量中连续相同的多个值的 span 大小，比如如果这里的向量为 0.3 0.3 0.2 0.4，则输出为 2（因为两个相同的 0.3 存在）。首先利用（一个奇怪的初值）[1,2,5,10] 作为权重来得到 $P_{scaled}\in R^{m*4}$，再扔进一个双向 GRU 得到隐藏状态 ht，再通过单层前馈和 sigmoid 得到对应的 $c_v$，也就是 $$c_v = \sum \sigma(FF(countGRU(P_{scaled})))$$这里用到正态假设，认为最后的答案是以 cv 为均值，方差为 0.5 的数，则此时对应计算答案 c：$$p(c) \propto exp(-(c-c_v)^2/2v^2)$$</p>
</li>
<li>
<p>$\text{compare-num-lt(P1, P2)} \rightarrow P$：此时要求输出的 P 是较小的一个。首先将 P1 和 P2 扔进 find-num 的那个模块中，对应得到数字 N1 和 N2。注意这里的 find-num 得到的模块是（多个数字提及）和（其对应的概率）的形式，则此时计算概率：<br>
$$<br>
\begin{align}<br>
p(N_1 &lt; N_2) &amp;= \sum _i \sum _j \mathbb{1} _{N_1^i &lt; N_2^j} {N_1^i N_2^j} \\<br>
p(N_2 &lt; N_1) &amp;= \sum _i \sum _j \mathbb{1} _{N_2^i &lt; N_1^j} {N_2^i N_1^j}<br>
\end{align}<br>
$$</p>
<p>对应得到最终的输出 Pout：$P_{out} = p(N_1&lt;N_2) * P_1 + p(N_2&lt;N_1)*P_2$​，随着训练不断进行，对应的两个 P 会不断接近边界 0/1，则此时对应的 Pout 也就是 P1 和 P2 二者其一</p>
</li>
<li>
<p>对应的 $\text{compare-num-gt , compare-date-lt, compare-date-gt}$ 和上面的处理方法相似，在此不再赘述</p>
</li>
<li>
<p>$\text{time-diff}(P_1, P_2)$：同理先通过 find-date 得到两个 P 对应的 D1 和 D2，同理这里的 D1 和 D2 是带有概率的日期列表，则计算 D1i 和 D2j 之间的差值，再对应乘上相关的概率，求加权平均。对应的概率计算：$p(t_d) = \sum_{i,j} 1_{(d_i-d_j  = t_d)} D_1^i D_2^j$</p>
</li>
<li>
<p>$\text{find-max-num}(P)$：同理先通过 find-num 提取出数字列表，注意这里实际上是得到了文段中每一个数字提及对应的概率，记作 T，也就是第 j 个提及对应一个概率 Tj；再计算 Tmax，这里是通过抽样的方式实现的，原文比较清楚：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023111452907.png" alt="image-20231023111452907" style="zoom:67%;" />
<p>最后通过 $P_i  = \sum_j T_j^{max} / T_j P_i A_{ij}.$ 计算出我的输出结果 P</p>
</li>
<li>
<p>$span(P) \rightarrow S$：也就是输出两个向量，分别表示每一个 token 是 start 或 end 的概率，训练方式和 count 相似，详细部分见原文的附录部分</p>
</li>
</ul>
<br>
<h3 id="3-3-模型训练">3.3 模型训练</h3>
<p>注意到前面的模块是很复杂的，先需要训练问题分解部分，还要再训练模块本身的功能，如果直接利用端到端训练会很难</p>
<p>这里使用 auxiliary training 的方式来完成模型训练。</p>
<ul>
<li>
<p><strong>模块功能的无监督训练</strong>：针对 find-num / find-date / relocate 三个模块，本身的作用也就是从 P 文段中提取信息，这里希望在数字 / 日期提及周围的 token 能够得到更高的关注，则此时控制窗口大小 W = 10，希望在提及 mention 的窗口范围内的 token 能够有更高的 attention，对应损失函数设置为：<br>
$$<br>
H _{loss} ^n = -\sum _{i=1} ^m \log (\sum _{j=0} ^{N _{tokens}} \mathbb{1} _{n_j \in [i\pm W] }A ^{num} _{ij})<br>
$$<br>
此时这三个模块对应在一起训练，此时对应的总损失函数 = 三个模块对应的损失函数的加和</p>
</li>
<li>
<p><strong>问题分解的有监督训练</strong>：这里由于本文使用的是 DROP 数据集，并没有任何关于问题分解的标签可用，这里作者直接选取了约 10% 的问题人工手动分解为几个模块来训练 question parser 部分。则此时的训练部分和带 LSTM  的 encoder + decoder 模型相同</p>
</li>
<li>
<p><strong>模型输出的监督学习</strong>：这里存在真实答案所以可以直接进行监督学习。同时考虑到对于（最短的是什么？）类似的问题，对于 find-num 模块，真实答案只是帮助模块确认了是否找到了最小的那个 num，对于其他的 num 的寻找不存在监督作用，长此以往的训练会导致 find-num 就只倾向于找到较小的 num，而导致整体模型的有偏。为了缓解这一问题，这里对约 5% 的可能出现类似情况的问题加入噪音，比如对于 （A 的最短 xxx 是多少） 的问题，我们认为离 A 最近的一个数字本身也应该作为 find-num 的一个输出存在。将这样的噪音加入训练集，和真实答案一同进行模型的监督学习</p>
</li>
</ul>
<br>
<br>
<hr>
<h2 id="4-experiment-实验部分">4 experiment 实验部分</h2>
<p>这里使用的是 AllenNLP 的 DROP 数据集来进行实验</p>
<p>DROP 本身是一个融合了实体查找（也就是自然语言推理部分，本身是 bridge 实体的提取和信息的综合）和符号推理（也就是客观推理部分，比如排序，求最大值etc）的数据集，这里选用 DROP 来进行实验</p>
<p>注意由于这里的推理能力是很有限的（本身只是定义了 10 种类型的 module），原文作者筛选了 20000 个符合相关类型的问题来作测试（也就是集中于讨论 数字类，比较，日期计算 etc 之类的问题）</p>
<p>此时得到的问题本身可以分为六类：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023111705218.png" alt="image-20231023111705218" style="zoom:60%;" />
<p>实验结果：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023111725347.png" alt="image-20231023111725347" style="zoom:60%;" />
<p>可以看到这里的提升还是比较明显的，同时初始的问题和文段的 embedding 对应的预训练模型对于整体模型效果还是影响很大的（GRU 对应的模型效果非常不行），本身从模型构造的角度来说也能感觉得到它很依赖初始 embedding 的质量（比如不停进行相似度矩阵计算 etc)</p>
<p>同时问题暴露也比较明显。作者给出了三类较为典型的回答错误的问题：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023111748733.png" alt="image-20231023111748733" style="zoom:67%;" />
<br/>
<blockquote>
<p><strong>最后胡说几句：</strong></p>
</blockquote>
<p>个人认为还是模块设计本身对整体模型带来巨大限制；1）10个预设置的模块只能帮助模型解决数学类的符号推理问题，对于需要利用逻辑规则等的，更自然语言或人类常识方向的推理，由于其本身的多样性直接预设值模块是根本不可行的；2）LSTM 作为 decoder + 模块本身的输入输出限制 使得模块本身的组合有限（比如不能连着两个 find-num，只能是链状结构不能为树状；<br>
但是对于类似于数值推理之类的，本身规则类别较少的推理问题或许这是一个可借鉴的思路，预先设计模块 + 把模块 embedding 了作为 vocabulary 来辅助 question parser 这种思路是真的很有意思hhh 一眼看上去会觉得 哇 的那种程度 ...<br>
还有就是模型太多的细节论文没讲清楚，特别是 question parser 部分和训练部分，正文动不动指向附录但是附录还是啥都没说明白 ... 或者是我没读明白也说不定hhh（有机会还是看看源码吧（</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器推理Reasoning</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器推理Reasoning</tag>
      </tags>
  </entry>
  <entry>
    <title>HopRetriever: 通过 Hop 检索回答开放领域的复杂多跳问题</title>
    <url>/2023/10/30/20210922-paper-note-HopRetriever/</url>
    <content><![CDATA[<p>原文写于 20210922，存档如下</p>
<p>时隔两年再读到会小小叹气唉 ...</p>
<blockquote>
<p><strong>HopRetriever:Retrieve Hops over Wikipedia to Answer Complex Questions</strong> ; Shaobo Li, Xiaoguang Li, Lifeng Shang, Xin Jiang,<br>
Qun Liu, Chengjie Sun, Zhenzhou Ji, Bingquan Liu; Harbin Institute of Technology; Huawei Noah’s Ark Lab</p>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzIwMTIuMTU1MzR2MS5wZGY=">https://arxiv.org/pdf/2012.15534v1.pdf<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-background">1. background</h2>
<p>一开始先明确这篇问题针对的问题：开放领域问答中的多跳问题回答</p>
<h3 id="1-1-开放领域问答（open-domain-question-answering）">1.1 开放领域问答（open-domain question answering）</h3>
<p>开放领域问答，应当分类为机器问答中的一种，可以简单解释为 <strong>于开放领域中（例如维基百科全体信息，此时问题可以是各种领域的各种问题）利用机器回答人类以自然语言形式提出的问题</strong>，同其他几种机器问答系统不同在于此时是针对开放领域提问的，可以理解为此时的问题可以涉及不同的各式的领域，也可以理解为此时回答问题所需要的知识领域是很广阔的，例如：</p>
<ul>
<li>传统机器阅读理解问题：给定一篇 / 多篇拜登 / 美国相关的文章，再提问美国总统是谁</li>
<li>开放领域问答问题：提问美国总统是谁？让子弹飞的导演是谁？北京是哪里的城市？所有问题都需要在庞大的知识库中（例如维基百科）寻找答案</li>
</ul>
<p>同理，相较于传统机器阅读理解问题的数据集会给定文章的形式，对应大部分开放领域问答数据集会将允许的答案检索文段设定为维基百科全部词条。对应的<strong>知识库的形式</strong>，可以为以下三种：</p>
<ul>
<li>1）结构化的，例如构造好的知识图谱的形式；</li>
<li>2）半结构化的，表格等；</li>
<li>3）非结构化的，如维基百科的自然语言形式的词条，本文所使用的为第三种形式（即问题与所依赖的知识库都是自然语言的形式）</li>
</ul>
<p>对应开放领域问答的任务形式，一般针对此类问题的回答分为两个步骤：</p>
<ul>
<li><strong>信息检索（information Retrieval， IR）</strong>：比如美国总统是谁的问题，此时需要机器先从知识库中得到美国相关的词条信息</li>
<li><strong>机器阅读理解（Machine Reading Comprehension， MRC）</strong>：也就是根据检索出的文段回答问题，类似传统的机器阅读理解形式</li>
</ul>
<br>
<h3 id="1-2-多跳阅读理解问题（multi-hop-complex-question）">1.2 多跳阅读理解问题（multi-hop / complex question）</h3>
<p>可以直观地理解为 <strong>需要多次跳转，将不同的信息进行进一步整合才能得到答案的阅读理解问题</strong>，举个例子（例子来自 CogQA）：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231021084007009.png" alt="image-20231021084007009" style="zoom: 80%;" />
<p>这个问题本身问的是导演，但是没有给出电影的名字，首先需要后面的信息去推断是哪一部电影，才能进一步去寻找该电影的导演。也就是说相较于传统的简单问题形式，多跳阅读理解问题需要机器掌握一定推理的能力，能够依据问题信息多步寻找所需要的信息并不断更新证据链，最终得到需要的答案。</p>
<br>
<br/>
<hr>
<h2 id="2-introduction">2 introduction</h2>
<p>针对开放领域的多跳阅读理解问题，当前主流模型大多为 Retriever + Reader 的结构：</p>
<ul>
<li>$D_q = Retriever(q,K)$：负责从知识库 K 中，依据问题 q 搜索可能的证据</li>
<li>$a = Reader(q, D_q)$：利用检索得到的证据 Dq 再结合问题 q 得到最后的答案</li>
</ul>
<p>此时如何收集所需要的信息或成为整个问题流程中最大的挑战，考虑此时知识库内存有大量信息，而为回答多跳问题同时需要从多个相关信息词条中收集所需要的信息并聚合，对于上述 retriever + reader 结构形式的模型而言，此时相较于传统的简单阅读理解问题，信息收集部分模型的能力十分重要。</p>
<p>最近主流的方法是将<strong>多跳证据收集作为迭代文档检索问题</strong>来处理，也就是将一个复杂问题的分步搜索求解的，从整个知识源中检索证据链的过程，分解成多个单步文档检索。而本文的作者认为，在这样检索的过程中需要同时利用结构化信息和非结构化信息；举个例子来解释这里的结构化和非结构化：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023112617930.png" alt="image-20231023112617930" style="zoom:67%;" />
<ul>
<li>结构化信息：也就是提及关系，例如左图中通过 spawned 关系提及了对应的三首歌，spawn 同时符合问题中的 song of 关系，故此时能够提示模型三首歌的信息是所需要的信息；</li>
<li>非结构化信息：也就是外来知识，比如此时可以通过对应歌名的超链接跳转到新的链接对应得到新的信息。注意此时三首歌中只有第一首是符合合作要求的，故此时模型需要探索三首歌对应的外部链接对应词条的信息，才能从三个选项中得到正确答案；</li>
</ul>
<p>综上，对于开放领域的问答，此时需要同时关注</p>
<ul>
<li>1）当前文档中对于下一跳实体的提及信息  = 结构化信息 = 关系证据；</li>
<li>2）下一跳实体本身链接对应的新的外部信息 = 非结构化信息 = 事实证据</li>
</ul>
<p>本文重点即在于将上述两种类型的信息结合起来，为此，作者定义了 <strong>跃点 = hop</strong> 为 <strong>超链接 + 链接对应外部词条内容的组合</strong>，此时可以认为 超链接 记录了当前实体和前序实体的关系（也就是新的实体是怎样在前一个实体的文档中被提及的），而超链接对应的外部词条内容扩充了被提及实体的信息。同时，本文着重研究了如何 <strong>有选择地提取需要的非结构化信息</strong>，同时将 <strong>结构化信息与非结构化信息作融合</strong></p>
<p>其实个人觉得这里的结构化信息 = mention 也就是 KGQA 中的实体关系的部分；而非结构化信息也就是其中尾结点的 embedding 的部分，对于 KGQA 而言本文的思路是十分常见的（也就是寻找在知识图谱上推理的路径的思路），只是在自然语言形式的文本下，实体的信息与各自的关系结构不像知识图谱中这么显式，需要一定的抽取整合工作</p>
<br>
<br>
<hr>
<h2 id="3-Method">3 Method</h2>
<br>
<h3 id="3-1-Overview">3.1 Overview</h3>
<p>先看看模型整体结构：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023112702952.png" alt="image-20231023112702952" style="zoom:50%;" />
<p>这里通过一个示例问题来展示模型流程：</p>
<ul>
<li>首先从问题中可以获取 Big Stone Gap 的实体</li>
<li>以该实体作为出发点，可以在其相关的文档中发现提及实体 Adriana 和 Donna；注意此时超链接对应的上下文中包含了 （directed by）和（produced by）的信息，这些信息 = 上述的结构化信息 = 提示了电影和两个人名之间的关系；</li>
<li>以 Adriana 的提及为例，此时其超链接对应上下文的信息（蓝色部分）作为 mention，而超链接对应的外部词条（也就是 Adriana 词条）作为 document，分别提供关系信息和事实信息，模型将这两种类型的信息作融合，作为 跃点 = hop 的信息；</li>
<li>由上步骤，同理可以从被提及的实体（例如上面的 Adriana）再出发寻找下一跳的实体，由此不断生成证据链，且注意到证据链中的每一跳 = 每一个跃点 = hop 都是存在自己的表示的（由 document 和 mention 两方面的信息组成）</li>
<li>以一定的条件结束检索，得到证据链与最终答案</li>
</ul>
<br>
<h3 id="3-2-Hop-encoding">3.2 Hop encoding</h3>
<p>首先考察如何得到跃点 = hop 的 embedding 信息，也就是<strong>同时得到 mention 和 document 的信息，并将其作融合</strong>（也就是同时融合结构化信息和非结构化信息 = 同时融合证据信息和事实信息的过程）</p>
<h4 id="3-2-1-mention-embedding">3.2.1 mention embedding</h4>
<p>设此时在实体 $e_i$ 的文档 $d_I$ 中提到了实体 $e_j$，提及部分的语句为  $m_{i,j}$</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023112738537.png" alt="image-20231023112738537" style="zoom:67%;" />
<p>以 the album spawned three singles <em>On My Mind</em> , ... 这样的一句话为例，这句话标志了从实体 ei = album 提及了 single 实体 ej = On My Mind，则这句话本身作为 $m_{i,j}$，本文采用的方法为在这句话的提及实体（也就是 On My Mind）的前后各加入一个特殊的 $[MARKER]$ 的token，将 原问题 + mention 部分的这一句话作拼接 → 再扔进 BERT，并取第一个 $[MARKER]$ 对应的 embedding 作为 mention 部分的 embedding</p>
<p>如果此时文档中没有直接提及实体 ej（例如相关词条的形式，在逛 ei 的词条的时候可能相关词条中出现了 ej 但是并没有一个明确的 mention 的一句话提到 ej）则用一个固定的向量 $m_p$ 作为 mention 部分的 embedding；注意 $m_p$ 是可学习的<br>
也就是由下式获得提及 $m_{i,j}$​ 的 embedding：<br>
$$<br>
m _{i,j} =<br>
\begin{cases}<br>
\text{BERT} _{[M-j]} (q; d_i), &amp;\text{if } m _{i, j} \in M \\<br>
m_p, &amp;\text{otherwise}<br>
\end{cases}<br>
$$</p>
<p>这个做法似乎是借鉴了 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE5MDYuMDMxNTh2MQ==">ACL2019 的文章：Matching the Blanks: Distributional Similarity for Relation Learning<i class="fa fa-external-link-alt"></i></span>，具体有效性和理由可能需要读读这篇</p>
<h4 id="3-2-2-document-embedding">3.2.2 document embedding</h4>
<p>这部分比较简单粗暴，也就是将被提及实体 $e_j$ 对应的外部词条的整个内容 $d_j$ 同问题 $q$ 拼接后，整个扔进 BERT，取 $[CLS]$ 对应 token 的 embedding 作为外部文档的 embedding，记作 $u_j$​<br>
$$<br>
u_j = \text{BERT} _{[CLS]} (q; d_j)<br>
$$</p>
<h4 id="3-2-3-knowledge-fusion">3.2.3 knowledge fusion</h4>
<p>再考虑如何将提及 = mention embedding 和外部文档 = document embedding 两部分的信息作融合<br>
记 mention embedding 为 $m_{i,j}$，而 document embedding 为 $u_j$，此时目标为得到对应的跃点的 embedding，记为 $hop_{i,j}$，这里通过注意力机制将信息作融合：<br>
$$<br>
\begin{align}<br>
a_m &amp;= hW_k m _{i, j} \\<br>
a_u &amp;= h W_k u_j \\<br>
{w_m, w_u} &amp;= \text{softmax} ({a_m, a_u}) \\<br>
\text{hop} _{i, j} &amp;= w_m \cdot W_v m _{i, j} + w_u \cdot W_v u_j<br>
\end{align}<br>
$$</p>
<p>其中 h 为过去检索的历史信息，具体是通过不断检索不断更新的（也就是每每从一个实体向下一个实体跳跃的过程中都会不断丰富 h 的信息，具体计算方式会在下面提及），这里的 h 实际上是作为注意力机制中的 query vector，而 $m_{i,j}$ 和 $u_j$ 作为 key vector，从中选出所需要的信息，并通过 softmax 获取 mention embedding 和 document embedding 相对的权重信息 $\omega_m, \omega_u$​，再结合得到对应跃点 = hop 的 embedding 信息</p>
<p>从直观的角度来说，这里的 h 也就是我当前已经推理完成得到的信息；例如问题：让子弹飞的导演家乡哪里？在初始面对问题的时候关注点应该在让子弹飞，但是已经推出导演名后关注点应该在家乡，此时不同的推理步骤对应的关注点是不同的</p>
<br>
<h3 id="3-3-Iterative-Retrieval-of-Hops">3.3  Iterative Retrieval of Hops</h3>
<p>注意到此时推理链的形成是通过不断跳跃不断寻找下一个 hop 来完成的，此时采用如下的形式完成接连的 hop 获取：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023113144858.png" alt="image-20231023113144858" style="zoom:60%;" />
<p>首先，初始的实体 $e_s$ 来自问题，在从 $e_s$ 跳跃至下一个提及实体 $e_i$ 的过程中使用一个初始的隐藏状态 $h_s$，获得这一 hop 的对应 embedding = $hop_{s,i}$ 后，将其和我初始的隐藏状态 $h_s$ 一同作为输入加入 RNN 网络， 并得到下一个 hop embedding 计算需要的隐藏状态 $h_2$，由此不断循环</p>
<p>也就是说，假设此时第 t-1 跳结束后我们来到实体 $e_i$，并期望得到实体 $e_i$ 到实体 $e_j$ 的 $hop_{i,j}$ 的信息，则此时需要用到的 $h_i$ 隐藏状态通过如下的方式计算：<br>
$$<br>
h_t =<br>
\begin{cases}<br>
h_s, &amp;t=1 \\<br>
\text{RNN} (h _{t-1}, \text{hop} _{k, i}), &amp;t\geq2<br>
\end{cases}<br>
$$</p>
<p>同时注意到，一个实体 $e_i$ 下可能有多个提及 $e_j$，为从中选择出下一步确实需要移动的实体，我们计算每一个可能的 $hop_{i,j}$ 确实为推理链中的一环的概率（通过对应第 t hop 的隐藏状态 ht 和该 hop 的 embedding 的点乘再 sigmoid）<br>
$$<br>
p(d_j) = \text{sigmoid} (h_t^T \text{hop} _{i, j})<br>
$$</p>
<p>为了标记何时结束跳跃，此时定义一个表示结束状态的 hop，记作 $hop_e$，其对应为 mention embedding $m_p$（也就是前面如果我们的 ei 实体中没有直接提及 ej 的时候使用的 mention embedding)和一个虚拟的 document embedding $u_e$ 的结合；如果此时 $hop_e$​​ 被选中，则停止 hop 的生成。</p>
<p>※ 整理一下上面提到的所有可能的 hop embedding：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023113333277.png" alt="image-20231023113333277" style="zoom:67%;" />
<br>
<h3 id="3-4-Fine-Grained-Sentence-Level-Retrieval">3.4 Fine-Grained Sentence-Level Retrieval</h3>
<p>注意到很多多跳阅读理解问题的数据集同时是要求给出当前答案所利用的证据的，故此时需要作支持句子检索 = 检索到底是哪些句子作为我推理链的证据</p>
<p>注意证据句子单使用 mention 的句子是不足的，也就是前面提到了 “mention 的信息只是结构化信息 = 标记了前后两个实体之间的关系信息”，但无法展示被提及实体本身的事实信息 = 非结构化信息。也就是说我的证据句子同时存在于被提及实体 ej 对应的外部词条 dj 中；</p>
<p>注意此时证据句子的检索和上述 hop 的迭代是同时进行的；假设此时经过 t 步的 hop 操作，我们位于实体 ei，想要从 ei 对应的文档 di 中寻找证据句子</p>
<p>di 文档中的第 $l$ 个句子为证据句子的概率为：<br>
$$<br>
\begin{align}<br>
s _{i, l} &amp;= \text{BERT} _{[SM-l]} (q;d_i) \\<br>
p(s_i, l) &amp;= \text{sigmoid} (h_t W_s s _{i, l})<br>
\end{align}<br>
$$</p>
<p>首先在文档 $d_i$ 的第 $l$ 个句子后加入一个特殊的 token $[SM-l]$，再将文档 di 和问题 q 拼起来扔进 BERT，将得到的 $[SM-l]$​ 的 embedding 取出（类似于 mention embedding 的获取方式），再用 (9) 式计算该句子为证据句子的概率；若此时的概率 &gt; 0.5，该句子将被认定为证据句子（因为一个文档中可能存在多句作为证据句子的所以并不是扔进 softmax 中取最大）</p>
<br>
<h3 id="3-5-objective-functions">3.5 objective functions</h3>
<p>综上，来定义最终的目标函数：</p>
<p>这里用交叉熵损失函数来处理，回忆一下，假设此时经过了 t-1 步的 hop，我们希望从当前的实体 ei 跳到下一个 ej，则我最终一通操作得到的是实体 ej 确实为下一跳实体的概率 $p(d_j)$<br>
这里令 $d_j$ 为正确推理链需要用到的文档（注意本文使用的 HotpotQA 等都是提供了解决问题的推理链的证据句子的，也就是提供了解决多跳问题的中间步骤的 bridge entity 的信息），则 hop 检索部分的损失函数定义为：<br>
$$<br>
\log p(d_j) + \sum _{\bar{d} _j \in D, \bar{d} _j \neq d_j} {\log (1-p(\bar{d}_j))}<br>
$$</p>
<p>对于证据句子检索部分，令 $s_{i,l}$​​ 表示确实为证据的句子（ ei 实体对应的词条 di 中的第 l 个句子），则损失函数同理用交叉熵定义为：<br>
$$<br>
\sum _{l \in L_i} \log p(s _{i, l}) + \sum _{l \notin L_i} \log (1-p(s _{i, l}))<br>
$$</p>
<p>在训练中需要同时最大化以上两个损失函数</p>
<br>
<br>
<hr>
<h2 id="4-experiment">4 experiment</h2>
<p>这里利用 <strong>HotpotQA</strong> 数据集作模型测试</p>
<br>
<h3 id="4-1-HotpotQA">4.1 HotpotQA</h3>
<p>先简单说说数据集</p>
<p>考虑到传统的机器阅读理解数据集存在一定的缺陷，将模型的能力仅仅限制在了简单的模式匹配，而不是真正的理解问题与顺次推理，这里为展现模型在需要一定的理解推理能力的更为复杂的多跳阅读理解问题上的优势，采用 HotpotQA 来进行测试</p>
<p>HotpotQA 为专为复杂问题 = 多跳阅读理解问题设计的数据集，其中的问题至少为两跳（也就是根本不存在简单问题，这也是其和传统机器阅读理解数据集的主要区别），分为 distractor 和 full wiki 两个赛道；前者固定为问题提供了几篇用于解答来源的文章，而后者是在整个维基百科上进行，也就是典型的开放领域的多跳问题解答任务，相较于 distractor 赛道更具挑战；</p>
<p>数据集基本包括：</p>
<ul>
<li><code>id</code> 唯一标识</li>
<li><code>question</code> 问题字符串</li>
<li><code>answer</code> 正确答案字符串，注意这里的答案是有多种类别的，有些答案只是 yes / no 类型，仅仅从文中进行 answer span 的划分不能完全满足需要</li>
<li><code>supporting_fact</code> 包含所有解答这个问题所需要的事实推理证据，每一个证据包括 title 所在段落标题和 sent_id = 具体提供了事实证据的句子的下标，也就是说这里给出的证据是精确到句子的</li>
<li><code>context</code> 参考段落内容</li>
</ul>
<p>HotpotQA 对应传统机器阅读理解的数据集（例如 CoQA,SQuAD 一类）提出了新的挑战：</p>
<ul>
<li>1）要求模型能够有从多个文档中综合收集信息的能力，也就是多个来源筛选可能的支撑性事实</li>
<li>2）不再是简单的模式匹配，本身需要模型自己具有一定的推理能力，真正理解问题并结合信息进行推理，得到最后答案</li>
<li>3）一并给出最终答案的支持证据，支持句子的正确与否同样会打分，也就是同时考察了模型的可解释性</li>
</ul>
<p>本文即在 HotpotQA 的 full wiki 赛道上测试模型，当前为排行榜 #3（2021.09.22）</p>
<br>
<h3 id="4-2-results">4.2 results</h3>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023113656895.png" alt="image-20231023113656895" style="zoom:60%;" />
<p>注意其中用于对比的几个模型</p>
<ul>
<li>CogQA 是典型的仅利用结构化信息的模型（基本思路是将提及的实体都收集起来构造认知图，再在图上进行 embedding 的传播和更新，很类似于一些推荐系统的思路，但可以说影响了后面很大一批做多跳阅读理解的论文，带着大家都去构造图去了 ...）；</li>
<li>Semantic Retrieval 是典型的仅利用非结构化信息的模型，同时检索支持文档和支持句子</li>
<li>PathRetriever 是典型的路径检索类的多跳阅读理解模型，同理是检索推理链的形式，但是仅关注了非结构化信息</li>
</ul>
<p>可以看到在 Ans = 提取答案 和 Sup = 找到支持证据的句子 两个任务上的提升都是比较明显的</p>
<p>同时，考虑到 HopRetriever 本身是针对检索部分作一定提升，在此特别考察其检索能力，主要和 PathRetriever 作对比（这里是考虑 topK 的击中率</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023113746181.png" alt="image-20231023113746181" style="zoom:55%;" />
<p>检索能力确实是大大增强了</p>
<br>
<h3 id="4-3-analysis">4.3 analysis</h3>
<p>以下进一步考察模型的特点与优势方面：</p>
<h4 id="4-3-1-for-different-question-types">4.3.1 for different question types</h4>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023113820430.png" alt="image-20231023113820430" style="zoom:55%;" />
<p>这里将 HotpotQA 中的问题分为两个类别：</p>
<ul>
<li>comparison 比较类，例如 A 和 B 谁年龄大，此时需要同时收集 A 和 B 的信息，再作比较，再给出答案</li>
<li>bridging 中间实体类，例如 1999年在 A 地拍摄的电影的导演是谁，此时需要先找到电影是哪一部（也就是中间步骤的 bridge entity）才能回答问题</li>
</ul>
<p>本身 hop 检索的方式就直观上更适应 bridging 类型问题的思路模式，最终结果也是在 bridging 问题上有所提升，而比较类问题表现较差；</p>
<p>可以理解，此时比较类问题更多关注的是非结构化信息；比如提问：A 和 B 谁的年龄更大，此时需要去寻找 A 和 B 的信息，再分别比较，关注的是 A 和 B 各自的信息 = 非结构化信息 = 事实证据，而不是 A 和 B 的信息之间的关系 = 结构化信息；故在比较类问题上，仅关注非结构化信息的 PathRetriever 和本文的模型效果差距不大</p>
<p>但是在 bridging 类型的问题上，此时我选择下一跳为哪一个实体等等子任务都是需要把握实体之间的关系的，也就是说相较于比较类问题会更关注结构化信息，因此本文模型于 bridging 类问题上有更好的提升</p>
<p>这里作者也确实去数据集检查了两类问题中的 mention 和 document 的比例：（这里也就是 mention embedding 和 document embedding 结合的部分的两个权重的比值（对应上面的 $\omega_1, \omega_2$）</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023113843027.png" alt="image-20231023113843027" style="zoom:67%;" />
<p>再来几个例子：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023113901172.png" alt="image-20231023113901172" style="zoom:60%;" />
<p>可以看到确实在 Case1 中，mention 本身便已经足够帮助解答问题（已经点明了 directed by），此时非结构化信息对于（选择导演 Adriana 作为下一跳的实体）是没有帮助的；</p>
<p>但是对于 Case 2，此时 mention 提及的实体是模糊的（同时存在两个），此时需要两个实体对应的非结构化信息，结合题目中的限制，来帮助确定下一跳的实体该是哪一个；</p>
<p>对于 Case 3 此时则不需要 mention 的信息（比较类问题），此时只是需要回答两个简单问题（分别 located in？）再作比较即可；并不需要关注实体之间的关系证据</p>
<p>综上，此时为解决多样的问题形式，结构化信息和非结构化信息均需要重视，本文提升点亦在此</p>
<h4 id="4-3-2-ablation-experiment">4.3.2  ablation experiment</h4>
<p>为检验模型各部分各自的效果，作者同理进行了消融实验：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023113925518.png" alt="image-20231023113925518" style="zoom: 60%;" />
<p>可以看到此时结构化信息对于模型是十分重要的；这也是模型相较于大多只关注非结构化信息的模型能够有所提升的原因</p>
<p>weighting 部分表示去除了结构化信息和非结构化信息各自的权重（也就是公式 (5) 中的两个权重 $\omega_m = \omega_u  = 1$，可以看到对于模型存在一定影响；例如上面的三个不同的 Case 情况，不同类型的问题对于 结构化信息和非结构化信息的关注度不是相同的，需要以一定的偏重进行结合；</p>
<p>sentence prediction 也就是证据句子的预测，一开始就是为了某些数据集的挑战要求而设计的，去掉本身不会影响模型效果。</p>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>NLP</category>
        <category>机器阅读理解(MRC)</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>机器阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>You Only Look Once（一）: YOLO 原论文笔记</title>
    <url>/2023/10/30/20220209-paper-note-YOLO1/</url>
    <content><![CDATA[<p>原文写于 20220209，存档如下</p>
<blockquote>
<p><strong>You Only Look Once:<br>
Unified, Real-Time Object Detection</strong> ; Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi; University of Washington, Allen Institute for AI, Facebook AI Research</p>
<p>原文：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE1MDYuMDI2NDAucGRm">https://arxiv.org/pdf/1506.02640.pdf<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<span id="more"></span>
<p>我：和 YOLO 小打小闹半年了</p>
<p>也是我：这是什么 → 看博客看源码 → 这是什么 → 看博客看源码 → 这是什么 → 看博客看源码 → 这是什么</p>
<p>脑子不好使就得记下来 ...</p>
<br>
<br>
<hr>
<h2 id="1-Background">1. Background</h2>
<p>YOLO 本身是目标检测算法，简单来说就是分成两个部分，先<strong>找到图像中的物体</strong>的位置 → 再进行<strong>图像分类确认它是什么</strong></p>
<p>在 YOLO 之前也有几个常用的方法：</p>
<ul>
<li>
<p><strong>deformable parts models (DPM)</strong></p>
<ul>
<li>利用滑动窗口的思路，可以直观地理解为通过一个窗口在图片上滑动来一步一步爬着检测（虽然更多关于 DPM 的重点在优化 / 启发式算法 etc 上，这里就不过多涉及了）</li>
<li>直观，但缺陷也十分明显（注意到物体在图中的位置和大小本身都是不确定的）：此时移动的步长，起始位置，框的大小等都有很多的可能，不注意就是巨大的计算量（所以一般会配合启发式算法）</li>
</ul>
</li>
<li>
<p><strong>R-CNN 类</strong></p>
<ul>
<li>总体思路：
<ul>
<li>先生成多个候选区域（这里主要是通过相邻区域合并的方式生成的，也就是说此时生成的区域的大小并不是一定的，而后续的模型需要固定大小的输入，故这里再通过一个 CNN 来提取特征转化为固定大小的输入）</li>
<li>扔进 SVM 里做分类（注意这里如果是 N 分类也就存在 N 个 SVM 的分类器）</li>
<li>经过 NMS（非最大抑制，这个机制在 YOLO 里也有，后续介绍，简单来说就是将重合度比较大的框来进行合并）</li>
<li>rescore：通过 box regressor 进行修正</li>
</ul>
</li>
<li>缺点：慢！超慢！本身 SVM 分类的速度就很慢了，本身候选区域较多的时候带来的大量的特征数据还会很占存储，并且本身的优化是比较难做的（这里分为多个模块进行，比如生成候选区域是一个部分，后续的分类又是另外一个部分</li>
</ul>
</li>
</ul>
<p>而 <strong>YOLO 的思路</strong>很简单：<strong>将目标检测问题转化为一个回归问题进行求解</strong>，也就是说将图像作为输入（像素数据），直接输出物体的位置和所属于的类别的置信度（是以一个向量的形式表示的，后续会介绍），属于端到端的模型形式。</p>
<p>这种特点的模型存在几个优势：</p>
<ul>
<li>很快，YOLO 的训练和最后 inference 的速度较前面的几个思路都是快很多的</li>
<li>不同于一般的滑动窗口的方式或事先筛选出候选区域的方式，YOLO 在处理图片的时候是直接输入整张图，也就是说较于上面的两种方式会有更多的上下文信息。也就是说 YOLO 在类似于 background error（也就是错误地将背景上的某一个东西当作目标切下来了） 的问题上会表现更好</li>
<li>更容易学习到物体的泛化表示（也就是在这张图片上训练认识了狗，能够以更好的泛化性能同时认出来别的图片里的不太一样的狗）也就是说作为模型的泛化性能加强了</li>
</ul>
<br>
<br>
<hr>
<h2 id="2-Model-Structure">2. Model Structure</h2>
<br>
<p>YOLO 是通过一个统一的神经网络来直接处理一张图片的，也就是说即使这个图片中存在多个目标，每一个目标还都是多分类问题，都是统一处理的；因此 YOLO 才能有比较好的速度；</p>
<br>
<h3 id="2-1-overview-主要思路">2.1 overview 主要思路</h3>
<ul>
<li>
<p>将<strong>整个图片分为 S*S 的小区域</strong>，这里的 S 自己指定；注意到每一个目标 → 假设都存在一个 true answer 也就是针对这个目标的最好的检测框 → 则每一个目标的检测框的中心点一定是落在某一个小区域内的；如果此时的中心点落在 x 框内，则 x 小区域就负责搞定这个目标；注意此时可能多个目标落在同一个区域<br>
<br/></p>
</li>
<li>
<p>每一个<strong>小区域设定 B 个可能的候选框，并计算每一个可能的候选框的得分</strong> = 置信度，是一个（该候选框和真实的目标检测框的重合程度）和（这个框里确实框住了某一个物体）的综合度量指标，计算方式如下：</p>
<p>$$confidence = Pr(Object) * IOU_{pred}^{truth}$$</p>
<ul>
<li>这里的 IOU 也就是：$$IOU = \frac{truth 的检测框 \cap pred 的检测框}{truth 的检测框 \cup pred 的检测框}$$，也就是真实的框和我预测的框的交并比</li>
<li>同时注意这里为什么要同时考虑两个指标：
<ul>
<li>考虑 IOU：想象此时有一个很大的狗，A 框只框住了狗头，B 框住了狗和一点点背景，此时 A 的Pr 为 0.999 而 B 的 Pr 为 0.998，但是本质上我宁愿选 B（A没全）；也就是说还通过计算 IOU 考虑到一个是否框准了的问题</li>
<li>考虑 Pr：比如狗后面有个树，本身树不是我们的识别目标，如果此时的 pred 的框 A 本身命中的是树，则可能和 狗 的 true answer 的 IOU 也是很高的，但是对应的 Pr 部分会比框住狗的预测框 B 更低，则此时通过 Pr 在前面控制，保证在后续的 NMS 部分会优先留下 B 而不是 A</li>
</ul>
</li>
</ul>
<br/>
</li>
<li>
<p><strong>每一个小区域（共 $S^2$ 个小区域）计算 B 个候选框，共 $S<em>S</em>B$ 个，每一个预测是一个长度为 5 的向量，记作 $(x,y,w,h,conf)$</strong></p>
<ul>
<li>(x, y) 表示当前预测的检测框的中心相对于我的小区域的位置（共 $S^2$ 个小区域），这里的 x 和 y 都是 0-1 之间的，也就是说是相对于当前小区域的左上角的偏移值</li>
<li>(w,h) 表示检测框的宽度和高度，一般是处理到 0-1 之间，标记当前的预测框和整个图片的宽度/高度的比例</li>
<li><code>conf</code> 为上述的置信度，可以看作是当前的框的可信度的综合指标，由（是否框准了 = 是否和真实的预测框有较好的重合）和（是否框里确实框住了物体）两个部分影响</li>
</ul>
<br/>
</li>
<li>
<p><strong>同时计算每一个小区域（注意是小区域，一开始 S*S 的那个，不是预测框）对应为第 i 个类别的概率，记作 $Pr(Class_i|Object)$；也就是说这里作者前提假设了同一个小区域内只有同一种物体的中心落在里面</strong></p>
<ul>
<li>在测试的时候，则该区域内的所有的 B 个预测框都对应乘上这个 Pr 值得到：<br>
$$confidence = Pr(Class_i|Object) * Pr(Object) * IOU_{pred}^{truth} = Pr(Class_i) * IOU_{pred}^{truth}$$，也就是说每一个小区域内对应的 B 个预测框的分类的 i 对应的条件概率（以确实框到了东西为条件）是一样的</li>
<li>上面计算得到的 conf 也就是每一个预测框框住的是分类 i 的物体的一个综合置信度得分</li>
</ul>
</li>
</ul>
<br>
<p><strong>举个例子：</strong></p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023120058589.png" alt="image-20231023120058589" style="zoom:67%;" />
<p>这里的 S 是 7，也就是将整个图片分为 49 个小区域，对应的每一个小区域设定考虑 B 个不同的候选框（注意这里设定的 B 的主要目的是保证如果多个目标的中心都在同一个小区域内也可以抓得比较全）→ 计算共 S*S*B 个框的预测信息，每一个预测框都对应一个五维的向量作为预测值，包括：</p>
<ul>
<li>1）预测框的中心对应当前的小区域的相对位置；</li>
<li>2）预测框的大小相对于整个图片的相对比值；</li>
<li>3）置信得分 = P(确实框到东西了) * IOU → 同时对于一个 C 分类问题，则每一个小区域都有一个长度为 C 的向量，表示该小区域对应的预测框是 i 分类的概率</li>
</ul>
<p>综上，此时整个模型的输出应该是大小为 S*S*(B*5 + C) 大小的一个向量</p>
<br>
<h3 id="2-2-Network-Design-网络设计">2.2 Network Design 网络设计</h3>
<p>整体的网络设计依赖卷积神经网络的思路，也就是一大串卷积（共 24 层）后面跟着全连接层（两层全连接）输出需要的预测的向量，也就是传统的（卷积先提取特征）再（扔进全连接层进行预测）的思路</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023120131783.png" alt="image-20231023120131783" style="zoom:60%;" />
<p>举例还是上面的 S = 7 的情况，设原图大小为 448*448*3（三通道 RGB 表示色彩）；假设这里的 B = 2，C = 20，一开始冲上来扫的卷积大小为 7 ；则对应的最后的输出应该是 7*7*(2*5 + 20), 本身是三维的，最后一个为 30（最后一维输出的大小 = B*5 + C）</p>
<br>
<br>
<hr>
<h2 id="3-Training-训练和损失函数">3 Training 训练和损失函数</h2>
<br>
<h3 id="3-1-预训练">3.1 预训练</h3>
<p>首先进行预训练，在 ImageNet 1000-class competition dataset 上面进行，将前面的 20 层卷积拿出来，后面跟上一个平均方法的池化层 + 一个全连接层，来进行预训练（原论文表示大概训了一周）</p>
<p>后续 fine tune 的时候最后的四层卷积和两个全连接层都是随机初始化权重的，也就是说这里的预训练知识针对最前面的 20 层卷积</p>
<p>注意这里最后输出的五维向量中，对应的 x,y 和 w,h 都是 0-1 之间的值（标准化过的结果）；</p>
<br>
<br>
<h3 id="3-2-损失函数">3.2 损失函数</h3>
<p>至于<strong>损失函数部分，这里利用平方误差和（sum-squared error）来衡量</strong>（因为比较方便优化），先把这个巨大无敌的损失函数摆过来：<br>
$$<br>
\begin{align}<br>
&amp; \lambda _{coord} \sum _{i=1} ^{S^2} \sum _{j=1} ^B \mathbb{1} _{ij} ^{obj} [(x_i - \hat{x} _i) ^2 + (y_i - \hat{y} _i)^2] \\<br>
+&amp; \lambda _{coord} \sum _{i =0} ^{S^2} \sum _{j=0} ^B \mathbb {1} _{ij} ^{obj} [(\sqrt{w_i} -\sqrt{\hat{w}_i}) ^2 + (\sqrt{h_i} -\sqrt{\hat{h}_i}) ^2] \\<br>
+&amp; \sum _{i =0} ^{S^2} \sum _{j=0} ^B \mathbb {1} _{ij} ^{obj} (C_i - \hat{C}_i)^2 \\<br>
+&amp; \lambda _{noobj} \sum _{i =0} ^{S^2} \sum _{j=0} ^B \mathbb {1} _{ij} ^{noobj} (C_i - \hat{C}_i)^2 \\<br>
+&amp; \sum _{i=0} ^{S^2} \mathbb {1} _{ij} ^{noobj} \sum _{c\in \text{classes}} (p_i(c) - \hat{p}_i(c))^2<br>
\end{align}<br>
$$</p>
<p>这里的 $1_{i}^{obj}$ 标记对于第 i 个小区域（共 S*S 个小区域）内是否出现了某一个目标的中心点；而 $1_{ij}^{obj}$ 标记第 i 个小区域内的第 j 个预测框（共 B 个 预测框)是否框住了某一个目标</p>
<br>
<h4 id="3-2-1-几个细节问题：">3.2.1 几个细节问题：</h4>
<ul>
<li>
<p><strong>Q1</strong>：我们的目标是想要使得平均精度最佳，也就是既要分类分得准，同时预测框的标记也需要准，但是如果直接用最后输出的五维向量来处理，此时对于（预测框的标记是否准确  = localization error）和（分类是否准确 = classification error）是同等重要来衡量的，不太对（）</p>
<ul>
<li><strong>A1</strong>：引入超参数 $\lambda_{coord}$ 控制（预测框的标记是否准）和（分类的结果是否对）两个部分在损失函数中对应的权重，设置 &gt; 1</li>
</ul>
<br/>
</li>
<li>
<p><strong>Q2</strong>：同时注意到大部分的小区域都是不含有我想要检测的目标的，也就是说真实的 conf 应该为 0，这部分的区域过多，可能会导致那些含有目标的小区域对于损失函数的影响被吞掉（也就是说如果模型学会对所有的 conf 都预测为 0，则只是损失了几个少数的含有目标的小区域，但大部分的区域都是超准的；这种情况显然会导致模型跑走）</p>
<ul>
<li><strong>A2</strong>：引入超参数 $\lambda_{noobj}$ 控制不含有检测目标的框在损失函数中的贡献，设置 &lt; 1</li>
</ul>
<br/>
</li>
<li>
<p><strong>Q3</strong>：在衡量我的预测框和真实的框之间的误差的时候（针对框的大小，也就是 w 和 h 两个参数），注意到如果我本身框大小为 10 相差1，和本身框大小为 1 但相差 1 完全是两个不同的概念（后者会更加严重）；也就是说对于相同的真实值与预测值之间的差值，如果对应的框越小，则对于损失函数的影响应该越大</p>
<ul>
<li>
<p><strong>A3</strong>：不用 真实值 - 预测值 来衡量，而是用 √真实值 - √预测值，（注意这里的方法解决这个问题的效果是很有限的 ...）具体原理见下：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023121054167.png" alt="image-20231023121054167" style="zoom:45%;" />
<p>注意这里的 x 轴为原值，y 轴为根号后的值，原来的 x 越小的时候，等距离的 x1 和 x2 对应的 y 轴的值 $\sqrt{x_1}$ 和 $\sqrt{x_2}$ 之间的差距会越大（也就是 x 每次都稳步增加，对应的 y 会增长飞快），也就对于损失函数的影响越大</p>
</li>
</ul>
</li>
</ul>
<br>
<h4 id="3-2-2-解释损失函数">3.2.2 解释损失函数</h4>
<p>现在再回头来重新解释一下损失函数（再摆一遍<br>
$$<br>
\begin{align}<br>
&amp; \lambda _{coord} \sum _{i=1} ^{S^2} \sum _{j=1} ^B \mathbb{1} _{ij} ^{obj} [(x_i - \hat{x} _i) ^2 + (y_i - \hat{y} _i)^2] \\<br>
+&amp; \lambda _{coord} \sum _{i =0} ^{S^2} \sum _{j=0} ^B \mathbb {1} _{ij} ^{obj} [(\sqrt{w_i} -\sqrt{\hat{w}_i}) ^2 + (\sqrt{h_i} -\sqrt{\hat{h}_i}) ^2] \\<br>
+&amp; \sum _{i =0} ^{S^2} \sum _{j=0} ^B \mathbb {1} _{ij} ^{obj} (C_i - \hat{C}_i)^2 \\<br>
+&amp; \lambda _{noobj} \sum _{i =0} ^{S^2} \sum _{j=0} ^B \mathbb {1} _{ij} ^{noobj} (C_i - \hat{C}_i)^2 \\<br>
+&amp; \sum _{i=0} ^{S^2} \mathbb {1} _{ij} ^{noobj} \sum _{c\in \text{classes}} (p_i(c) - \hat{p}_i(c))^2<br>
\end{align}<br>
$$<br>
一行一行来：</p>
<ul>
<li>① 控制中心点 x 和 y 的预测，注意这里的 x 和 y 都是中心化到 0-1 之间的，不做上面的 Q3 的处理；注意如果示性函数 1 对应的为 0 ，也就是说当前的预测框里就没有物体，则对损失函数不影响；注意前面有 λcoord 存在，控制此时 localization error 的惩罚的权重；</li>
<li>② 同理，控制框的大小的预测，这里按 Q3 的解释做开根处理后再相减，同理注意如果当前预测框内没有物体，则全部置为 0；同理存在 λcoord；</li>
<li>③ 存在目标的预测框的 C 值（置信度）的误差惩罚；</li>
<li>④ 不存在目标的预测框的 C 值（置信度）的误差惩罚，注意前面带有 λ noobj，这个超参数加入主要是因为进入 ④ 的框比进入 ③ 的框要多得多，对于单个的框来说没有哪个更重要的说法；</li>
<li>⑤ 对于分类准确性的惩罚，注意这里是基于小区域（S*S 个）进行的，不是针对每一个预测框（否则三连乘会超多）；只集中于存在目标的小区域；</li>
</ul>
<p>同时注意，假设一个小区域内同时存在目标 ABC，对应它有预测框 abc，可能一开始 a 预测框就是离 A 目标最近（也就是 IOU 最大），则后续梯度下降的时候，它比起去贴本来离得远的 B 目标，a 预测框会越来越贴近 A 目标；也就是说随着训练的进行会出现某一个预测框就针对某一个目标开始优化的情况，算是一定程度上的专门性</p>
<br>
<h3 id="3-3-训练参数设置">3.3 训练参数设置</h3>
<p>几个原论文给出的炼丹参考：</p>
<p><strong>学习率处理：</strong></p>
<ul>
<li>第一个 epoch 先从 $10^{-3}$ 逐渐上升到 $10^{-2}$，注意不是一开始用大学习率，会很容易一把子发散</li>
<li>原论文保持 $10^{-2}$ 又训了 75 epoch，再 $10^{-3}$ 30 epoch，再 $10^{-4}$ 30 epoch</li>
<li>※ 原论文手动调了学习率可能还是有一定影响的，可能后续炼丹的时候也可以试试不要直接交给 decay 而是手动一下</li>
</ul>
<p><strong>缓解过拟合</strong></p>
<p>这里为了缓解过拟合用了 dropout，参数打 0.5</p>
<p>同时可以配合数据增强的方法，原论文用了  random scaling and translations （大概到 20% 的原图大小）</p>
<br>
<br>
<hr>
<h2 id="4-Inference-推理">4 Inference 推理</h2>
<br>
<h3 id="4-1-模型推理">4.1 模型推理</h3>
<p>和训练的部分同理，推理的时候也只需要走一次模型。具体会给出 S*S*B 每一个框的对应的置信度 conf，同时通过 (x,y,w,h) 标记好框的位置</p>
<p>注意到会一并计算每一个小区域的对应的各个类别的概率（同上所述，注意这里作者假设了每一个小区域负责检测到的目标 = 中心点落在该小区域内的目标都是属于同一个类别的；则也可以得到对应的每一个预测框的预测的类别</p>
<p>最后输出的时候可以通过控制阈值的方法输出（后续在源码部分详细说说），比如最简单的就是控制置信度，大于 xx 的预测框才能够输出</p>
<br>
<h3 id="4-2-NMS-方法（Non-Maximal-Suppression-非极大值抑制）">4.2 NMS 方法（Non-Maximal Suppression / 非极大值抑制）</h3>
<p>※原文表示是可以用这个，但是感觉为了好点的效果是必要组成部分（？）</p>
<p>考虑有些很大的物品 / 或者这个目标的中心值刚好在边界上，则可能会导致多个小区域都给出了比较好的预测框，也就是说对于同一个目标，会出现几个较好的预测框。此时需要从它们中选择一个，否则会出现冗余</p>
<p>这里使用 NMS 方法 = Non-Maximal Suppression / 非极大值抑制，将多余的 / 冗余的预测框去掉。本身这个方法从 R-CNN 开始就已经用起来了（不如说对于滑动窗的方法反而是最容易出现这样的重复的冗余预测框的），简单来说步骤如下：</p>
<ul>
<li>将可能在定位同一个目标的所有候选框搞出来 → 设定为备选框</li>
<li>按照置信度从大大小排序备选框</li>
<li>取置信度最大的框作为基准，计算和其他余下的框的 IOU，对应大于某一个阈值的其他框都全部扔掉</li>
<li>重复步骤直到筛选结束</li>
</ul>
<p>也就是说 NMS 本身是一个局部最大的搜索方法。注意在实现的时候是必须一张图一张图来进行的，也就是说会出现在当前 batch 内遍历每一张图再一个一个来 NMS 的情况（源码里再说）</p>
<p>对于 YOLO 来说，一般是先根据置信度扔掉大部分的框（也就是设定阈值，conf &lt; 阈值的预测框直接 pass），再进行 NMS 进行进一步的缩减。注意这里 NMS 的候选框也就是所有被留下的预测框，这里的 IOU 的计算量是 $n^2$ 级别的，所以一开始先根据置信度把大部分扔掉。</p>
<br>
<br>
<hr>
<h2 id="5-summary">5 summary</h2>
<br>
<h3 id="5-1-YOLO-步骤总结">5.1 YOLO 步骤总结</h3>
<p>细节的东西比较多，以下来整体梳理一下 YOLO 的思路：</p>
<ul>
<li>固定图像输入大小，这里假设为 448*448*3；设定存在 C = 20 种不同类别的目标</li>
<li>将整张图片分为 S*S 的小区域（grid cell），假设 S = 7</li>
<li>每一个小区域设定搜索 B 个预测框（bounding box），假设 B = 2
<ul>
<li>每一个预测框给出一个五维向量 $(x,y,w,h,conf)$ 作为预测输出
<ul>
<li>xy 表示预测框中心点相对于当前的小区域（grid cell）的位置</li>
<li>wh 表示预测框的宽高相对于整张图片大小的比例</li>
<li>conf 为该搜索框的置信度，由 Pr(是否包含 obj) * IOU(预测框和真实框的交并比)计算
<ul>
<li>多啰嗦一句 ... 一个预测框的置信度是通过模型输出的，通过全连接层劈里啪啦一顿操作预测出一个值；而我的 ground truth = 该预测框的真实的置信度 → 是通过上面的式子计算的，此时真实的 bonding box 的坐标都有，则中心位置可以计算 → 若中心位置在这个小区域内，则 Pr(是否包含 obj) = 1；得到 ground truth 后就是训练模型劈里啪啦出来的那个值不断接近我计算的真实值；</li>
</ul>
</li>
</ul>
</li>
<li>所以这里最后的输出大小为 S*S*(B*5 + C) = 7*7*30 ，注意是三维的</li>
</ul>
</li>
<li>每一个小区域（grid cell）都给定 C 个可能的概率，表示该小区域内的预测框对应的目标为第 c 类目标的概率；注意这里假设了中心落在同一个小区域内的目标都是同类别的。</li>
<li>训练 training →
<ul>
<li>通过上面的那个巨大无敌的损失函数，包括 localization error（也就是对目标框的 xywh 的惩罚）+ 对每一个预测框的 C 置信度的惩罚 + 对当前小区域的 classification error 分类</li>
</ul>
</li>
<li>推理 inference →
<ul>
<li>计算得到 S*S*B 个候选框的位置大小 + 置信度（直接通过模型吐出来的，含义 = Pr*IOU），先设定置信度阈值将特别小的框扔掉，再通过 NMS 去掉冗余，对应框住的东西的分类 = 该框所在的小区域（grid cell）对应的各类概率最大的那个分类，也就是说每一个小区域内的框都是同一类的东西；</li>
</ul>
</li>
</ul>
<br>
<h3 id="5-2-YOLO-的优缺点">5.2 YOLO 的优缺点</h3>
<p><strong>优点</strong>：</p>
<ul>
<li><strong>快，YOLO 的检测速度比往常的模型快很多</strong>，这也是 YOLO 最大的优点之一，使得它在实时监测上基本能把别的模型按着打（比如输入是实时的视频流）。实验表示即使是精简版的 YOLO fast 在 FPS155 的速度下也能达到不错的精度；</li>
<li><strong>更少出现背景误检的问题，也就是更低的 background error</strong>；也就是说 YOLO 更少将啥也没有的背景误检测出来作为目标。前面也提到，因为 YOLO 的输入是整张图直接扔进去，也就是说会有更多的上下文信息，故相较于其他模型不容易从局部上将背景作误判；</li>
<li>**泛化能力比往常的模型要好。**原文用的是Picasso Dataset 和 People-Art Dataset 来作（艺术作品种的人的检测）的实验，YOLO 的效果会好很多，展现出一定的泛化能力。</li>
</ul>
<p><strong>缺点</strong> ：</p>
<ul>
<li>假设强，此时假设了每一个小区域内的目标不超过 B 个（原文 B = 2），同时假设了中心点落在同一个小区域内的所有目标都是同一类的物体
<ul>
<li>也就是说如果出现<strong>很多的目标密集挤在一起，此时 YOLO 的效果不一定会很好</strong>（会识别不全）算是 YOLO 不擅长的一个场景；</li>
</ul>
</li>
<li><strong>泛化能力还是有限，主要对于长宽比不太一样的情况会表现不佳</strong> → 比如2：1的瘦狗看多了会认不出1：1的胖狗；原作者将原因归结于提取的用于预测的特征还是比较粗糙，因为本身存在对原图像多次下采样的结构；</li>
<li>损失函数部分<strong>不同大小的框对于损失函数的贡献的区分不明显</strong>。相同的差值，大小不同的框对于损失函数的贡献应当是不同的 → 也就是前面提到了在 localization error 的部分（针对 w 和 h），如果是一个大小为 10 的框预测误差为 1 还好，但是大小为 1 的框预测误差为 1 要出事，上述操作是开根号后再进行差值计算，但是实验表示这样的处理效果还是有限。</li>
</ul>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>CV</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>YOLO</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>模式匹配：从 BF 到 KMP（图解 + 代码）</title>
    <url>/2023/10/30/20221125-summary-patternmatchKMP/</url>
    <content><![CDATA[<p>原文写于 20221125，存档如下</p>
<blockquote>
<p>KMP 真的一看就懂一做就错三天全忘 好像青年痴呆</p>
<p>遂烂笔头之</p>
</blockquote>
<span id="more"></span>
<br>
<br>
<hr>
<h2 id="1-模式匹配">1. 模式匹配</h2>
<p>这里考察的是模式匹配问题</p>
<p>也就是我给定一个字符串 s，和一个子串 t，我想要找到 s 的一个子串 = t，也就是（在 s 中找到 t 进行匹配的任务）</p>
<p>此时将 s 称为目标串，子串 t 称为模式串</p>
<p>以下主要考虑两种方法：</p>
<ul>
<li>朴素模式匹配，也就是暴力法，BF 算法</li>
<li>大名鼎鼎 KMP</li>
</ul>
<p>看完可以在这里练手：</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9zaG9ydGVzdC1wYWxpbmRyb21lLw==">214. 最短回文串<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9sb25nZXN0LWhhcHB5LXByZWZpeC8=">1392. 最长快乐前缀<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9maW5kLXRoZS1pbmRleC1vZi10aGUtZmlyc3Qtb2NjdXJyZW5jZS1pbi1hLXN0cmluZy8=">28. 找出字符串中第一个匹配项的下标<i class="fa fa-external-link-alt"></i></span></p>
<br>
<br>
<hr>
<h2 id="2-Brute-Force-算法">2.Brute-Force 算法</h2>
<p>也就是暴力 = BF 方法</p>
<h3 id="2-1-思路">2.1 思路</h3>
<p>考虑 s 目标串从第 i 个位置开始和 模式串 t 可以匹配上，则我枚举这里的起点 i：</p>
<ul>
<li>从第一个位置 s[0] 开始，检查 s[0] == t[0]? s[1] == t[1]? ... 直到匹配结束或者出现不匹配为止</li>
<li>从第二个为止 s[1] 开始，和 t 从头匹配，也就是 s[1] == t[0] ?   s[2] == t[1]? ...</li>
<li>循环到匹配上为止；或者当前的位置 i 后面已经没 t 这么长的剩余了，则返回 -1 表示 s 中不存在 t</li>
</ul>
<p>一般使用的时候用双指针，i 表示当前匹配到 s 的第 i 位；j 表示匹配到 t 的第 j 位；当 s[i] ≠ t[j] 的时候说明匹配失败，j 回到 0，i 回到上一轮匹配开头位置的下一个</p>
<br>
<h3 id="2-2-代码示例">2.2 代码示例</h3>
<p>提供一个 python 代码，基于 <span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9maW5kLXRoZS1pbmRleC1vZi10aGUtZmlyc3Qtb2NjdXJyZW5jZS1pbi1hLXN0cmluZy8=">28. 找出字符串中第一个匹配项的下标<i class="fa fa-external-link-alt"></i></span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">strStr</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    	<span class="comment"># 这里的 s 是主串 = 目标串，t 为子串 = 模式串</span></span><br><span class="line">        <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)-<span class="built_in">len</span>(t)+<span class="number">1</span>):</span><br><span class="line">            <span class="comment"># start 表示从 s 的 start 位置开始匹配 t</span></span><br><span class="line">            i,j = start,<span class="number">0</span> <span class="comment"># 双指针，指示当前匹配到 s 和 t 的哪一个位置了</span></span><br><span class="line">            <span class="keyword">while</span> s[i] == t[j]:</span><br><span class="line">                i += <span class="number">1</span>; j += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> j == <span class="built_in">len</span>(t): <span class="keyword">return</span> start  <span class="comment"># 匹配成功</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这里的 s 的长度为 m，t 的长度为 n，最坏的情况我每一轮匹配都是到最后才发现匹配不上（则每一轮匹配复杂度为 O(n)），同时真的匹配上要到 s 的最末尾（进行 O(m) 次匹配）</p>
<p>则此时的算法复杂度 = O(mn)</p>
<br>
<br>
<hr>
<h2 id="3-KMP-算法">3. KMP 算法</h2>
<p>考虑传统暴力方法：也就是我这一轮匹配从 s 的 start 位置开始，如果匹配失败了，我就从 s 的 start + 1 位置开始尝试下一次；</p>
<p>所以说这里的复杂度会是 mn，最坏的情况我要把 （s 的每一个字符）都当作和 t 的一轮匹配的开头来尝试一次，会很麻烦</p>
<p>KMP 的思路即：我如果以 start 为开头，匹配到了 start + k 才发现 start + k + 1 匹配不上了，但是我这轮已知了 s 的 start → start + k 和 t 的前 k + 1 个字符是一样的，则我想要利用这个信息快速筛选掉一些我已知不可能的 s 的 start，也就是不再需要将 s 的每一个字符都作为可能的开头来尝试一次了</p>
<h3 id="3-1-整体思路">3.1 整体思路</h3>
<p>假设此时我对下面的 s 和 t 进行匹配；一开始以 s 的第一个元素作为匹配的开头进行匹配：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122110562.png" alt="image-20231023122110562" style="zoom:30%;" />
<p>匹匹匹匹到 a vs c 的时候发现不匹配了，如果是 BF 方法，则此时下一个 start 设置为 s 的第二个字符（也就是 b)，t 回到开头，重新开始尝试匹配</p>
<p>但是本轮匹配的时候，我已经发现了 t 的前四个和 s 的前四个是一样的，则我考虑能不能跳过一部分的开头</p>
<p>假设我还是以 s 的第二个元素为新的 start，t 也回到开头，重新开始匹配</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122201463.png" alt="image-20231023122201463" style="zoom:50%;" />
<p>匹配顺序如图，但是注意 s 的绿色部分和 t 的绿色部分是相等的，s 的绿色的部分的信息我已知；则这里的第二轮匹配的前几个检查，其实也就是在检查下图的蓝色部分是否是一模一样的：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122240961.png" alt="image-20231023122240961" style="zoom:45%;" />
<p>而这里的黑框的部分，也就是 t 的绿色部分的前三个元素 和 后三个元素，这一轮的匹配要是能成功，就要求 t 的绿色部分的 （前三个元素 = 后三个元素）</p>
<p>当然是不行的（。我不用看 s 只用看 t 就知道，这三个元素不相等，则以 s 的下标 1 的元素（=b） 作为 start 来进行匹配肯定不行，这个 start 尝试都不用尝试；</p>
<p>则此时尝试按照 BF ，再把 t 后移一位</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122311871.png" alt="image-20231023122311871" style="zoom:45%;" />
<p>同理，这里如果要匹配成功，则 t 的绿色部分的（前两个字符）和 t 的绿色部分的（后两个字符）需要一样；注意到这里还真的是一样的，说明以 s 的下标为 2 的字符（=a)作为 start 来匹配可能有戏</p>
<p>综上，我考虑：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122346802.png" alt="image-20231023122346802" style="zoom:60%;" />
<ul>
<li>我在第 x 轮匹配中，t 和 s 的 start 位置对齐，检查到 k 位置的时候发现 t 和 s 匹配不上，这轮匹配失败</li>
<li>但是我通过这轮匹配知道了 s 的（ start → start + k-1） 和 t 的（0 → k-1）是一样的，这里的匹配上了的长度为 k 的区域就是上面的绿色部分</li>
<li>下一轮，如果我将 t 后移 x 个，则这轮匹配可行需要（t 的绿色部分的倒数 k-x 个 = 蓝色黑框部分）和（t 的绿色部分的开头 k-x 个 = 蓝色黑框部分）相同才行</li>
</ul>
<p>综上，我从 start 开始对齐匹配失败了，则 start = start + 1 开始新的一轮匹配要成功，则需要绿色部分的倒数 k-1 个 = 开头的 k-1 个才行；同理，从 start = start + 1 开始新的一轮匹配要成功，则需要绿色部分的倒数 k-2 个 = 开头的 k-2 个才行 ...</p>
<p>那我只要知道最大的一个 k0，使得（t 的前 k 个元素 = 绿色部分）的（倒数 k0 个）=（开头 k0 个） 就行了？因为这里的 k0 是最大的，则 k-1 → k-2 → ... → k-k0+1 的这些检查一定不成功，也就是说 start + 1 / + 2 / + ... / + k0-1 这些新的 start 都一定不会成功，只要跳过就行；</p>
<p>为了实现上面的判断，我对于任意的一个 k（任意长度的绿色部分）都要知道对应的最大的 k0，使得这个绿色部分的倒数 k0 个 = 开头 k0 个，我用一个数组 next[i] 来进行记录；同时注意这里的 k0 当然不能 = k，否则自己等于自己没有意义；即：</p>
<p>$$next[i] = max {k_0| t[i-k_0: i] == t[:k_0], k_0 &lt; k}$$</p>
<p>注意这里的绿色部分是不包括 t 的第 k 个元素的</p>
<p>综上，得到 next[i] 后，我的匹配算法可以精简为：</p>
<ul>
<li>t 和 s 的 start 位置对齐，进行匹配；到 t[k] 的时候发现匹配不成功</li>
<li>start += k-next[k];</li>
<li>主串 s 的指针：i  = max(start, i)
<ul>
<li>其实这里的 i 是可以不动的，只是要处理一下被 start 超过的情况</li>
</ul>
</li>
<li>模式串 t 的指针：j = max(next[k], 0)
<ul>
<li>只是处理一下 k = 0，一个都没匹配上的情况，此时 next[0] = -1</li>
</ul>
</li>
<li>继续尝试匹配</li>
</ul>
<br>
<h3 id="3-2-计算-next-i">3.2 计算 next[i]</h3>
<p>那么现在问题就是怎么得到 next[i]</p>
<p>注意到 next[i] 和 s 是无关的，它是针对 t 做的预处理</p>
<h4 id="3-2-1-基本思路">3.2.1 基本思路</h4>
<p>再搬下来一遍 $$next[i] = max {k_0| t[i-k_0+1: i+1] == t[:k_0+1], k_0 &lt; k}$$</p>
<p>规定 next[0] = -1，k = 0 的时候绿色部分为 0啥也没有 ；同理 next[1] = 0，这里的绿色部分只有一个字符，如果和自己相等了就是全匹配了，自己等于自己没意义；设置为 0</p>
<p>考虑如果我已知了 next[i]，想要知道 next[i+1]</p>
<p>则分成两种情况：</p>
<ul>
<li>情况一：t[i] == t[next[i-1]]  也就是说相较于 i-1，此时新加入的元素刚好可以顺着往下匹配，则这里的 next[i] = next[i-1] + 1</li>
</ul>
<p>比如这里的 next[3] 考察的是黄色部分，此时倒数的一个（a) 和开头的一个（a）是相等的，我已知 next[3] = 1，则 next[4]?</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122432117.png" alt="image-20231023122432117" style="zoom:45%;" />
<p>注意到对于 next[4]，t[3] 加入黄色部分，而 t[3] 和上一个 next[3] 匹配后的下一个位置接着匹配（也就是深色的两个 b），则此时 next[4] = next[3] + 1 = 2</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122527022.png" alt="image-20231023122527022" style="zoom:50%;" />
<ul>
<li>情况二：此时两个深色位置不相等，也就是 t[i] != t[next[i-1]]</li>
</ul>
<p>直观理解就是这里的新的 next[i+1] 不能再顺着 next[i] 匹配的成果下去了，比如下图：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122609376.png" alt="image-20231023122609376" style="zoom:45%;" />
<p>这里的蓝色部分是 next[9] 匹配好的，但是对于 next[10] 来说因为 a！= c 无法接下去了；</p>
<p>则我这里的目标找到哪里可以继续匹配我 t[9] 位置的这个 a，且匹配上的位置尽量靠后（则可以保证 k0 尽量长），那也就是 t[9] 这个 a 前面的 abab 尽量也匹配上，则此时问题转移为蓝色的部分的倒数 k1 个能否和 t 开头的 k1 个匹配上，注意到了嘛，这个 t0 就存在 next[4] = next[next[i]]，也就是关注蓝色部分的匹配情况的那个 next 存储着这里我要的 k1</p>
<p>则我一开始是在 next[9] 的基础上继续算 next[10]，发现匹配不上，则我下一个就在 next[4] 的基础上继续匹配，也就是下图：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122643608.png" alt="image-20231023122643608" style="zoom:50%;" />
<p>这下匹配上了！则 next[10] 也就是 next[4] + 1</p>
<p>当然也会有很刁钻的情况，就是匹配不上，比如：</p>
<img src="https://cdn.jsdelivr.net/gh/baijn-nan/blog-image-hosting-2023@main/paper-note/image-20231023122803363.png" alt="image-20231023122803363" style="zoom:45%;" />
<p>这个 z 哪里都没有啊，则我还是不断考虑蓝色部分的最大的 k1，也就是 next[next[4]] = next[2]，此时变成 0</p>
<p>则此时变成 t[9] 和 开头 t[0] 匹配，还是不行，直接返回 0</p>
<br>
<h4 id="3-2-2-整理">3.2.2. 整理</h4>
<p>综上，计算 next[i] 按照下述步骤：</p>
<ul>
<li>初始化，next[0] = 0,  next[1] = 1</li>
<li>对于 next[i+1]
<ul>
<li>prek0 = next[i-1]  标记上面蓝色部分的末尾</li>
<li>先看 next[i] == t[prek0]</li>
<li>如果成立，则 next[i] = prek0 + 1</li>
<li>如果不成立，prek0 = next[prek0]，继续检查</li>
<li>直到这里的 prek0 = 0，但是还是 next[i] != t[0]，则 next[i] = 1</li>
</ul>
</li>
</ul>
<p>一个基础的 python 代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nxt = [<span class="number">0</span>]*(<span class="built_in">len</span>(t)+<span class="number">1</span>)  <span class="comment"># 这里多计算一位，在某些任务有用（比如 lc 214）</span></span><br><span class="line">nxt[<span class="number">0</span>], nxt[<span class="number">1</span>] = -<span class="number">1</span>, <span class="number">0</span></span><br><span class="line">i = <span class="number">2</span></span><br><span class="line">prek0 = nxt[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">while</span> i &lt; <span class="built_in">len</span>(t)+<span class="number">1</span>:</span><br><span class="line">    <span class="keyword">if</span> t[prek0] == t[i-<span class="number">1</span>]:    nxt[i] = prek0 + <span class="number">1</span>; prek0 += <span class="number">1</span>; i += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 表示跟着 next[i-1] 匹配上了</span></span><br><span class="line">    <span class="keyword">elif</span> prek0 &lt;= <span class="number">0</span>:    nxt[i] = <span class="number">0</span>; prek0 = <span class="number">0</span>; i+=<span class="number">1</span></span><br><span class="line">        <span class="comment"># 表示 prek0 已经为 0 了但是还是匹配不上；则 nxt 为 0，下一个</span></span><br><span class="line">    <span class="keyword">else</span>:   prek0 = nxt[prek0]</span><br><span class="line">        <span class="comment"># 表示当前的 i 还有救，不断缩短蓝色部分尝试匹配它</span></span><br></pre></td></tr></table></figure>
<br>
<h3 id="3-3-整体代码">3.3 整体代码</h3>
<p>综上，此时匹配的思路为：</p>
<ul>
<li>先预处理得到 next</li>
<li>开始匹配，第一轮 start = 0，将 t 和 s 的 start 位置对齐尝试匹配
<ul>
<li>匹配成功，返回 start 就是匹配成功的起始位置</li>
<li>匹配到 t[k] 的时候失败，
<ul>
<li>则取出 next[k]，这里的 start = start + k-next[k]</li>
<li>主串 s 的指针：i  = max(start, i)</li>
<li>模式串 t 的指针：j = max(next[k], 0)</li>
</ul>
</li>
</ul>
</li>
<li>如果当前从 s 的 start 位置开始剩下的部分不足 len(t)，匹配失败，此时 s 中不存在 t 子串</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">strStr</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 预处理 计算 next</span></span><br><span class="line">        nxt = [<span class="number">0</span>] * (<span class="built_in">len</span>(t) + <span class="number">1</span>)</span><br><span class="line">        nxt[<span class="number">0</span>], nxt[<span class="number">1</span>] = -<span class="number">1</span>, <span class="number">0</span></span><br><span class="line">        i = <span class="number">2</span>; prek0 = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(t)+<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> t[i-<span class="number">1</span>] == t[prek0]:  nxt[i] = prek0 + <span class="number">1</span>; prek0 += <span class="number">1</span>; i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> prek0 == <span class="number">0</span>:    nxt[i] = <span class="number">0</span>; i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:   prek0 = nxt[prek0]</span><br><span class="line">        <span class="comment"># 进行匹配</span></span><br><span class="line">        start = <span class="number">0</span></span><br><span class="line">        i,j = <span class="number">0</span>,<span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> start + <span class="built_in">len</span>(t) &lt;= <span class="built_in">len</span>(s):</span><br><span class="line">            <span class="keyword">while</span> s[i] == t[j]: </span><br><span class="line">                i+=<span class="number">1</span>; j+=<span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> j == <span class="built_in">len</span>(t): <span class="keyword">return</span> start  <span class="comment"># 匹配成功，返回起始位置</span></span><br><span class="line">            k = j </span><br><span class="line">            start += k - nxt[k]</span><br><span class="line">            i = <span class="built_in">max</span>(i, start)  <span class="comment"># 注意处理一个都匹配不上，start 直接 + 1 超过了 i 的情况</span></span><br><span class="line">            j = <span class="built_in">max</span>(nxt[k], <span class="number">0</span>)  <span class="comment"># 小心 k = 0 的情况</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>  <span class="comment"># 匹配失败</span></span><br></pre></td></tr></table></figure>
<br>
<br>
<br>
]]></content>
      <categories>
        <category>基础整理</category>
        <category>算法基础</category>
      </categories>
      <tags>
        <tag>算法基础</tag>
        <tag>模式匹配</tag>
      </tags>
  </entry>
  <entry>
    <title>adb 调试清理安卓系统预装 (附三星禁用list - OneUI5.1 + 安卓13)</title>
    <url>/2023/10/30/20231019-casual-adbuninstall/</url>
    <content><![CDATA[<blockquote>
<p>找工焦虑，转移注意力嚯嚯！</p>
</blockquote>
<p>年初三桑更新多了预装游戏助推器，会跟着所有 google play 注册的游戏自启动，本来不太在意的但 pjsk 三周年更新后老是打歌途中反复跳通知 ... 断了第二次 fc 后痛定思痛，今天白刀子必须见血（舔</p>
<p>target：以 (相对) 安全 / 不root留保修/ 可恢复 的方式清理不需要的预装app</p>
<p>系统：三星s21国行 / OneUI5.1 / 安卓 13 + win10</p>
<span id="more"></span>
<br/>
<br/>
<hr>
<h2 id="step-0：确认工具">step 0：确认工具</h2>
<p>其实三桑预装算是比较多的，但到手几个月就出国了加之 nhv 烂村子没地方修，一直没敢直接上手杀，日常使用也还是以 sd 女仆小修小补为主，即使这次起意要做还是希望回国前以相对保守的方式处理；</p>
<p>个人考虑 adb 特点如下：</p>
<ul>
<li>方便，免 root，像我这种手滑砸来砸去的未来还能去店里换个屏；</li>
<li>说是 uninstall 但本质不是全卸载，所有命令都是在 user 层面进行的，也就是说恢复比较方便（保守；希望株连九族的朋友可能不合适这个）</li>
<li>简单干净不需要装别的东西，还是不要那种装大流氓管小流氓把，我感觉好像被 ntr ... 且三桑 Bixby 老是和三方软件冲突（比如和酷安老哥最喜欢的冰箱）装机的前两周有吃够苦头；</li>
</ul>
<p>个人设备系统：</p>
<ul>
<li>三星 galaxy s21 国行，SM-G9910</li>
<li>安卓13，One UI 5.1，20230701 安全补丁</li>
<li>google play 20230501 更新</li>
</ul>
<br/>
<br/>
<hr>
<h2 id="adb-操作">adb 操作</h2>
<p>上手，准备数据线和电脑（以下命令基于 win10</p>
<br/>
<h3 id="准备">准备</h3>
<blockquote>
<p>先备份，先备份，先备份，玩机有风险，先备份</p>
</blockquote>
<p>备份建议 <strong>s 换机助手</strong>；傻瓜式操作；</p>
<ul>
<li>pc 端下载 <span class="exturl" data-url="aHR0cHM6Ly93d3cuc2Ftc3VuZy5jb20vY24vYXBwcy9zbWFydC1zd2l0Y2gv">官网链接<i class="fa fa-external-link-alt"></i></span> ，上面是安卓端，往下滑有 pc 端；</li>
<li>手机直接应用市场 / google play</li>
<li>注意这里如果中途切断是会有大量 cache 占手机空间的（... 很坑），可以手机端重装卸载再来</li>
</ul>
<p>等待备份的时候准备 <strong>adb</strong>：</p>
<ul>
<li>建议不要用任何三方界面，adb 有什么好用三方的不就是套壳 ... <span class="exturl" data-url="aHR0cHM6Ly9kZXZlbG9wZXIuYW5kcm9pZC5jb20vdG9vbHMvcmVsZWFzZXMvcGxhdGZvcm0tdG9vbHM/aGw9emgtY24=">官网下载<i class="fa fa-external-link-alt"></i></span>，普通用用直接命令行工具就行；</li>
<li>打开 SDK-platform-tools，确认文件夹下有 adb.exe</li>
</ul>
<br/>
<h3 id="手机进开发者模式">手机进开发者模式</h3>
<p>设置 → 关于手机 → 软件信息 → 找到编译编号</p>
<p>连击七下，输入密码确认</p>
<p>返回设置，找到开发者选项 → usb 调试，打开；</p>
<p>数据线连接电脑</p>
<br/>
<h3 id="命令行工具">命令行工具</h3>
<p>打开刚刚下载的 sdk 工具，文件夹 SDK-platform-tools，确认文件夹下有 adb.exe</p>
<p>在当前目录下打开命令行工具</p>
<ul>
<li>直接在当前文件夹目录行输入 cmd，回车</li>
<li>或者 win+R，输入 cmd 启动后，再 cd 到当前文件夹</li>
</ul>
<h4 id="检查设备信息">检查设备信息</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">adb devices</span><br></pre></td></tr></table></figure>
<p>看手机，跳出窗口询问是否允许，授权；</p>
<h4 id="打开-shell-交互式">打开 shell 交互式</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">adb shell</span><br></pre></td></tr></table></figure>
<p>注意这里的命令行的开头变成 <code>o1q:/ $ </code> ，表示进入交互式命令</p>
<p>同时检查当前的软件列表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pm list package</span><br></pre></td></tr></table></figure>
<p>最好找个记事本把这里的输出复制粘贴记下来，到时候可以用关键字查找搜索包名删除</p>
<br/>
<h3 id="基本命令">基本命令</h3>
<p>以下都是在 shell 下，如果普通命令行记得加上 <code>adb shell</code></p>
<h4 id="删除">删除</h4>
<p>本质是为当前用户删除，不是直接移除；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pm uninstall -k --user 0 package-name</span><br></pre></td></tr></table></figure>
<p>这里的 package-name 在上面输出的 list 里面找，比如</p>
<p><code>package:/system/priv-app/GameTools_Dream/GameTools_Dream.apk=com.samsung.android.game.gametools</code></p>
<p>找到最后的 <code>apk=</code> 后 <code>.com</code> 的部分就是包名 <code>com.samsung.android.game.gametools</code></p>
<p>这里的 <code>-k</code> 是保存用户数据信息和缓存文件</p>
<p>比如删除游戏助推器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pm uninstall -k --user 0 com.samsung.android.game.gametools</span><br></pre></td></tr></table></figure>
<p>出现 Success 就是删除成功；如果是 Failure 一般是包名错误，注意大家版本都不太一样包名可能不一样，最好还是从自己的 list 里面找；</p>
<br/>
<h4 id="禁用">禁用</h4>
<p>直接 uninstall 换成 disable</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pm disable-user package-name</span><br></pre></td></tr></table></figure>
<p>package-name 和上面一样</p>
<br/>
<h4 id="恢复">恢复</h4>
<p>也就是 uninstall 换成 enable （所以说其实没有删除 ...</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pm enable package-name</span><br></pre></td></tr></table></figure>
<br/>
<br/>
<hr>
<h3 id="自用禁用列表">自用禁用列表</h3>
<p>还是看个人使用习惯，比如我不用 bixby 但希望保留完整的 google play 套件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">adb devices</span><br><span class="line">adb shell</span><br><span class="line"></span><br><span class="line"><span class="comment"># AR Zone</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.arzone</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.ardrawing.zh</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.aremoji</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.aremojieditor</span><br><span class="line"><span class="comment"># 游戏助推器</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.game.gametools</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.game.gos</span><br><span class="line"><span class="comment"># 相机贴纸</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.app.camera.sticker.facearavatar.preload</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.sec.android.autodoodle.service <span class="comment"># 费流量大户 ...</span></span><br><span class="line"><span class="comment"># 三星浏览器（注意装好替代）</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.sec.android.app.sbrowser</span><br><span class="line"><span class="comment"># Dex</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.sec.android.desktopmode.uiservice  <span class="comment"># Dex</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.sec.android.app.desktoplauncher  <span class="comment"># Dex 主屏幕</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.sec.android.dexsystemui</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.sec.android.app.dexonpc</span><br><span class="line"><span class="comment"># bixby 套件</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.bixby.service</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.bixbytouch</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.bixby.agent</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.bixby.wakeup</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.bixbyvision.framework</span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.app.settings.bixby</span><br><span class="line"><span class="comment"># 其他</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.kidsinstaller  <span class="comment"># 儿童模式</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.hongbaoassistant <span class="comment"># 红包助手</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.sec.mhs.smarttethering  <span class="comment"># 自动开启热点</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.mdecservice  <span class="comment"># 其他设备上打电话发短信</span></span><br><span class="line">pm uninstall --user <span class="number">0</span> com.samsung.android.mdx  <span class="comment"># 连接到 windows</span></span><br></pre></td></tr></table></figure>
<br/>
<br/>
<hr>
<h3 id="参考">参考</h3>
<p><span class="exturl" data-url="aHR0cHM6Ly90aWViYS5iYWlkdS5jb20vcC82OTA3MDQ5MDg1">adb禁用列表<i class="fa fa-external-link-alt"></i></span>  贴吧老哥补充很全，有些包名字变了，可以关键字在自己的 list 里面搜索</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9tYWFqaWFhLndvcmRwcmVzcy5jb20vMjAyMS8wNi8xMi9zYW1zdW5nLWJsb2F0d2FyZS1yZW1vdmFsLXdpdGhvdXQtcm9vdC8=">s10 原厂app 卸载笔记<i class="fa fa-external-link-alt"></i></span> 原作者建了 google doc，有记录一些大家删了出问题的包，可以先在这里check（当然个人建议是如果你不知道它是干嘛的，要么搞明白要么就别删 ...）</p>
<br/>
<br/>
<br/>
]]></content>
      <categories>
        <category>friends日常</category>
        <category>我和我的三桑</category>
      </categories>
      <tags>
        <tag>friends日常</tag>
        <tag>安卓</tag>
        <tag>我和我的三桑</tag>
      </tags>
  </entry>
</search>
